{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Price Prediction::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset from this link:\n",
    "\n",
    "https://www.kaggle.com/hellbuoy/car-price-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\n",
    "\n",
    "They have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n",
    "\n",
    "Which variables are significant in predicting the price of a car\n",
    "How well those variables describe the price of a car\n",
    "Based on various market surveys, the consulting firm has gathered a large data set of different types of cars across the America market.\n",
    "\n",
    "# task::\n",
    "We are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW ::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Load Data\n",
    "\n",
    "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
    "\n",
    "3.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
    "\n",
    "4.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
    "\n",
    "5.Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
    "6.Train the Model with Epochs (100) and validate it\n",
    "\n",
    "7.If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
    "\n",
    "8.Evaluation Step\n",
    "\n",
    "9.Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tp\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_ID</th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>...</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero giulia</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero stelvio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>alfa-romero Quadrifoglio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100 ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>-1</td>\n",
       "      <td>volvo 145e (sw)</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>109.1</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>16845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>-1</td>\n",
       "      <td>volvo 144ea</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>109.1</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>8.7</td>\n",
       "      <td>160</td>\n",
       "      <td>5300</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>19045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>203</td>\n",
       "      <td>-1</td>\n",
       "      <td>volvo 244dl</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>109.1</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.8</td>\n",
       "      <td>134</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>21485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>204</td>\n",
       "      <td>-1</td>\n",
       "      <td>volvo 246</td>\n",
       "      <td>diesel</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>109.1</td>\n",
       "      <td>...</td>\n",
       "      <td>145</td>\n",
       "      <td>idi</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>106</td>\n",
       "      <td>4800</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>22470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>205</td>\n",
       "      <td>-1</td>\n",
       "      <td>volvo 264gl</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>109.1</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>22625.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     car_ID  symboling                   CarName fueltype aspiration  \\\n",
       "0         1          3        alfa-romero giulia      gas        std   \n",
       "1         2          3       alfa-romero stelvio      gas        std   \n",
       "2         3          1  alfa-romero Quadrifoglio      gas        std   \n",
       "3         4          2               audi 100 ls      gas        std   \n",
       "4         5          2                audi 100ls      gas        std   \n",
       "..      ...        ...                       ...      ...        ...   \n",
       "200     201         -1           volvo 145e (sw)      gas        std   \n",
       "201     202         -1               volvo 144ea      gas      turbo   \n",
       "202     203         -1               volvo 244dl      gas        std   \n",
       "203     204         -1                 volvo 246   diesel      turbo   \n",
       "204     205         -1               volvo 264gl      gas      turbo   \n",
       "\n",
       "    doornumber      carbody drivewheel enginelocation  wheelbase  ...  \\\n",
       "0          two  convertible        rwd          front       88.6  ...   \n",
       "1          two  convertible        rwd          front       88.6  ...   \n",
       "2          two    hatchback        rwd          front       94.5  ...   \n",
       "3         four        sedan        fwd          front       99.8  ...   \n",
       "4         four        sedan        4wd          front       99.4  ...   \n",
       "..         ...          ...        ...            ...        ...  ...   \n",
       "200       four        sedan        rwd          front      109.1  ...   \n",
       "201       four        sedan        rwd          front      109.1  ...   \n",
       "202       four        sedan        rwd          front      109.1  ...   \n",
       "203       four        sedan        rwd          front      109.1  ...   \n",
       "204       four        sedan        rwd          front      109.1  ...   \n",
       "\n",
       "     enginesize  fuelsystem  boreratio  stroke compressionratio horsepower  \\\n",
       "0           130        mpfi       3.47    2.68              9.0        111   \n",
       "1           130        mpfi       3.47    2.68              9.0        111   \n",
       "2           152        mpfi       2.68    3.47              9.0        154   \n",
       "3           109        mpfi       3.19    3.40             10.0        102   \n",
       "4           136        mpfi       3.19    3.40              8.0        115   \n",
       "..          ...         ...        ...     ...              ...        ...   \n",
       "200         141        mpfi       3.78    3.15              9.5        114   \n",
       "201         141        mpfi       3.78    3.15              8.7        160   \n",
       "202         173        mpfi       3.58    2.87              8.8        134   \n",
       "203         145         idi       3.01    3.40             23.0        106   \n",
       "204         141        mpfi       3.78    3.15              9.5        114   \n",
       "\n",
       "     peakrpm citympg  highwaympg    price  \n",
       "0       5000      21          27  13495.0  \n",
       "1       5000      21          27  16500.0  \n",
       "2       5000      19          26  16500.0  \n",
       "3       5500      24          30  13950.0  \n",
       "4       5500      18          22  17450.0  \n",
       "..       ...     ...         ...      ...  \n",
       "200     5400      23          28  16845.0  \n",
       "201     5300      19          25  19045.0  \n",
       "202     5500      18          23  21485.0  \n",
       "203     4800      26          27  22470.0  \n",
       "204     5400      19          25  22625.0  \n",
       "\n",
       "[205 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('CarPrice_Assignment.csv')\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_ID</th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>...</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero giulia</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>alfa-romero stelvio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>alfa-romero Quadrifoglio</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100 ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>audi 100ls</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   car_ID  symboling                   CarName fueltype aspiration doornumber  \\\n",
       "0       1          3        alfa-romero giulia      gas        std        two   \n",
       "1       2          3       alfa-romero stelvio      gas        std        two   \n",
       "2       3          1  alfa-romero Quadrifoglio      gas        std        two   \n",
       "3       4          2               audi 100 ls      gas        std       four   \n",
       "4       5          2                audi 100ls      gas        std       four   \n",
       "\n",
       "       carbody drivewheel enginelocation  wheelbase  ...  enginesize  \\\n",
       "0  convertible        rwd          front       88.6  ...         130   \n",
       "1  convertible        rwd          front       88.6  ...         130   \n",
       "2    hatchback        rwd          front       94.5  ...         152   \n",
       "3        sedan        fwd          front       99.8  ...         109   \n",
       "4        sedan        4wd          front       99.4  ...         136   \n",
       "\n",
       "   fuelsystem  boreratio  stroke compressionratio horsepower  peakrpm citympg  \\\n",
       "0        mpfi       3.47    2.68              9.0        111     5000      21   \n",
       "1        mpfi       3.47    2.68              9.0        111     5000      21   \n",
       "2        mpfi       2.68    3.47              9.0        154     5000      19   \n",
       "3        mpfi       3.19    3.40             10.0        102     5500      24   \n",
       "4        mpfi       3.19    3.40              8.0        115     5500      18   \n",
       "\n",
       "   highwaympg    price  \n",
       "0          27  13495.0  \n",
       "1          27  16500.0  \n",
       "2          26  16500.0  \n",
       "3          30  13950.0  \n",
       "4          22  17450.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_ID              0\n",
       "symboling           0\n",
       "CarName             0\n",
       "fueltype            0\n",
       "aspiration          0\n",
       "doornumber          0\n",
       "carbody             0\n",
       "drivewheel          0\n",
       "enginelocation      0\n",
       "wheelbase           0\n",
       "carlength           0\n",
       "carwidth            0\n",
       "carheight           0\n",
       "curbweight          0\n",
       "enginetype          0\n",
       "cylindernumber      0\n",
       "enginesize          0\n",
       "fuelsystem          0\n",
       "boreratio           0\n",
       "stroke              0\n",
       "compressionratio    0\n",
       "horsepower          0\n",
       "peakrpm             0\n",
       "citympg             0\n",
       "highwaympg          0\n",
       "price               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # to count the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_ID                int64\n",
       "symboling             int64\n",
       "CarName              object\n",
       "fueltype             object\n",
       "aspiration           object\n",
       "doornumber           object\n",
       "carbody              object\n",
       "drivewheel           object\n",
       "enginelocation       object\n",
       "wheelbase           float64\n",
       "carlength           float64\n",
       "carwidth            float64\n",
       "carheight           float64\n",
       "curbweight            int64\n",
       "enginetype           object\n",
       "cylindernumber       object\n",
       "enginesize            int64\n",
       "fuelsystem           object\n",
       "boreratio           float64\n",
       "stroke              float64\n",
       "compressionratio    float64\n",
       "horsepower            int64\n",
       "peakrpm               int64\n",
       "citympg               int64\n",
       "highwaympg            int64\n",
       "price               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CarName', 'fueltype', 'aspiration', 'doornumber', 'carbody',\n",
       "        'drivewheel', 'enginelocation', 'enginetype', 'cylindernumber',\n",
       "        'fuelsystem'], dtype=object),\n",
       " (10,),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= df.columns[df.dtypes== 'O'].values\n",
    "a , a.shape , type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_ID</th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>...</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>5</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>5</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>5</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>-1</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>5</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>16845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>-1</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>5</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>8.7</td>\n",
       "      <td>160</td>\n",
       "      <td>5300</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>19045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>203</td>\n",
       "      <td>-1</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>5</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.8</td>\n",
       "      <td>134</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>21485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>204</td>\n",
       "      <td>-1</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>...</td>\n",
       "      <td>145</td>\n",
       "      <td>3</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>106</td>\n",
       "      <td>4800</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>22470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>205</td>\n",
       "      <td>-1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>5</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>22625.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     car_ID  symboling  CarName  fueltype  aspiration  doornumber  carbody  \\\n",
       "0         1          3        2         1           0           2        0   \n",
       "1         2          3        3         1           0           2        0   \n",
       "2         3          1        1         1           0           2        2   \n",
       "3         4          2        4         1           0           4        3   \n",
       "4         5          2        5         1           0           4        3   \n",
       "..      ...        ...      ...       ...         ...         ...      ...   \n",
       "200     201         -1      139         1           0           4        3   \n",
       "201     202         -1      138         1           1           4        3   \n",
       "202     203         -1      140         1           0           4        3   \n",
       "203     204         -1      142         0           1           4        3   \n",
       "204     205         -1      143         1           1           4        3   \n",
       "\n",
       "     drivewheel  enginelocation  wheelbase  ...  enginesize  fuelsystem  \\\n",
       "0             2               0       88.6  ...         130           5   \n",
       "1             2               0       88.6  ...         130           5   \n",
       "2             2               0       94.5  ...         152           5   \n",
       "3             1               0       99.8  ...         109           5   \n",
       "4             0               0       99.4  ...         136           5   \n",
       "..          ...             ...        ...  ...         ...         ...   \n",
       "200           2               0      109.1  ...         141           5   \n",
       "201           2               0      109.1  ...         141           5   \n",
       "202           2               0      109.1  ...         173           5   \n",
       "203           2               0      109.1  ...         145           3   \n",
       "204           2               0      109.1  ...         141           5   \n",
       "\n",
       "     boreratio  stroke  compressionratio  horsepower  peakrpm  citympg  \\\n",
       "0         3.47    2.68               9.0         111     5000       21   \n",
       "1         3.47    2.68               9.0         111     5000       21   \n",
       "2         2.68    3.47               9.0         154     5000       19   \n",
       "3         3.19    3.40              10.0         102     5500       24   \n",
       "4         3.19    3.40               8.0         115     5500       18   \n",
       "..         ...     ...               ...         ...      ...      ...   \n",
       "200       3.78    3.15               9.5         114     5400       23   \n",
       "201       3.78    3.15               8.7         160     5300       19   \n",
       "202       3.58    2.87               8.8         134     5500       18   \n",
       "203       3.01    3.40              23.0         106     4800       26   \n",
       "204       3.78    3.15               9.5         114     5400       19   \n",
       "\n",
       "     highwaympg    price  \n",
       "0            27  13495.0  \n",
       "1            27  16500.0  \n",
       "2            26  16500.0  \n",
       "3            30  13950.0  \n",
       "4            22  17450.0  \n",
       "..          ...      ...  \n",
       "200          28  16845.0  \n",
       "201          25  19045.0  \n",
       "202          23  21485.0  \n",
       "203          27  22470.0  \n",
       "204          25  22625.0  \n",
       "\n",
       "[205 rows x 26 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelEncoder=LabelEncoder()\n",
    "df['doornumber']= df['doornumber'].map({'two':2,'four':4})\n",
    "for i in range(10):\n",
    "    if a[i]=='doornumber':\n",
    "        continue\n",
    "       \n",
    "    df[a[i]]= labelEncoder.fit_transform(df[a[i]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_ID                int64\n",
       "symboling             int64\n",
       "CarName               int32\n",
       "fueltype              int32\n",
       "aspiration            int32\n",
       "doornumber            int64\n",
       "carbody               int32\n",
       "drivewheel            int32\n",
       "enginelocation        int32\n",
       "wheelbase           float64\n",
       "carlength           float64\n",
       "carwidth            float64\n",
       "carheight           float64\n",
       "curbweight            int64\n",
       "enginetype            int32\n",
       "cylindernumber        int32\n",
       "enginesize            int64\n",
       "fuelsystem            int32\n",
       "boreratio           float64\n",
       "stroke              float64\n",
       "compressionratio    float64\n",
       "horsepower            int64\n",
       "peakrpm               int64\n",
       "citympg               int64\n",
       "highwaympg            int64\n",
       "price               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_ID              0\n",
       "symboling           0\n",
       "CarName             0\n",
       "fueltype            0\n",
       "aspiration          0\n",
       "doornumber          0\n",
       "carbody             0\n",
       "drivewheel          0\n",
       "enginelocation      0\n",
       "wheelbase           0\n",
       "carlength           0\n",
       "carwidth            0\n",
       "carheight           0\n",
       "curbweight          0\n",
       "enginetype          0\n",
       "cylindernumber      0\n",
       "enginesize          0\n",
       "fuelsystem          0\n",
       "boreratio           0\n",
       "stroke              0\n",
       "compressionratio    0\n",
       "horsepower          0\n",
       "peakrpm             0\n",
       "citympg             0\n",
       "highwaympg          0\n",
       "price               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_ID</th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>...</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97.2</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.64</td>\n",
       "      <td>9.0</td>\n",
       "      <td>94</td>\n",
       "      <td>5200</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>9960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>151</td>\n",
       "      <td>5</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.11</td>\n",
       "      <td>9.5</td>\n",
       "      <td>143</td>\n",
       "      <td>5500</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>22018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93.7</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.23</td>\n",
       "      <td>9.4</td>\n",
       "      <td>68</td>\n",
       "      <td>5500</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>6692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197</td>\n",
       "      <td>-2</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>104.3</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>5</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>15985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>5</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>179</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>102.9</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.35</td>\n",
       "      <td>9.3</td>\n",
       "      <td>161</td>\n",
       "      <td>5200</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>16558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>204</td>\n",
       "      <td>-1</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>...</td>\n",
       "      <td>145</td>\n",
       "      <td>3</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>106</td>\n",
       "      <td>4800</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>22470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98.8</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.39</td>\n",
       "      <td>22.7</td>\n",
       "      <td>64</td>\n",
       "      <td>4650</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>10795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>103.5</td>\n",
       "      <td>...</td>\n",
       "      <td>209</td>\n",
       "      <td>5</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.39</td>\n",
       "      <td>8.0</td>\n",
       "      <td>182</td>\n",
       "      <td>5400</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>30760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93.7</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.41</td>\n",
       "      <td>9.2</td>\n",
       "      <td>76</td>\n",
       "      <td>6000</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>7129.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     car_ID  symboling  CarName  fueltype  aspiration  doornumber  carbody  \\\n",
       "0       144          0      105         1           0           4        3   \n",
       "1       126          3       98         1           0           2        2   \n",
       "2       122          1       93         1           0           4        3   \n",
       "3       197         -2      140         1           0           4        3   \n",
       "4         3          1        1         1           0           2        2   \n",
       "..      ...        ...      ...       ...         ...         ...      ...   \n",
       "200     179          3      118         1           0           2        2   \n",
       "201     204         -1      142         0           1           4        3   \n",
       "202      64          0       58         0           0           4        3   \n",
       "203      16          0       13         1           0           4        3   \n",
       "204      35          1       43         1           0           2        2   \n",
       "\n",
       "     drivewheel  enginelocation  wheelbase  ...  enginesize  fuelsystem  \\\n",
       "0             1               0       97.2  ...         108           5   \n",
       "1             2               0       94.5  ...         151           5   \n",
       "2             1               0       93.7  ...          90           1   \n",
       "3             2               0      104.3  ...         141           5   \n",
       "4             2               0       94.5  ...         152           5   \n",
       "..          ...             ...        ...  ...         ...         ...   \n",
       "200           2               0      102.9  ...         171           5   \n",
       "201           2               0      109.1  ...         145           3   \n",
       "202           1               0       98.8  ...         122           3   \n",
       "203           2               0      103.5  ...         209           5   \n",
       "204           1               0       93.7  ...          92           0   \n",
       "\n",
       "     boreratio  stroke  compressionratio  horsepower  peakrpm  citympg  \\\n",
       "0         3.62    2.64               9.0          94     5200       26   \n",
       "1         3.94    3.11               9.5         143     5500       19   \n",
       "2         2.97    3.23               9.4          68     5500       31   \n",
       "3         3.78    3.15               9.5         114     5400       24   \n",
       "4         2.68    3.47               9.0         154     5000       19   \n",
       "..         ...     ...               ...         ...      ...      ...   \n",
       "200       3.27    3.35               9.3         161     5200       20   \n",
       "201       3.01    3.40              23.0         106     4800       26   \n",
       "202       3.39    3.39              22.7          64     4650       36   \n",
       "203       3.62    3.39               8.0         182     5400       16   \n",
       "204       2.91    3.41               9.2          76     6000       30   \n",
       "\n",
       "     highwaympg    price  \n",
       "0            32   9960.0  \n",
       "1            27  22018.0  \n",
       "2            38   6692.0  \n",
       "3            28  15985.0  \n",
       "4            26  16500.0  \n",
       "..          ...      ...  \n",
       "200          24  16558.0  \n",
       "201          27  22470.0  \n",
       "202          42  10795.0  \n",
       "203          22  30760.0  \n",
       "204          34   7129.0  \n",
       "\n",
       "[205 rows x 26 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuffled=df.sample(frac=1).reset_index(drop=True)\n",
    "df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4400e+02, 0.0000e+00, 1.0500e+02, ..., 2.6000e+01, 3.2000e+01,\n",
       "        9.9600e+03],\n",
       "       [1.2600e+02, 3.0000e+00, 9.8000e+01, ..., 1.9000e+01, 2.7000e+01,\n",
       "        2.2018e+04],\n",
       "       [1.2200e+02, 1.0000e+00, 9.3000e+01, ..., 3.1000e+01, 3.8000e+01,\n",
       "        6.6920e+03],\n",
       "       ...,\n",
       "       [6.4000e+01, 0.0000e+00, 5.8000e+01, ..., 3.6000e+01, 4.2000e+01,\n",
       "        1.0795e+04],\n",
       "       [1.6000e+01, 0.0000e+00, 1.3000e+01, ..., 1.6000e+01, 2.2000e+01,\n",
       "        3.0760e+04],\n",
       "       [3.5000e+01, 1.0000e+00, 4.3000e+01, ..., 3.0000e+01, 3.4000e+01,\n",
       "        7.1290e+03]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shuff= df_shuffled.values\n",
    "df_shuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.44e+02, 0.00e+00, 1.05e+02, ..., 5.20e+03, 2.60e+01, 3.20e+01],\n",
       "        [1.26e+02, 3.00e+00, 9.80e+01, ..., 5.50e+03, 1.90e+01, 2.70e+01],\n",
       "        [1.22e+02, 1.00e+00, 9.30e+01, ..., 5.50e+03, 3.10e+01, 3.80e+01],\n",
       "        ...,\n",
       "        [9.40e+01, 1.00e+00, 8.30e+01, ..., 5.20e+03, 3.10e+01, 3.70e+01],\n",
       "        [9.90e+01, 2.00e+00, 7.00e+01, ..., 5.20e+03, 3.10e+01, 3.70e+01],\n",
       "        [6.60e+01, 0.00e+00, 5.40e+01, ..., 5.00e+03, 1.90e+01, 2.70e+01]],\n",
       "       dtype=float32),\n",
       " (103, 25))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data= df_shuff[:103,:25].astype('float32')\n",
    "train_data , train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 156.,    0.,  112., ..., 4800.,   27.,   32.],\n",
       "        [  36.,    0.,   38., ..., 6000.,   30.,   34.],\n",
       "        [ 114.,    0.,   85., ..., 5000.,   19.,   24.],\n",
       "        ...,\n",
       "        [ 193.,    0.,  135., ..., 4500.,   33.,   38.],\n",
       "        [ 159.,    0.,  120., ..., 4500.,   34.,   36.],\n",
       "        [ 108.,    0.,   85., ..., 5000.,   19.,   24.]], dtype=float32),\n",
       " (62, 25))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data= df_shuff[103:165,:25].astype('float32')\n",
    "test_data , test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.120e+02,  0.000e+00,  8.500e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  2.000e+00,  0.000e+00,  1.079e+02,\n",
       "          1.867e+02,  6.840e+01,  5.670e+01,  3.075e+03,  2.000e+00,\n",
       "          2.000e+00,  1.200e+02,  5.000e+00,  3.460e+00,  2.190e+00,\n",
       "          8.400e+00,  9.500e+01,  5.000e+03,  1.900e+01,  2.400e+01],\n",
       "        [ 1.880e+02,  2.000e+00,  1.360e+02,  0.000e+00,  1.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.730e+01,\n",
       "          1.717e+02,  6.550e+01,  5.570e+01,  2.319e+03,  3.000e+00,\n",
       "          2.000e+00,  9.700e+01,  3.000e+00,  3.010e+00,  3.400e+00,\n",
       "          2.300e+01,  6.800e+01,  4.500e+03,  3.700e+01,  4.200e+01],\n",
       "        [ 1.700e+01,  0.000e+00,  1.400e+01,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  3.000e+00,  2.000e+00,  0.000e+00,  1.035e+02,\n",
       "          1.938e+02,  6.790e+01,  5.370e+01,  3.380e+03,  3.000e+00,\n",
       "          3.000e+00,  2.090e+02,  5.000e+00,  3.620e+00,  3.390e+00,\n",
       "          8.000e+00,  1.820e+02,  5.400e+03,  1.600e+01,  2.200e+01],\n",
       "        [ 1.840e+02,  2.000e+00,  1.300e+02,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.730e+01,\n",
       "          1.717e+02,  6.550e+01,  5.570e+01,  2.209e+03,  3.000e+00,\n",
       "          2.000e+00,  1.090e+02,  5.000e+00,  3.190e+00,  3.400e+00,\n",
       "          9.000e+00,  8.500e+01,  5.250e+03,  2.700e+01,  3.400e+01],\n",
       "        [ 1.900e+01,  2.000e+00,  2.400e+01,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,  8.840e+01,\n",
       "          1.411e+02,  6.030e+01,  5.320e+01,  1.488e+03,  2.000e+00,\n",
       "          4.000e+00,  6.100e+01,  1.000e+00,  2.910e+00,  3.030e+00,\n",
       "          9.500e+00,  4.800e+01,  5.100e+03,  4.700e+01,  5.300e+01],\n",
       "        [ 2.050e+02, -1.000e+00,  1.430e+02,  1.000e+00,  1.000e+00,\n",
       "          4.000e+00,  3.000e+00,  2.000e+00,  0.000e+00,  1.091e+02,\n",
       "          1.888e+02,  6.890e+01,  5.550e+01,  3.062e+03,  3.000e+00,\n",
       "          2.000e+00,  1.410e+02,  5.000e+00,  3.780e+00,  3.150e+00,\n",
       "          9.500e+00,  1.140e+02,  5.400e+03,  1.900e+01,  2.500e+01],\n",
       "        [ 2.500e+01,  1.000e+00,  3.400e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,  9.370e+01,\n",
       "          1.573e+02,  6.380e+01,  5.060e+01,  1.967e+03,  3.000e+00,\n",
       "          2.000e+00,  9.000e+01,  1.000e+00,  2.970e+00,  3.230e+00,\n",
       "          9.400e+00,  6.800e+01,  5.500e+03,  3.100e+01,  3.800e+01],\n",
       "        [ 1.870e+02,  2.000e+00,  1.310e+02,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.730e+01,\n",
       "          1.717e+02,  6.550e+01,  5.570e+01,  2.275e+03,  3.000e+00,\n",
       "          2.000e+00,  1.090e+02,  5.000e+00,  3.190e+00,  3.400e+00,\n",
       "          9.000e+00,  8.500e+01,  5.250e+03,  2.700e+01,  3.400e+01],\n",
       "        [ 1.800e+02,  3.000e+00,  1.200e+02,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  2.000e+00,  2.000e+00,  0.000e+00,  1.029e+02,\n",
       "          1.835e+02,  6.770e+01,  5.200e+01,  3.016e+03,  0.000e+00,\n",
       "          3.000e+00,  1.710e+02,  5.000e+00,  3.270e+00,  3.350e+00,\n",
       "          9.300e+00,  1.610e+02,  5.200e+03,  1.900e+01,  2.400e+01],\n",
       "        [ 1.760e+02, -1.000e+00,  1.200e+02,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,  1.024e+02,\n",
       "          1.756e+02,  6.650e+01,  5.390e+01,  2.414e+03,  3.000e+00,\n",
       "          2.000e+00,  1.220e+02,  5.000e+00,  3.310e+00,  3.540e+00,\n",
       "          8.700e+00,  9.200e+01,  4.200e+03,  2.700e+01,  3.200e+01],\n",
       "        [ 4.100e+01,  0.000e+00,  3.600e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.650e+01,\n",
       "          1.754e+02,  6.250e+01,  5.410e+01,  2.372e+03,  3.000e+00,\n",
       "          2.000e+00,  1.100e+02,  0.000e+00,  3.150e+00,  3.580e+00,\n",
       "          9.000e+00,  8.600e+01,  5.800e+03,  2.700e+01,  3.300e+01],\n",
       "        [ 4.000e+00,  2.000e+00,  4.000e+00,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.980e+01,\n",
       "          1.766e+02,  6.620e+01,  5.430e+01,  2.337e+03,  3.000e+00,\n",
       "          2.000e+00,  1.090e+02,  5.000e+00,  3.190e+00,  3.400e+00,\n",
       "          1.000e+01,  1.020e+02,  5.500e+03,  2.400e+01,  3.000e+01],\n",
       "        [ 1.130e+02,  0.000e+00,  8.800e+01,  0.000e+00,  1.000e+00,\n",
       "          4.000e+00,  3.000e+00,  2.000e+00,  0.000e+00,  1.079e+02,\n",
       "          1.867e+02,  6.840e+01,  5.670e+01,  3.252e+03,  2.000e+00,\n",
       "          2.000e+00,  1.520e+02,  3.000e+00,  3.700e+00,  3.520e+00,\n",
       "          2.100e+01,  9.500e+01,  4.150e+03,  2.800e+01,  3.300e+01],\n",
       "        [ 9.300e+01,  1.000e+00,  7.600e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.450e+01,\n",
       "          1.653e+02,  6.380e+01,  5.450e+01,  1.938e+03,  3.000e+00,\n",
       "          2.000e+00,  9.700e+01,  1.000e+00,  3.150e+00,  3.290e+00,\n",
       "          9.400e+00,  6.900e+01,  5.200e+03,  3.100e+01,  3.700e+01],\n",
       "        [ 7.800e+01,  2.000e+00,  6.400e+01,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,  9.370e+01,\n",
       "          1.573e+02,  6.440e+01,  5.080e+01,  1.944e+03,  3.000e+00,\n",
       "          2.000e+00,  9.200e+01,  1.000e+00,  2.970e+00,  3.230e+00,\n",
       "          9.400e+00,  6.800e+01,  5.500e+03,  3.100e+01,  3.800e+01],\n",
       "        [ 8.200e+01,  3.000e+00,  6.300e+01,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,  9.630e+01,\n",
       "          1.730e+02,  6.540e+01,  4.940e+01,  2.328e+03,  3.000e+00,\n",
       "          2.000e+00,  1.220e+02,  1.000e+00,  3.350e+00,  3.460e+00,\n",
       "          8.500e+00,  8.800e+01,  5.000e+03,  2.500e+01,  3.200e+01],\n",
       "        [ 3.200e+01,  2.000e+00,  4.300e+01,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,  8.660e+01,\n",
       "          1.446e+02,  6.390e+01,  5.080e+01,  1.819e+03,  3.000e+00,\n",
       "          2.000e+00,  9.200e+01,  0.000e+00,  2.910e+00,  3.410e+00,\n",
       "          9.200e+00,  7.600e+01,  6.000e+03,  3.100e+01,  3.800e+01],\n",
       "        [ 4.000e+01,  0.000e+00,  4.400e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.650e+01,\n",
       "          1.754e+02,  6.520e+01,  5.410e+01,  2.304e+03,  3.000e+00,\n",
       "          2.000e+00,  1.100e+02,  0.000e+00,  3.150e+00,  3.580e+00,\n",
       "          9.000e+00,  8.600e+01,  5.800e+03,  2.700e+01,  3.300e+01],\n",
       "        [ 1.150e+02,  0.000e+00,  8.700e+01,  0.000e+00,  1.000e+00,\n",
       "          4.000e+00,  4.000e+00,  2.000e+00,  0.000e+00,  1.142e+02,\n",
       "          1.989e+02,  6.840e+01,  5.870e+01,  3.485e+03,  2.000e+00,\n",
       "          2.000e+00,  1.520e+02,  3.000e+00,  3.700e+00,  3.520e+00,\n",
       "          2.100e+01,  9.500e+01,  4.150e+03,  2.500e+01,  2.500e+01],\n",
       "        [ 1.650e+02,  1.000e+00,  1.200e+02,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  2.000e+00,  2.000e+00,  0.000e+00,  9.450e+01,\n",
       "          1.687e+02,  6.400e+01,  5.260e+01,  2.204e+03,  3.000e+00,\n",
       "          2.000e+00,  9.800e+01,  1.000e+00,  3.190e+00,  3.030e+00,\n",
       "          9.000e+00,  7.000e+01,  4.800e+03,  2.900e+01,  3.400e+01],\n",
       "        [ 1.610e+02,  0.000e+00,  1.200e+02,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.570e+01,\n",
       "          1.663e+02,  6.440e+01,  5.300e+01,  2.094e+03,  3.000e+00,\n",
       "          2.000e+00,  9.800e+01,  1.000e+00,  3.190e+00,  3.030e+00,\n",
       "          9.000e+00,  7.000e+01,  4.800e+03,  3.800e+01,  4.700e+01],\n",
       "        [ 8.900e+01, -1.000e+00,  6.600e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.630e+01,\n",
       "          1.724e+02,  6.540e+01,  5.160e+01,  2.403e+03,  3.000e+00,\n",
       "          2.000e+00,  1.100e+02,  6.000e+00,  3.170e+00,  3.460e+00,\n",
       "          7.500e+00,  1.160e+02,  5.500e+03,  2.300e+01,  3.000e+01],\n",
       "        [ 1.000e+02,  0.000e+00,  8.100e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,  9.720e+01,\n",
       "          1.734e+02,  6.520e+01,  5.470e+01,  2.324e+03,  3.000e+00,\n",
       "          2.000e+00,  1.200e+02,  1.000e+00,  3.330e+00,  3.470e+00,\n",
       "          8.500e+00,  9.700e+01,  5.200e+03,  2.700e+01,  3.400e+01],\n",
       "        [ 2.700e+01,  1.000e+00,  2.800e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.370e+01,\n",
       "          1.573e+02,  6.380e+01,  5.060e+01,  1.989e+03,  3.000e+00,\n",
       "          2.000e+00,  9.000e+01,  1.000e+00,  2.970e+00,  3.230e+00,\n",
       "          9.400e+00,  6.800e+01,  5.500e+03,  3.100e+01,  3.800e+01],\n",
       "        [ 6.700e+01,  0.000e+00,  6.000e+01,  0.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  2.000e+00,  0.000e+00,  1.049e+02,\n",
       "          1.750e+02,  6.610e+01,  5.440e+01,  2.700e+03,  3.000e+00,\n",
       "          2.000e+00,  1.340e+02,  3.000e+00,  3.430e+00,  3.640e+00,\n",
       "          2.200e+01,  7.200e+01,  4.200e+03,  3.100e+01,  3.900e+01],\n",
       "        [ 1.910e+02,  3.000e+00,  1.460e+02,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,  9.450e+01,\n",
       "          1.657e+02,  6.400e+01,  5.140e+01,  2.221e+03,  3.000e+00,\n",
       "          2.000e+00,  1.090e+02,  5.000e+00,  3.190e+00,  3.400e+00,\n",
       "          8.500e+00,  9.000e+01,  5.500e+03,  2.400e+01,  2.900e+01],\n",
       "        [ 7.200e+01, -1.000e+00,  2.000e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  2.000e+00,  0.000e+00,  1.156e+02,\n",
       "          2.026e+02,  7.170e+01,  5.650e+01,  3.740e+03,  5.000e+00,\n",
       "          0.000e+00,  2.340e+02,  5.000e+00,  3.460e+00,  3.100e+00,\n",
       "          8.300e+00,  1.550e+02,  4.750e+03,  1.600e+01,  1.800e+01],\n",
       "        [ 1.900e+02,  3.000e+00,  1.450e+02,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  0.000e+00,  1.000e+00,  0.000e+00,  9.450e+01,\n",
       "          1.593e+02,  6.420e+01,  5.560e+01,  2.254e+03,  3.000e+00,\n",
       "          2.000e+00,  1.090e+02,  5.000e+00,  3.190e+00,  3.400e+00,\n",
       "          8.500e+00,  9.000e+01,  5.500e+03,  2.400e+01,  2.900e+01],\n",
       "        [ 1.680e+02,  2.000e+00,  1.220e+02,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  1.000e+00,  2.000e+00,  0.000e+00,  9.840e+01,\n",
       "          1.762e+02,  6.560e+01,  5.200e+01,  2.540e+03,  3.000e+00,\n",
       "          2.000e+00,  1.460e+02,  5.000e+00,  3.620e+00,  3.500e+00,\n",
       "          9.300e+00,  1.160e+02,  4.800e+03,  2.400e+01,  3.000e+01],\n",
       "        [ 4.600e+01,  0.000e+00,  4.600e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.450e+01,\n",
       "          1.559e+02,  6.360e+01,  5.200e+01,  1.909e+03,  3.000e+00,\n",
       "          2.000e+00,  9.000e+01,  1.000e+00,  3.030e+00,  3.110e+00,\n",
       "          9.600e+00,  7.000e+01,  5.400e+03,  3.800e+01,  4.300e+01],\n",
       "        [ 1.350e+02,  3.000e+00,  1.030e+02,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,  9.910e+01,\n",
       "          1.866e+02,  6.650e+01,  5.610e+01,  2.707e+03,  3.000e+00,\n",
       "          2.000e+00,  1.210e+02,  5.000e+00,  2.540e+00,  2.070e+00,\n",
       "          9.300e+00,  1.100e+02,  5.250e+03,  2.100e+01,  2.800e+01],\n",
       "        [ 2.900e+01, -1.000e+00,  3.300e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  4.000e+00,  1.000e+00,  0.000e+00,  1.033e+02,\n",
       "          1.746e+02,  6.460e+01,  5.980e+01,  2.535e+03,  3.000e+00,\n",
       "          2.000e+00,  1.220e+02,  1.000e+00,  3.340e+00,  3.460e+00,\n",
       "          8.500e+00,  8.800e+01,  5.000e+03,  2.400e+01,  3.000e+01],\n",
       "        [ 3.000e+01,  3.000e+00,  3.100e+01,  1.000e+00,  1.000e+00,\n",
       "          2.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,  9.590e+01,\n",
       "          1.732e+02,  6.630e+01,  5.020e+01,  2.811e+03,  3.000e+00,\n",
       "          2.000e+00,  1.560e+02,  4.000e+00,  3.600e+00,  3.900e+00,\n",
       "          7.000e+00,  1.450e+02,  5.000e+03,  1.900e+01,  2.400e+01],\n",
       "        [ 4.200e+01,  0.000e+00,  3.900e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.650e+01,\n",
       "          1.754e+02,  6.520e+01,  5.410e+01,  2.465e+03,  3.000e+00,\n",
       "          2.000e+00,  1.100e+02,  5.000e+00,  3.150e+00,  3.580e+00,\n",
       "          9.000e+00,  1.010e+02,  5.800e+03,  2.400e+01,  2.800e+01],\n",
       "        [ 1.160e+02,  0.000e+00,  8.500e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  2.000e+00,  0.000e+00,  1.079e+02,\n",
       "          1.867e+02,  6.840e+01,  5.670e+01,  3.075e+03,  2.000e+00,\n",
       "          2.000e+00,  1.200e+02,  5.000e+00,  3.460e+00,  3.190e+00,\n",
       "          8.400e+00,  9.700e+01,  5.000e+03,  1.900e+01,  2.400e+01],\n",
       "        [ 1.790e+02,  3.000e+00,  1.180e+02,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  2.000e+00,  2.000e+00,  0.000e+00,  1.029e+02,\n",
       "          1.835e+02,  6.770e+01,  5.200e+01,  2.976e+03,  0.000e+00,\n",
       "          3.000e+00,  1.710e+02,  5.000e+00,  3.270e+00,  3.350e+00,\n",
       "          9.300e+00,  1.610e+02,  5.200e+03,  2.000e+01,  2.400e+01],\n",
       "        [ 2.040e+02, -1.000e+00,  1.420e+02,  0.000e+00,  1.000e+00,\n",
       "          4.000e+00,  3.000e+00,  2.000e+00,  0.000e+00,  1.091e+02,\n",
       "          1.888e+02,  6.890e+01,  5.550e+01,  3.217e+03,  3.000e+00,\n",
       "          3.000e+00,  1.450e+02,  3.000e+00,  3.010e+00,  3.400e+00,\n",
       "          2.300e+01,  1.060e+02,  4.800e+03,  2.600e+01,  2.700e+01],\n",
       "        [ 6.400e+01,  0.000e+00,  5.800e+01,  0.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  1.000e+00,  0.000e+00,  9.880e+01,\n",
       "          1.778e+02,  6.650e+01,  5.550e+01,  2.443e+03,  3.000e+00,\n",
       "          2.000e+00,  1.220e+02,  3.000e+00,  3.390e+00,  3.390e+00,\n",
       "          2.270e+01,  6.400e+01,  4.650e+03,  3.600e+01,  4.200e+01],\n",
       "        [ 1.600e+01,  0.000e+00,  1.300e+01,  1.000e+00,  0.000e+00,\n",
       "          4.000e+00,  3.000e+00,  2.000e+00,  0.000e+00,  1.035e+02,\n",
       "          1.890e+02,  6.690e+01,  5.570e+01,  3.230e+03,  3.000e+00,\n",
       "          3.000e+00,  2.090e+02,  5.000e+00,  3.620e+00,  3.390e+00,\n",
       "          8.000e+00,  1.820e+02,  5.400e+03,  1.600e+01,  2.200e+01],\n",
       "        [ 3.500e+01,  1.000e+00,  4.300e+01,  1.000e+00,  0.000e+00,\n",
       "          2.000e+00,  2.000e+00,  1.000e+00,  0.000e+00,  9.370e+01,\n",
       "          1.500e+02,  6.400e+01,  5.260e+01,  1.956e+03,  3.000e+00,\n",
       "          2.000e+00,  9.200e+01,  0.000e+00,  2.910e+00,  3.410e+00,\n",
       "          9.200e+00,  7.600e+01,  6.000e+03,  3.000e+01,  3.400e+01]],\n",
       "       dtype=float32),\n",
       " (40, 25))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data= df_shuff[165:,:25].astype('float32')\n",
    "val_data , val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9960.   , 22018.   ,  6692.   , 15985.   , 16500.   , 32528.   ,\n",
       "        17669.   , 37028.   , 10198.   , 28248.   ,  7126.   ,  6479.   ,\n",
       "         7788.   ,  8845.   , 10898.   ,  7799.   , 11845.   ,  7775.   ,\n",
       "         9538.   ,  9295.   , 16430.   , 13499.   , 17859.168,  9995.   ,\n",
       "        16503.   , 12440.   ,  7463.   ,  7053.   , 13415.   ,  6918.   ,\n",
       "        21485.   , 18420.   ,  6529.   ,  6095.   , 13200.   , 12764.   ,\n",
       "         7957.   ,  9959.   ,  6695.   ,  6338.   , 28176.   , 15750.   ,\n",
       "         7099.   , 36880.   , 10945.   ,  8495.   ,  6229.   , 17710.   ,\n",
       "        16845.   , 35550.   , 40960.   , 18150.   ,  7609.   ,  7689.   ,\n",
       "        11248.   ,  6989.   , 19699.   , 45400.   ,  9233.   ,  8013.   ,\n",
       "        13860.   , 16500.   , 16515.   , 34028.   ,  7995.   , 10595.   ,\n",
       "         7198.   ,  6692.   , 13645.   , 12290.   ,  6669.   , 11199.   ,\n",
       "         6785.   , 18950.   ,  9549.   ,  8058.   , 25552.   , 24565.   ,\n",
       "         9298.   ,  8558.   , 13295.   ,  7603.   ,  8195.   ,  7299.   ,\n",
       "         8916.5  ,  5389.   ,  9895.   ,  7999.   , 11259.   , 13499.   ,\n",
       "         9279.   ,  7775.   , 17199.   ,  9095.   , 17950.   , 21105.   ,\n",
       "        35056.   , 31400.5  ,  7895.   ,  8189.   ,  7349.   ,  8249.   ,\n",
       "        18280.   ], dtype=float32),\n",
       " (103,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label= df_shuff[:103,25].astype('float32')\n",
    "train_label , train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8778.,  7295., 16695., 14399.,  6938.,  6649., 10698., 13495.,\n",
       "        14489., 12629.,  7395., 10245., 11549.,  7957., 18399.,  6377.,\n",
       "         5499., 11245., 18150., 20970., 36000., 15250.,  9258., 15510.,\n",
       "        11694.,  5572.,  6575.,  8921., 18620.,  9989., 14869.,  6795.,\n",
       "         8358.,  5348., 12940., 18920.,  5572.,  5118.,  5195., 12170.,\n",
       "         5399., 19045., 15690.,  8948., 10345., 32250., 31600., 17450.,\n",
       "         7898.,  6295.,  9639.,  6488., 16925.,  7499., 11048., 23875.,\n",
       "        11850., 15645.,  7295., 13845.,  7898., 11900.], dtype=float32),\n",
       " (62,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label = df_shuff[103:165,25].astype('float32')\n",
    "test_label , test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([15580. ,  9495. , 41315. ,  7975. ,  5151. , 22625. ,  6229. ,\n",
       "         8495. , 15998. ,  9988. , 10295. , 13950. , 16900. ,  6849. ,\n",
       "         6189. ,  8499. ,  6855. ,  8845. , 17075. ,  8238. ,  7738. ,\n",
       "         9279. ,  8949. ,  7609. , 18344. ,  9980. , 34184. , 11595. ,\n",
       "         8449. ,  8916.5, 15040. ,  8921. , 12964. , 12945. , 16630. ,\n",
       "        16558. , 22470. , 10795. , 30760. ,  7129. ], dtype=float32),\n",
       " (40,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label = df_shuff[165:,25].astype('float32')\n",
    "val_label , val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean = np.mean(train_data)\n",
    "std = np.std(train_data)\n",
    "\n",
    "\n",
    "train_data -= mean\n",
    "train_data /= std\n",
    "\n",
    "val_data -= mean\n",
    "val_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.18143256, -0.31152064, -0.21666475, ...,  4.386104  ,\n",
       "         -0.2880325 , -0.28261217],\n",
       "        [-0.19769357, -0.30881047, -0.22298847, ...,  4.6571207 ,\n",
       "         -0.29435623, -0.2871291 ],\n",
       "        [-0.20130712, -0.31061724, -0.22750542, ...,  4.6571207 ,\n",
       "         -0.28351557, -0.27719185],\n",
       "        ...,\n",
       "        [-0.22660203, -0.31061724, -0.2365393 , ...,  4.386104  ,\n",
       "         -0.28351557, -0.27809522],\n",
       "        [-0.22208507, -0.30971384, -0.24828337, ...,  4.386104  ,\n",
       "         -0.28351557, -0.27809522],\n",
       "        [-0.25189692, -0.31152064, -0.2627376 , ...,  4.205426  ,\n",
       "         -0.29435623, -0.2871291 ]], dtype=float32),\n",
       " (103, 25),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data , train_data.shape , type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.17059189, -0.31152064, -0.21034102, ...,  4.0247483 ,\n",
       "         -0.2871291 , -0.28261217],\n",
       "        [-0.2789986 , -0.31152064, -0.27719185, ...,  5.1088157 ,\n",
       "         -0.28441894, -0.28080538],\n",
       "        [-0.20853424, -0.31152064, -0.23473254, ...,  4.205426  ,\n",
       "         -0.29435623, -0.2898393 ],\n",
       "        ...,\n",
       "        [-0.13716649, -0.31152064, -0.18956307, ...,  3.7537315 ,\n",
       "         -0.28170878, -0.27719185],\n",
       "        [-0.16788171, -0.31152064, -0.2031139 , ...,  3.7537315 ,\n",
       "         -0.28080538, -0.2789986 ],\n",
       "        [-0.21395458, -0.31152064, -0.23473254, ...,  4.205426  ,\n",
       "         -0.29435623, -0.2898393 ]], dtype=float32),\n",
       " (62, 25))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data , test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.21034102, -0.31152064, -0.23473254, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.30971384, -0.31152064, -0.21404491,\n",
       "         -0.14285783, -0.2497288 , -0.26029843,  2.4664016 , -0.30971384,\n",
       "         -0.30971384, -0.2031139 , -0.30700368, -0.3083949 , -0.3095422 ,\n",
       "         -0.30393216, -0.22569863,  4.205426  , -0.29435623, -0.2898393 ],\n",
       "        [-0.14168343, -0.30971384, -0.18865967, -0.31152064, -0.31061724,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22362085,\n",
       "         -0.15640867, -0.25234863, -0.26120183,  1.7834393 , -0.30881047,\n",
       "         -0.30971384, -0.22389185, -0.30881047, -0.3088014 , -0.30844912,\n",
       "         -0.29074267, -0.25009015,  3.7537315 , -0.27809522, -0.2735783 ],\n",
       "        [-0.29616302, -0.31152064, -0.2988732 , -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30881047, -0.30971384, -0.31152064, -0.21801983,\n",
       "         -0.13644376, -0.25018048, -0.2630086 ,  2.7419355 , -0.30881047,\n",
       "         -0.30881047, -0.12271225, -0.30700368, -0.30825037, -0.30845812,\n",
       "         -0.3042935 , -0.14710376,  4.566782  , -0.2970664 , -0.29164606],\n",
       "        [-0.14529698, -0.30971384, -0.19408001, -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30881047, -0.31061724, -0.31152064, -0.22362085,\n",
       "         -0.15640867, -0.25234863, -0.26120183,  1.6840664 , -0.30881047,\n",
       "         -0.30971384, -0.21305119, -0.30700368, -0.3086388 , -0.30844912,\n",
       "         -0.30339012, -0.23473254,  4.4312735 , -0.2871291 , -0.28080538],\n",
       "        [-0.29435623, -0.30971384, -0.2898393 , -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30971384, -0.31061724, -0.31152064, -0.231661  ,\n",
       "         -0.18405238, -0.25704625, -0.2634603 ,  1.0327227 , -0.30971384,\n",
       "         -0.30790707, -0.25641388, -0.31061724, -0.30889177, -0.30878335,\n",
       "         -0.30293843, -0.26815793,  4.2957654 , -0.26906133, -0.263641  ],\n",
       "        [-0.1263258 , -0.31242403, -0.18233594, -0.31061724, -0.31061724,\n",
       "         -0.30790707, -0.30881047, -0.30971384, -0.31152064, -0.21296084,\n",
       "         -0.14096071, -0.2492771 , -0.26138252,  2.4546576 , -0.30881047,\n",
       "         -0.30971384, -0.18414272, -0.30700368, -0.30810583, -0.30867496,\n",
       "         -0.30293843, -0.20853424,  4.566782  , -0.29435623, -0.2889359 ],\n",
       "        [-0.2889359 , -0.31061724, -0.28080538, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30971384, -0.31061724, -0.31152064, -0.22687304,\n",
       "         -0.16941747, -0.2538844 , -0.26580912,  1.4654462 , -0.30881047,\n",
       "         -0.30971384, -0.23021558, -0.31061724, -0.30883756, -0.30860266,\n",
       "         -0.30302876, -0.25009015,  4.6571207 , -0.28351557, -0.27719185],\n",
       "        [-0.14258681, -0.30971384, -0.19317663, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22362085,\n",
       "         -0.15640867, -0.25234863, -0.26120183,  1.7436901 , -0.30881047,\n",
       "         -0.30971384, -0.21305119, -0.30700368, -0.3086388 , -0.30844912,\n",
       "         -0.30339012, -0.23473254,  4.4312735 , -0.2871291 , -0.28080538],\n",
       "        [-0.14891054, -0.30881047, -0.2031139 , -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30971384, -0.30971384, -0.31152064, -0.21856187,\n",
       "         -0.14574867, -0.25036114, -0.26454437,  2.4131017 , -0.31152064,\n",
       "         -0.30881047, -0.15704104, -0.30700368, -0.30856657, -0.30849427,\n",
       "         -0.30311912, -0.16607493,  4.386104  , -0.29435623, -0.2898393 ],\n",
       "        [-0.1525241 , -0.31242403, -0.2031139 , -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30971384, -0.31061724, -0.31152064, -0.21901356,\n",
       "         -0.15288545, -0.25144523, -0.26282793,  1.8692613 , -0.30881047,\n",
       "         -0.30971384, -0.20130712, -0.30700368, -0.30853042, -0.30832264,\n",
       "         -0.30366114, -0.22840881,  3.4827147 , -0.2871291 , -0.28261217],\n",
       "        [-0.27448165, -0.31152064, -0.2789986 , -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22434355,\n",
       "         -0.15306614, -0.2550588 , -0.26264727,  1.831319  , -0.30881047,\n",
       "         -0.30971384, -0.2121478 , -0.31152064, -0.30867496, -0.30828652,\n",
       "         -0.30339012, -0.23382914,  4.928138  , -0.2871291 , -0.28170878],\n",
       "        [-0.30790707, -0.30971384, -0.30790707, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22136237,\n",
       "         -0.15198205, -0.25171626, -0.2624666 ,  1.7997003 , -0.30881047,\n",
       "         -0.30971384, -0.21305119, -0.30700368, -0.3086388 , -0.30844912,\n",
       "         -0.30248675, -0.21937491,  4.6571207 , -0.2898393 , -0.28441894],\n",
       "        [-0.20943762, -0.31152064, -0.23202236, -0.31152064, -0.31061724,\n",
       "         -0.30790707, -0.30881047, -0.30971384, -0.31152064, -0.21404491,\n",
       "         -0.14285783, -0.2497288 , -0.26029843,  2.6263015 , -0.30971384,\n",
       "         -0.30971384, -0.17420544, -0.30881047, -0.30817807, -0.3083407 ,\n",
       "         -0.29254946, -0.22569863,  3.4375453 , -0.28622574, -0.28170878],\n",
       "        [-0.22750542, -0.31061724, -0.24286303, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22615033,\n",
       "         -0.16219036, -0.2538844 , -0.26228592,  1.439248  , -0.30881047,\n",
       "         -0.30971384, -0.22389185, -0.31061724, -0.30867496, -0.30854848,\n",
       "         -0.30302876, -0.24918677,  4.386104  , -0.28351557, -0.27809522],\n",
       "        [-0.24105626, -0.30971384, -0.2537037 , -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30971384, -0.31061724, -0.31152064, -0.22687304,\n",
       "         -0.16941747, -0.25334236, -0.26562846,  1.4446683 , -0.30881047,\n",
       "         -0.30971384, -0.22840881, -0.31061724, -0.30883756, -0.30860266,\n",
       "         -0.30302876, -0.25009015,  4.6571207 , -0.28351557, -0.27719185],\n",
       "        [-0.2374427 , -0.30881047, -0.2546071 , -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30971384, -0.31061724, -0.31152064, -0.22452423,\n",
       "         -0.15523426, -0.25243896, -0.2668932 ,  1.7915698 , -0.30881047,\n",
       "         -0.30971384, -0.20130712, -0.31061724, -0.30849427, -0.3083949 ,\n",
       "         -0.30384183, -0.23202236,  4.205426  , -0.2889359 , -0.28261217],\n",
       "        [-0.28261217, -0.30971384, -0.2726749 , -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30971384, -0.31061724, -0.31152064, -0.2332871 ,\n",
       "         -0.18089052, -0.25379404, -0.26562846,  1.3317446 , -0.30881047,\n",
       "         -0.30971384, -0.22840881, -0.31152064, -0.30889177, -0.30844006,\n",
       "         -0.30320942, -0.24286303,  5.1088157 , -0.28351557, -0.27719185],\n",
       "        [-0.27538505, -0.31152064, -0.2717715 , -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22434355,\n",
       "         -0.15306614, -0.25261962, -0.26264727,  1.7698885 , -0.30881047,\n",
       "         -0.30971384, -0.2121478 , -0.31152064, -0.30867496, -0.30828652,\n",
       "         -0.30339012, -0.23382914,  4.928138  , -0.2871291 , -0.28170878],\n",
       "        [-0.20763084, -0.31152064, -0.23292576, -0.31152064, -0.31061724,\n",
       "         -0.30790707, -0.30790707, -0.30971384, -0.31152064, -0.20835356,\n",
       "         -0.13183649, -0.2497288 , -0.25849167,  2.8367913 , -0.30971384,\n",
       "         -0.30971384, -0.17420544, -0.30881047, -0.30817807, -0.3083407 ,\n",
       "         -0.29254946, -0.22569863,  3.4375453 , -0.2889359 , -0.2889359 ],\n",
       "        [-0.16246139, -0.31061724, -0.2031139 , -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30971384, -0.30971384, -0.31152064, -0.22615033,\n",
       "         -0.15911885, -0.2537037 , -0.26400235,  1.6795496 , -0.30881047,\n",
       "         -0.30971384, -0.22298847, -0.31061724, -0.3086388 , -0.30878335,\n",
       "         -0.30339012, -0.24828337,  4.0247483 , -0.28532234, -0.28080538],\n",
       "        [-0.16607493, -0.31152064, -0.2031139 , -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22506627,\n",
       "         -0.16128697, -0.25334236, -0.263641  ,  1.5801767 , -0.30881047,\n",
       "         -0.30971384, -0.22298847, -0.31061724, -0.3086388 , -0.30878335,\n",
       "         -0.30339012, -0.24828337,  4.0247483 , -0.27719185, -0.26906133],\n",
       "        [-0.23111898, -0.31242403, -0.25189692, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22452423,\n",
       "         -0.1557763 , -0.25243896, -0.26490572,  1.859324  , -0.30881047,\n",
       "         -0.30971384, -0.2121478 , -0.30610028, -0.30865687, -0.3083949 ,\n",
       "         -0.3047452 , -0.20672746,  4.6571207 , -0.29074267, -0.28441894],\n",
       "        [-0.22118169, -0.31152064, -0.23834608, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30971384, -0.31061724, -0.31152064, -0.22371118,\n",
       "         -0.15487291, -0.25261962, -0.26210523,  1.7879562 , -0.30881047,\n",
       "         -0.30971384, -0.2031139 , -0.31061724, -0.30851236, -0.30838588,\n",
       "         -0.30384183, -0.22389185,  4.386104  , -0.2871291 , -0.28080538],\n",
       "        [-0.2871291 , -0.31061724, -0.28622574, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22687304,\n",
       "         -0.16941747, -0.2538844 , -0.26580912,  1.4853208 , -0.30881047,\n",
       "         -0.30971384, -0.23021558, -0.31061724, -0.30883756, -0.30860266,\n",
       "         -0.30302876, -0.25009015,  4.6571207 , -0.28351557, -0.27719185],\n",
       "        [-0.25099355, -0.31152064, -0.25731727, -0.31152064, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.30971384, -0.31152064, -0.21675509,\n",
       "         -0.15342748, -0.2518066 , -0.26237625,  2.1276307 , -0.30881047,\n",
       "         -0.30971384, -0.19046645, -0.30881047, -0.308422  , -0.30823228,\n",
       "         -0.29164606, -0.24647659,  3.4827147 , -0.28351557, -0.27628845],\n",
       "        [-0.13897325, -0.30881047, -0.17962578, -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30971384, -0.31061724, -0.31152064, -0.22615033,\n",
       "         -0.16182901, -0.2537037 , -0.2650864 ,  1.6949072 , -0.30881047,\n",
       "         -0.30971384, -0.21305119, -0.30700368, -0.3086388 , -0.30844912,\n",
       "         -0.30384183, -0.23021558,  4.6571207 , -0.2898393 , -0.28532234],\n",
       "        [-0.24647659, -0.31242403, -0.29345283, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.30971384, -0.31152064, -0.20708881,\n",
       "         -0.12849393, -0.2467476 , -0.26047912,  3.0671556 , -0.30700368,\n",
       "         -0.31152064, -0.10012751, -0.30700368, -0.3083949 , -0.3087201 ,\n",
       "         -0.30402252, -0.17149527,  3.979579  , -0.2970664 , -0.29525962],\n",
       "        [-0.13987665, -0.30881047, -0.18052916, -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.31152064, -0.31061724, -0.31152064, -0.22615033,\n",
       "         -0.1676107 , -0.25352302, -0.26129216,  1.724719  , -0.30881047,\n",
       "         -0.30971384, -0.21305119, -0.30700368, -0.3086388 , -0.30844912,\n",
       "         -0.30384183, -0.23021558,  4.6571207 , -0.2898393 , -0.28532234],\n",
       "        [-0.1597512 , -0.30971384, -0.20130712, -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.31061724, -0.30971384, -0.31152064, -0.22262712,\n",
       "         -0.15234342, -0.25225827, -0.26454437,  1.9830884 , -0.30881047,\n",
       "         -0.30971384, -0.17962578, -0.30700368, -0.30825037, -0.30835876,\n",
       "         -0.30311912, -0.20672746,  4.0247483 , -0.2898393 , -0.28441894],\n",
       "        [-0.26996472, -0.31152064, -0.26996472, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22615033,\n",
       "         -0.17068224, -0.25406507, -0.26454437,  1.4130497 , -0.30881047,\n",
       "         -0.30971384, -0.23021558, -0.31061724, -0.30878335, -0.3087111 ,\n",
       "         -0.3028481 , -0.24828337,  4.566782  , -0.27719185, -0.2726749 ],\n",
       "        [-0.18956307, -0.30881047, -0.21847153, -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30971384, -0.31061724, -0.31152064, -0.22199474,\n",
       "         -0.14294817, -0.25144523, -0.26084048,  2.1339543 , -0.30881047,\n",
       "         -0.30971384, -0.20221052, -0.30700368, -0.309226  , -0.3096506 ,\n",
       "         -0.30311912, -0.2121478 ,  4.4312735 , -0.29254946, -0.28622574],\n",
       "        [-0.28532234, -0.31242403, -0.28170878, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30790707, -0.31061724, -0.31152064, -0.2182005 ,\n",
       "         -0.15378883, -0.25316167, -0.25749797,  1.9785714 , -0.30881047,\n",
       "         -0.30971384, -0.20130712, -0.31061724, -0.3085033 , -0.3083949 ,\n",
       "         -0.30384183, -0.23202236,  4.205426  , -0.2898393 , -0.28441894],\n",
       "        [-0.28441894, -0.30881047, -0.28351557, -0.31061724, -0.31061724,\n",
       "         -0.30971384, -0.30971384, -0.31061724, -0.31152064, -0.2248856 ,\n",
       "         -0.15505359, -0.25162593, -0.26617047,  2.227907  , -0.30881047,\n",
       "         -0.30971384, -0.17059189, -0.30790707, -0.30826843, -0.3079974 ,\n",
       "         -0.3051969 , -0.18052916,  4.205426  , -0.29435623, -0.2898393 ],\n",
       "        [-0.2735783 , -0.31152064, -0.27628845, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22434355,\n",
       "         -0.15306614, -0.25261962, -0.26264727,  1.9153341 , -0.30881047,\n",
       "         -0.30971384, -0.2121478 , -0.30700368, -0.30867496, -0.30828652,\n",
       "         -0.30339012, -0.22027831,  4.928138  , -0.2898393 , -0.28622574],\n",
       "        [-0.20672746, -0.31152064, -0.23473254, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.30971384, -0.31152064, -0.21404491,\n",
       "         -0.14285783, -0.2497288 , -0.26029843,  2.4664016 , -0.30971384,\n",
       "         -0.30971384, -0.2031139 , -0.30700368, -0.3083949 , -0.3086388 ,\n",
       "         -0.30393216, -0.22389185,  4.205426  , -0.29435623, -0.2898393 ],\n",
       "        [-0.14981394, -0.30881047, -0.20492068, -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30971384, -0.30971384, -0.31152064, -0.21856187,\n",
       "         -0.14574867, -0.25036114, -0.26454437,  2.3769662 , -0.31152064,\n",
       "         -0.30881047, -0.15704104, -0.30700368, -0.30856657, -0.30849427,\n",
       "         -0.30311912, -0.16607493,  4.386104  , -0.29345283, -0.2898393 ],\n",
       "        [-0.1272292 , -0.31242403, -0.18323934, -0.31152064, -0.31061724,\n",
       "         -0.30790707, -0.30881047, -0.30971384, -0.31152064, -0.21296084,\n",
       "         -0.14096071, -0.2492771 , -0.26138252,  2.594683  , -0.30881047,\n",
       "         -0.30881047, -0.18052916, -0.30881047, -0.3088014 , -0.30844912,\n",
       "         -0.29074267, -0.21576135,  4.0247483 , -0.2880325 , -0.2871291 ],\n",
       "        [-0.2537037 , -0.31152064, -0.25912404, -0.31152064, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.31061724, -0.31152064, -0.22226575,\n",
       "         -0.150898  , -0.25144523, -0.26138252,  1.8954595 , -0.30881047,\n",
       "         -0.30971384, -0.20130712, -0.30881047, -0.30845812, -0.30845812,\n",
       "         -0.2910137 , -0.2537037 ,  3.88924   , -0.2789986 , -0.2735783 ],\n",
       "        [-0.2970664 , -0.31152064, -0.29977655, -0.31061724, -0.31152064,\n",
       "         -0.30790707, -0.30881047, -0.30971384, -0.31152064, -0.21801983,\n",
       "         -0.14078003, -0.25108388, -0.26120183,  2.606427  , -0.30881047,\n",
       "         -0.30881047, -0.12271225, -0.30700368, -0.30825037, -0.30845812,\n",
       "         -0.3042935 , -0.14710376,  4.566782  , -0.2970664 , -0.29164606],\n",
       "        [-0.279902  , -0.31061724, -0.2726749 , -0.31061724, -0.31152064,\n",
       "         -0.30971384, -0.30971384, -0.31061724, -0.31152064, -0.22687304,\n",
       "         -0.17601222, -0.2537037 , -0.26400235,  1.455509  , -0.30881047,\n",
       "         -0.30971384, -0.22840881, -0.31152064, -0.30889177, -0.30844006,\n",
       "         -0.30320942, -0.24286303,  5.1088157 , -0.28441894, -0.28080538]],\n",
       "       dtype=float32),\n",
       " (40, 25))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data , val_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation='relu',input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(8, activation='relu'))\n",
    "    model.add(layers.Dense(6, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5524.94775390625"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for no activation, relu for others\n",
    "model = build_model()\n",
    "model.fit(train_data, train_label,epochs=100, batch_size=1, verbose=0)\n",
    "val_mse, val_mae = model.evaluate(val_data, val_label, verbose=0)\n",
    "val_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the price is off by a margin of 2298$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation (as the data is very small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, (102, 25), (102,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_shuff[103:,:25].astype('float32')\n",
    "y = df_shuff[103:,25].astype('float32')\n",
    "k = 3\n",
    "num_val_samples = len(x) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "num_val_samples , x.shape , y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 159145184.0000 - mae: 10233.6924 - val_loss: 100238968.0000 - val_mae: 8091.9531\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 116971360.0000 - mae: 7968.4946 - val_loss: 62426572.0000 - val_mae: 5517.5420\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 79985848.0000 - mae: 5871.3809 - val_loss: 40535648.0000 - val_mae: 4287.9790\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 59326552.0000 - mae: 5009.2295 - val_loss: 32056528.0000 - val_mae: 3974.4978\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 52382992.0000 - mae: 4969.0586 - val_loss: 30738540.0000 - val_mae: 3990.3848\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 50905412.0000 - mae: 5066.7158 - val_loss: 30685452.0000 - val_mae: 4044.3464\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 49986440.0000 - mae: 5168.4805 - val_loss: 30474028.0000 - val_mae: 4012.6145\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 50078572.0000 - mae: 5110.9360 - val_loss: 30358902.0000 - val_mae: 4019.7739\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 49722932.0000 - mae: 5051.5605 - val_loss: 30193230.0000 - val_mae: 4001.6687\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 49780000.0000 - mae: 5017.7012 - val_loss: 30267084.0000 - val_mae: 4064.3953\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 49351760.0000 - mae: 5087.8169 - val_loss: 29959926.0000 - val_mae: 4014.5413\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 49426780.0000 - mae: 4982.2998 - val_loss: 30020048.0000 - val_mae: 4057.0010\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 48518160.0000 - mae: 5101.7295 - val_loss: 29740144.0000 - val_mae: 4017.1787\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 48353164.0000 - mae: 5087.7324 - val_loss: 29489782.0000 - val_mae: 3985.6499\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 48275088.0000 - mae: 5012.4170 - val_loss: 29609812.0000 - val_mae: 4043.9521\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 47430556.0000 - mae: 5119.6562 - val_loss: 29141920.0000 - val_mae: 3957.8792\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 48342284.0000 - mae: 4908.9272 - val_loss: 29168272.0000 - val_mae: 3994.7427\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47757976.0000 - mae: 4971.1958 - val_loss: 29090874.0000 - val_mae: 4001.5869\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47417552.0000 - mae: 4967.0039 - val_loss: 29091084.0000 - val_mae: 4023.7854\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46987464.0000 - mae: 5035.3584 - val_loss: 28544572.0000 - val_mae: 3921.2417\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 46794556.0000 - mae: 5005.2349 - val_loss: 28385888.0000 - val_mae: 3913.2021\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46625820.0000 - mae: 4979.2622 - val_loss: 28295210.0000 - val_mae: 3925.4573\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46287448.0000 - mae: 4983.0103 - val_loss: 28315944.0000 - val_mae: 3961.8281\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45886260.0000 - mae: 4991.7295 - val_loss: 27991044.0000 - val_mae: 3911.3850\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45961496.0000 - mae: 4898.4912 - val_loss: 27766818.0000 - val_mae: 3883.0256\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45244772.0000 - mae: 4934.1602 - val_loss: 27689828.0000 - val_mae: 3899.1172\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45313704.0000 - mae: 4923.1260 - val_loss: 27485292.0000 - val_mae: 3879.0598\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45205988.0000 - mae: 4878.5107 - val_loss: 27278396.0000 - val_mae: 3857.3965\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44516000.0000 - mae: 4928.2930 - val_loss: 26939232.0000 - val_mae: 3776.1013\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44882168.0000 - mae: 4851.3877 - val_loss: 26947692.0000 - val_mae: 3837.3291\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44425588.0000 - mae: 4811.8638 - val_loss: 27102494.0000 - val_mae: 3911.1406\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44013468.0000 - mae: 4859.6895 - val_loss: 26586604.0000 - val_mae: 3810.0159\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43625392.0000 - mae: 4879.2778 - val_loss: 26397632.0000 - val_mae: 3788.3762\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43725472.0000 - mae: 4818.0713 - val_loss: 26504294.0000 - val_mae: 3858.8572\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43609048.0000 - mae: 4701.3696 - val_loss: 26567126.0000 - val_mae: 3893.8069\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42499040.0000 - mae: 4834.7437 - val_loss: 25782610.0000 - val_mae: 3702.5732\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43261944.0000 - mae: 4704.9150 - val_loss: 25905434.0000 - val_mae: 3798.2595\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42548424.0000 - mae: 4729.8276 - val_loss: 25981512.0000 - val_mae: 3844.5652\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42061988.0000 - mae: 4787.9199 - val_loss: 25480296.0000 - val_mae: 3755.9375\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42077812.0000 - mae: 4750.0210 - val_loss: 25201980.0000 - val_mae: 3708.4690\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42006944.0000 - mae: 4686.1240 - val_loss: 25261360.0000 - val_mae: 3768.2605\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41299792.0000 - mae: 4768.5254 - val_loss: 24864556.0000 - val_mae: 3691.7446\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41921148.0000 - mae: 4588.8638 - val_loss: 24868328.0000 - val_mae: 3732.7834\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41147696.0000 - mae: 4663.4492 - val_loss: 24542258.0000 - val_mae: 3673.6003\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41064772.0000 - mae: 4633.4341 - val_loss: 24659496.0000 - val_mae: 3742.5613\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40626448.0000 - mae: 4631.6426 - val_loss: 24569986.0000 - val_mae: 3750.5061\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40198108.0000 - mae: 4677.9121 - val_loss: 24349182.0000 - val_mae: 3731.7319\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39779684.0000 - mae: 4650.3301 - val_loss: 23916696.0000 - val_mae: 3665.5222\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39527944.0000 - mae: 4611.9854 - val_loss: 23573872.0000 - val_mae: 3606.8079\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39346616.0000 - mae: 4611.7329 - val_loss: 23377520.0000 - val_mae: 3593.6548\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39138848.0000 - mae: 4515.2344 - val_loss: 23139414.0000 - val_mae: 3562.1777\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39079476.0000 - mae: 4475.6489 - val_loss: 23311432.0000 - val_mae: 3652.9780\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38405092.0000 - mae: 4549.9497 - val_loss: 22986360.0000 - val_mae: 3609.7529\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 16541903.0000 - mae: 4067.173 - 0s 1ms/step - loss: 38320616.0000 - mae: 4531.7832 - val_loss: 22877650.0000 - val_mae: 3615.3623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37750092.0000 - mae: 4469.7695 - val_loss: 22738370.0000 - val_mae: 3614.5745\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37135448.0000 - mae: 4473.6567 - val_loss: 22189208.0000 - val_mae: 3511.4331\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37626656.0000 - mae: 4215.5303 - val_loss: 22496572.0000 - val_mae: 3611.2874\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36674556.0000 - mae: 4459.1665 - val_loss: 22052778.0000 - val_mae: 3546.8953\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36336332.0000 - mae: 4461.3999 - val_loss: 21581838.0000 - val_mae: 3459.3142\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36652468.0000 - mae: 4228.1533 - val_loss: 21986430.0000 - val_mae: 3589.8254\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36167072.0000 - mae: 4380.6548 - val_loss: 21695786.0000 - val_mae: 3559.3364\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 35725072.0000 - mae: 4394.8735 - val_loss: 21411722.0000 - val_mae: 3531.8972\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 35232204.0000 - mae: 4349.5991 - val_loss: 20772874.0000 - val_mae: 3419.2629\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 35265944.0000 - mae: 4260.9121 - val_loss: 20572976.0000 - val_mae: 3409.3457\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34958360.0000 - mae: 4231.2534 - val_loss: 20762288.0000 - val_mae: 3495.7080\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34005444.0000 - mae: 4307.6030 - val_loss: 20030488.0000 - val_mae: 3346.3821\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34426856.0000 - mae: 4196.5278 - val_loss: 19924758.0000 - val_mae: 3362.7119\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34048084.0000 - mae: 4151.0156 - val_loss: 19828544.0000 - val_mae: 3384.0962\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33794628.0000 - mae: 4086.1614 - val_loss: 19842682.0000 - val_mae: 3431.5117\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32969622.0000 - mae: 4169.2778 - val_loss: 19389648.0000 - val_mae: 3359.5181\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32751296.0000 - mae: 4145.1802 - val_loss: 19000554.0000 - val_mae: 3303.4482\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32192538.0000 - mae: 4070.7000 - val_loss: 18654856.0000 - val_mae: 3251.4019\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32085252.0000 - mae: 4036.5881 - val_loss: 18637736.0000 - val_mae: 3303.0718\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31477478.0000 - mae: 4054.9277 - val_loss: 18555166.0000 - val_mae: 3335.5254\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31173110.0000 - mae: 4019.9751 - val_loss: 18101944.0000 - val_mae: 3256.0957\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29904390.0000 - mae: 4021.1853 - val_loss: 17430096.0000 - val_mae: 3060.0645\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30984306.0000 - mae: 3932.8245 - val_loss: 17275014.0000 - val_mae: 3094.4099\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30521218.0000 - mae: 3873.2651 - val_loss: 17500182.0000 - val_mae: 3247.9280\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29664098.0000 - mae: 3893.0171 - val_loss: 17193216.0000 - val_mae: 3217.6685\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29082520.0000 - mae: 3884.8989 - val_loss: 16888790.0000 - val_mae: 3187.6772\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 28715212.0000 - mae: 3855.0195 - val_loss: 16398946.0000 - val_mae: 3091.1035\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 28654216.0000 - mae: 3727.1826 - val_loss: 16443861.0000 - val_mae: 3175.1606\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27375560.0000 - mae: 3854.8201 - val_loss: 15610280.0000 - val_mae: 2920.3816\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27973506.0000 - mae: 3695.7012 - val_loss: 15539944.0000 - val_mae: 3006.3923\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27011210.0000 - mae: 3730.2607 - val_loss: 15111354.0000 - val_mae: 2907.2019\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27205078.0000 - mae: 3577.9370 - val_loss: 15321954.0000 - val_mae: 3078.6436\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26236656.0000 - mae: 3662.2295 - val_loss: 15010161.0000 - val_mae: 3050.5417\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25741734.0000 - mae: 3652.7361 - val_loss: 14697916.0000 - val_mae: 3026.5491\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25494682.0000 - mae: 3499.4551 - val_loss: 14203112.0000 - val_mae: 2934.7231\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24881398.0000 - mae: 3558.1533 - val_loss: 14052349.0000 - val_mae: 2960.7915\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24530902.0000 - mae: 3488.5654 - val_loss: 13942710.0000 - val_mae: 2998.5945\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24132956.0000 - mae: 3400.9592 - val_loss: 13903638.0000 - val_mae: 3044.1287\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23118614.0000 - mae: 3515.2932 - val_loss: 13023607.0000 - val_mae: 2835.9285\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23082284.0000 - mae: 3303.6331 - val_loss: 13414607.0000 - val_mae: 3014.4199\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 22470930.0000 - mae: 3409.0813 - val_loss: 12900189.0000 - val_mae: 2927.2334\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 22109218.0000 - mae: 3318.1331 - val_loss: 12907146.0000 - val_mae: 2973.8577\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20813872.0000 - mae: 3383.1204 - val_loss: 11494556.0000 - val_mae: 2527.0100\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 21364432.0000 - mae: 3235.6936 - val_loss: 11440785.0000 - val_mae: 2641.5042\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20987592.0000 - mae: 3174.7898 - val_loss: 11411437.0000 - val_mae: 2704.8723\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20377902.0000 - mae: 3172.9829 - val_loss: 11725709.0000 - val_mae: 2837.3345\n",
      "processing fold # 1\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 172481104.0000 - mae: 11585.3359 - val_loss: 219763584.0000 - val_mae: 12164.3525\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 131582768.0000 - mae: 9632.6348 - val_loss: 163314848.0000 - val_mae: 9606.4980\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 85266496.0000 - mae: 6638.7617 - val_loss: 107910504.0000 - val_mae: 6929.4360\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 51376492.0000 - mae: 4746.7979 - val_loss: 80520536.0000 - val_mae: 5895.7744\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42167860.0000 - mae: 4511.0527 - val_loss: 72918392.0000 - val_mae: 5688.7417\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39166680.0000 - mae: 4516.3594 - val_loss: 68637424.0000 - val_mae: 5688.5039\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39344260.0000 - mae: 4536.1396 - val_loss: 69067848.0000 - val_mae: 5639.8320\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38654360.0000 - mae: 4456.2935 - val_loss: 68371504.0000 - val_mae: 5636.0259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38387208.0000 - mae: 4547.1035 - val_loss: 68329048.0000 - val_mae: 5600.4238\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37943648.0000 - mae: 4508.0371 - val_loss: 69027712.0000 - val_mae: 5572.3115\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38419868.0000 - mae: 4403.7275 - val_loss: 68294424.0000 - val_mae: 5554.9575\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37928788.0000 - mae: 4374.5698 - val_loss: 66405016.0000 - val_mae: 5579.8955\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37224852.0000 - mae: 4416.7627 - val_loss: 67124816.0000 - val_mae: 5521.0356\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37077592.0000 - mae: 4378.2695 - val_loss: 65979836.0000 - val_mae: 5525.1055\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36584296.0000 - mae: 4367.9194 - val_loss: 64879232.0000 - val_mae: 5540.8262\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36238776.0000 - mae: 4376.9727 - val_loss: 64686524.0000 - val_mae: 5502.8062\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36099904.0000 - mae: 4321.6650 - val_loss: 64563616.0000 - val_mae: 5464.3711\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 35581112.0000 - mae: 4315.2021 - val_loss: 64646052.0000 - val_mae: 5425.7998\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 35517168.0000 - mae: 4249.9438 - val_loss: 64493336.0000 - val_mae: 5395.7695\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34958548.0000 - mae: 4280.3730 - val_loss: 63781692.0000 - val_mae: 5379.3062\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34742880.0000 - mae: 4220.1294 - val_loss: 63213056.0000 - val_mae: 5360.8535\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34004308.0000 - mae: 4205.2114 - val_loss: 61223148.0000 - val_mae: 5416.2075\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34012108.0000 - mae: 4141.5693 - val_loss: 60542488.0000 - val_mae: 5412.9604\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33436044.0000 - mae: 4179.9653 - val_loss: 59940804.0000 - val_mae: 5389.9575\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32926698.0000 - mae: 4170.9419 - val_loss: 59725884.0000 - val_mae: 5342.2939\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32553690.0000 - mae: 4112.7417 - val_loss: 60008148.0000 - val_mae: 5272.4072\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32408260.0000 - mae: 4028.4316 - val_loss: 58757736.0000 - val_mae: 5282.9736\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31845030.0000 - mae: 4029.4587 - val_loss: 58392732.0000 - val_mae: 5251.0762\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31327590.0000 - mae: 3994.2058 - val_loss: 59392352.0000 - val_mae: 5139.5977\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31172820.0000 - mae: 3943.3110 - val_loss: 57351692.0000 - val_mae: 5184.2935\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30588728.0000 - mae: 3960.8374 - val_loss: 56543880.0000 - val_mae: 5166.7065\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29812012.0000 - mae: 3865.6895 - val_loss: 54905136.0000 - val_mae: 5203.1855\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29722902.0000 - mae: 3858.6011 - val_loss: 55053080.0000 - val_mae: 5101.4639\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29362796.0000 - mae: 3843.1233 - val_loss: 55074548.0000 - val_mae: 5033.9268\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 28643182.0000 - mae: 3804.1855 - val_loss: 54879120.0000 - val_mae: 4974.5391\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 28243678.0000 - mae: 3756.1963 - val_loss: 54349704.0000 - val_mae: 4928.6738\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 28084840.0000 - mae: 3681.6179 - val_loss: 54004632.0000 - val_mae: 4884.8975\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27832288.0000 - mae: 3597.5039 - val_loss: 52889128.0000 - val_mae: 4880.9365\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26908456.0000 - mae: 3637.4712 - val_loss: 52329440.0000 - val_mae: 4835.8770\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26505784.0000 - mae: 3617.9268 - val_loss: 50975216.0000 - val_mae: 4824.7300\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25751388.0000 - mae: 3580.2322 - val_loss: 49629000.0000 - val_mae: 4823.7866\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25223094.0000 - mae: 3516.2124 - val_loss: 48627356.0000 - val_mae: 4795.7051\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24552914.0000 - mae: 3509.4753 - val_loss: 48179956.0000 - val_mae: 4724.0518\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23607568.0000 - mae: 3468.5403 - val_loss: 49775568.0000 - val_mae: 4551.4448\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24271162.0000 - mae: 3265.6753 - val_loss: 47784112.0000 - val_mae: 4573.0820\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23115058.0000 - mae: 3310.0518 - val_loss: 46114636.0000 - val_mae: 4561.7461\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 22057638.0000 - mae: 3283.2151 - val_loss: 45435668.0000 - val_mae: 4477.1523\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 21728468.0000 - mae: 3207.2021 - val_loss: 44717636.0000 - val_mae: 4415.9287\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 21609282.0000 - mae: 3113.7759 - val_loss: 42388060.0000 - val_mae: 4465.1787\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20747888.0000 - mae: 3152.9692 - val_loss: 42375972.0000 - val_mae: 4361.5977\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20650356.0000 - mae: 2993.7625 - val_loss: 41611332.0000 - val_mae: 4321.0723\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 19848558.0000 - mae: 3011.3254 - val_loss: 40755596.0000 - val_mae: 4270.9375\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 19297768.0000 - mae: 2910.8564 - val_loss: 39482012.0000 - val_mae: 4251.1582\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 18288376.0000 - mae: 2946.1458 - val_loss: 40171908.0000 - val_mae: 4070.6157\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 17835030.0000 - mae: 2727.4285 - val_loss: 39944108.0000 - val_mae: 3981.9448\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 17204700.0000 - mae: 2766.8206 - val_loss: 42133736.0000 - val_mae: 3891.0491\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 16548614.0000 - mae: 2763.1201 - val_loss: 35873824.0000 - val_mae: 4000.4021\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 16452915.0000 - mae: 2664.2959 - val_loss: 34696432.0000 - val_mae: 3982.6807\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 15526791.0000 - mae: 2753.6599 - val_loss: 37167332.0000 - val_mae: 3721.8997\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 15870157.0000 - mae: 2560.9883 - val_loss: 32985454.0000 - val_mae: 3879.6614\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 15274669.0000 - mae: 2615.0996 - val_loss: 33119428.0000 - val_mae: 3745.2234\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14746082.0000 - mae: 2588.0613 - val_loss: 34044280.0000 - val_mae: 3600.5762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14442698.0000 - mae: 2522.8271 - val_loss: 33540442.0000 - val_mae: 3537.2485\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14008694.0000 - mae: 2462.1379 - val_loss: 30054874.0000 - val_mae: 3797.4961\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13367699.0000 - mae: 2411.4060 - val_loss: 29836890.0000 - val_mae: 3559.2322\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12955096.0000 - mae: 2462.0466 - val_loss: 32254750.0000 - val_mae: 3395.8726\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12741272.0000 - mae: 2406.5486 - val_loss: 29597116.0000 - val_mae: 3405.6313\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12579096.0000 - mae: 2343.8733 - val_loss: 29646752.0000 - val_mae: 3356.5859\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12453219.0000 - mae: 2315.3811 - val_loss: 27098134.0000 - val_mae: 3507.6663\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12428035.0000 - mae: 2398.7246 - val_loss: 26877870.0000 - val_mae: 3422.9561\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12120772.0000 - mae: 2364.5391 - val_loss: 27781262.0000 - val_mae: 3281.6536\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12101938.0000 - mae: 2300.3379 - val_loss: 27400708.0000 - val_mae: 3252.7812\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11362777.0000 - mae: 2300.7839 - val_loss: 28219272.0000 - val_mae: 3213.7351\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11430011.0000 - mae: 2372.1069 - val_loss: 27727272.0000 - val_mae: 3190.9026\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10899908.0000 - mae: 2293.9341 - val_loss: 26287078.0000 - val_mae: 3182.9539\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11399369.0000 - mae: 2308.6814 - val_loss: 24583650.0000 - val_mae: 3264.6182\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11087714.0000 - mae: 2213.6816 - val_loss: 23624020.0000 - val_mae: 3402.4492\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11050113.0000 - mae: 2320.2163 - val_loss: 25707090.0000 - val_mae: 3119.2043\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10732501.0000 - mae: 2211.3755 - val_loss: 26068596.0000 - val_mae: 3107.8896\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11002486.0000 - mae: 2266.3640 - val_loss: 23820042.0000 - val_mae: 3144.9956\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10390042.0000 - mae: 2258.9824 - val_loss: 22424016.0000 - val_mae: 3387.8921\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10392574.0000 - mae: 2204.1282 - val_loss: 22006172.0000 - val_mae: 3307.8455\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10754505.0000 - mae: 2284.5200 - val_loss: 21984942.0000 - val_mae: 3323.1663\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10592719.0000 - mae: 2255.5430 - val_loss: 23162842.0000 - val_mae: 3047.2903\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10475852.0000 - mae: 2227.2380 - val_loss: 22238992.0000 - val_mae: 3104.1292\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10617942.0000 - mae: 2272.7302 - val_loss: 22871274.0000 - val_mae: 3031.5413\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10125978.0000 - mae: 2264.5417 - val_loss: 24766432.0000 - val_mae: 3009.0403\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10591560.0000 - mae: 2202.5540 - val_loss: 21881930.0000 - val_mae: 3038.8391\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10377667.0000 - mae: 2238.7292 - val_loss: 24274300.0000 - val_mae: 2979.3394\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10552817.0000 - mae: 2198.0010 - val_loss: 24365194.0000 - val_mae: 2973.1406\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10533583.0000 - mae: 2181.8457 - val_loss: 22495162.0000 - val_mae: 2979.3508\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9974968.0000 - mae: 2297.4512 - val_loss: 26310066.0000 - val_mae: 3065.5129\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9941548.0000 - mae: 2284.6108 - val_loss: 23238562.0000 - val_mae: 2933.9397\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10311547.0000 - mae: 2266.3040 - val_loss: 23154990.0000 - val_mae: 2922.2271\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9812359.0000 - mae: 2133.4995 - val_loss: 20620168.0000 - val_mae: 2962.8547\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9907947.0000 - mae: 2256.1787 - val_loss: 21486976.0000 - val_mae: 2906.8533\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9754727.0000 - mae: 2195.1895 - val_loss: 20375944.0000 - val_mae: 2969.6345\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9541739.0000 - mae: 2238.5867 - val_loss: 19632490.0000 - val_mae: 3163.0269\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9985079.0000 - mae: 2170.0781 - val_loss: 21273396.0000 - val_mae: 2865.2480\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9966227.0000 - mae: 2236.3286 - val_loss: 21600386.0000 - val_mae: 2846.7410\n",
      "processing fold # 2\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 215330800.0000 - mae: 12681.9219 - val_loss: 192274832.0000 - val_mae: 12288.5703\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 207805424.0000 - mae: 12374.3496 - val_loss: 183766752.0000 - val_mae: 11932.6152\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 195653968.0000 - mae: 11879.3828 - val_loss: 168292848.0000 - val_mae: 11260.2109\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 176783520.0000 - mae: 11030.1719 - val_loss: 144845584.0000 - val_mae: 10168.6562\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 146853424.0000 - mae: 9667.1709 - val_loss: 114278960.0000 - val_mae: 8540.0459\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 112515320.0000 - mae: 7784.0356 - val_loss: 81606960.0000 - val_mae: 6356.0571\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 84560792.0000 - mae: 6132.5977 - val_loss: 59528352.0000 - val_mae: 4845.6992\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 63469592.0000 - mae: 5071.2300 - val_loss: 45397984.0000 - val_mae: 4468.5835\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 53195344.0000 - mae: 4925.0098 - val_loss: 41525984.0000 - val_mae: 4566.1606\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 50257464.0000 - mae: 4876.5679 - val_loss: 40629900.0000 - val_mae: 4686.9990\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 49709308.0000 - mae: 4860.2124 - val_loss: 40388472.0000 - val_mae: 4744.0664\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 49197452.0000 - mae: 4924.1816 - val_loss: 40236872.0000 - val_mae: 4729.3882\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 49216404.0000 - mae: 4877.6787 - val_loss: 40068680.0000 - val_mae: 4769.4224\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 48710240.0000 - mae: 4946.1567 - val_loss: 39924328.0000 - val_mae: 4752.4810\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 48747704.0000 - mae: 4901.9385 - val_loss: 39788560.0000 - val_mae: 4775.3130\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47918816.0000 - mae: 4991.6777 - val_loss: 39681384.0000 - val_mae: 4700.6851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 48521344.0000 - mae: 4876.0054 - val_loss: 39526464.0000 - val_mae: 4750.5049\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 48550440.0000 - mae: 4867.162 - 0s 1ms/step - loss: 48550440.0000 - mae: 4867.1626 - val_loss: 39395580.0000 - val_mae: 4732.3145\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47797232.0000 - mae: 4920.4087 - val_loss: 39299004.0000 - val_mae: 4674.0991\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 48090248.0000 - mae: 4867.2290 - val_loss: 39136552.0000 - val_mae: 4708.9653\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47709088.0000 - mae: 4901.3120 - val_loss: 39008320.0000 - val_mae: 4712.8442\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47566612.0000 - mae: 4896.6187 - val_loss: 38885960.0000 - val_mae: 4722.3716\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47645612.0000 - mae: 4816.4858 - val_loss: 38777464.0000 - val_mae: 4734.9727\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47262412.0000 - mae: 4851.1299 - val_loss: 38620412.0000 - val_mae: 4705.6987\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47084048.0000 - mae: 4863.7407 - val_loss: 38480152.0000 - val_mae: 4666.7476\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46897880.0000 - mae: 4899.9360 - val_loss: 38364672.0000 - val_mae: 4627.6050\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46889816.0000 - mae: 4808.8306 - val_loss: 38231904.0000 - val_mae: 4678.5127\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46673376.0000 - mae: 4857.5107 - val_loss: 38095360.0000 - val_mae: 4625.3916\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46752416.0000 - mae: 4783.5132 - val_loss: 37971868.0000 - val_mae: 4615.7803\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46028580.0000 - mae: 4866.3735 - val_loss: 37926668.0000 - val_mae: 4541.8477\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46873216.0000 - mae: 4723.6870 - val_loss: 37743352.0000 - val_mae: 4582.3691\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46170464.0000 - mae: 4801.1943 - val_loss: 37614116.0000 - val_mae: 4621.7202\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46275628.0000 - mae: 4766.2080 - val_loss: 37491812.0000 - val_mae: 4625.8755\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45926972.0000 - mae: 4801.6787 - val_loss: 37346440.0000 - val_mae: 4588.5552\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45810136.0000 - mae: 4768.0210 - val_loss: 37232596.0000 - val_mae: 4601.1611\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45724088.0000 - mae: 4765.2593 - val_loss: 37114988.0000 - val_mae: 4596.8066\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45411768.0000 - mae: 4744.0493 - val_loss: 36994088.0000 - val_mae: 4567.4561\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45267140.0000 - mae: 4762.5488 - val_loss: 36910428.0000 - val_mae: 4620.8184\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45551584.0000 - mae: 4727.7939 - val_loss: 36748144.0000 - val_mae: 4540.7588\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45709020.0000 - mae: 4659.5625 - val_loss: 36647864.0000 - val_mae: 4528.7437\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44935364.0000 - mae: 4727.5298 - val_loss: 36558400.0000 - val_mae: 4586.0996\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44942996.0000 - mae: 4735.2510 - val_loss: 36458716.0000 - val_mae: 4599.5654\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44894840.0000 - mae: 4708.2510 - val_loss: 36299224.0000 - val_mae: 4561.2046\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44504696.0000 - mae: 4730.7383 - val_loss: 36213472.0000 - val_mae: 4581.0942\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44424760.0000 - mae: 4735.9307 - val_loss: 36102432.0000 - val_mae: 4566.3994\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44343032.0000 - mae: 4743.7915 - val_loss: 35945552.0000 - val_mae: 4505.0874\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44125132.0000 - mae: 4721.6284 - val_loss: 35828776.0000 - val_mae: 4476.7095\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44142956.0000 - mae: 4691.6333 - val_loss: 35705412.0000 - val_mae: 4504.7354\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42992832.0000 - mae: 4777.1235 - val_loss: 35854584.0000 - val_mae: 4344.8848\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44260580.0000 - mae: 4607.3545 - val_loss: 35494080.0000 - val_mae: 4443.6777\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43597144.0000 - mae: 4696.7212 - val_loss: 35383544.0000 - val_mae: 4423.6465\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43655648.0000 - mae: 4665.7778 - val_loss: 35236864.0000 - val_mae: 4458.9160\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 43876892.0000 - mae: 4694.205 - 0s 1ms/step - loss: 43366784.0000 - mae: 4669.7534 - val_loss: 35117428.0000 - val_mae: 4437.9648\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43311936.0000 - mae: 4647.8086 - val_loss: 34994804.0000 - val_mae: 4458.9688\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43069304.0000 - mae: 4673.2607 - val_loss: 34893492.0000 - val_mae: 4476.2866\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43058624.0000 - mae: 4633.7114 - val_loss: 34764056.0000 - val_mae: 4455.0703\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42860356.0000 - mae: 4658.8789 - val_loss: 34642212.0000 - val_mae: 4412.0566\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42924320.0000 - mae: 4592.5117 - val_loss: 34537164.0000 - val_mae: 4427.3667\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42481596.0000 - mae: 4669.1294 - val_loss: 34413420.0000 - val_mae: 4395.1221\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42435276.0000 - mae: 4641.2671 - val_loss: 34299460.0000 - val_mae: 4362.1479\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42409304.0000 - mae: 4606.2471 - val_loss: 34178060.0000 - val_mae: 4371.2495\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42505144.0000 - mae: 4589.4653 - val_loss: 34130132.0000 - val_mae: 4301.0874\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42307196.0000 - mae: 4533.3354 - val_loss: 33944232.0000 - val_mae: 4362.7544\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 8653330.0000 - mae: 2941.65 - 0s 1ms/step - loss: 42512128.0000 - mae: 4524.7588 - val_loss: 33878540.0000 - val_mae: 4304.8945\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41859524.0000 - mae: 4530.4136 - val_loss: 33606188.0000 - val_mae: 4248.5088\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42203716.0000 - mae: 4506.1729 - val_loss: 33520354.0000 - val_mae: 4224.5596\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41459276.0000 - mae: 4531.9478 - val_loss: 33336786.0000 - val_mae: 4234.1636\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 42332612.0000 - mae: 4653.131 - 0s 1ms/step - loss: 41174132.0000 - mae: 4565.7935 - val_loss: 33302110.0000 - val_mae: 4191.2783\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 41768992.0000 - mae: 4438.8838 - val_loss: 33017524.0000 - val_mae: 4257.3477\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40801876.0000 - mae: 4572.3867 - val_loss: 32933998.0000 - val_mae: 4206.0693\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40872704.0000 - mae: 4559.1748 - val_loss: 32798358.0000 - val_mae: 4201.4287\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40861180.0000 - mae: 4501.5410 - val_loss: 32594846.0000 - val_mae: 4242.0776\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41111532.0000 - mae: 4421.3809 - val_loss: 32484084.0000 - val_mae: 4222.5581\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40430824.0000 - mae: 4499.6460 - val_loss: 32337382.0000 - val_mae: 4235.6914\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40458284.0000 - mae: 4466.1377 - val_loss: 32189790.0000 - val_mae: 4282.4233\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40179104.0000 - mae: 4424.0107 - val_loss: 32118644.0000 - val_mae: 4328.5371\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40444396.0000 - mae: 4431.7456 - val_loss: 31931120.0000 - val_mae: 4258.3442\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39439964.0000 - mae: 4533.0635 - val_loss: 31856656.0000 - val_mae: 4152.4663\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39666672.0000 - mae: 4498.5220 - val_loss: 31845914.0000 - val_mae: 4084.8855\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39534424.0000 - mae: 4492.1968 - val_loss: 31588458.0000 - val_mae: 4124.5439\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38969204.0000 - mae: 4490.1597 - val_loss: 31617754.0000 - val_mae: 4046.7224\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39509216.0000 - mae: 4417.7705 - val_loss: 31324592.0000 - val_mae: 4087.4817\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39101496.0000 - mae: 4329.9087 - val_loss: 31084034.0000 - val_mae: 4205.1650\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38689052.0000 - mae: 4473.6538 - val_loss: 30926184.0000 - val_mae: 4148.6382\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38465040.0000 - mae: 4456.9624 - val_loss: 30842734.0000 - val_mae: 4077.2859\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38770428.0000 - mae: 4353.5947 - val_loss: 30621638.0000 - val_mae: 4130.1235\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38158212.0000 - mae: 4356.0815 - val_loss: 30718384.0000 - val_mae: 3991.1777\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38619268.0000 - mae: 4311.3135 - val_loss: 30328990.0000 - val_mae: 4113.6396\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38110432.0000 - mae: 4371.9858 - val_loss: 30178090.0000 - val_mae: 4111.6333\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38056588.0000 - mae: 4354.9375 - val_loss: 30035648.0000 - val_mae: 4085.0566\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37887836.0000 - mae: 4323.7031 - val_loss: 29850292.0000 - val_mae: 4108.3149\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37314028.0000 - mae: 4393.8647 - val_loss: 29677204.0000 - val_mae: 4087.6926\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37009460.0000 - mae: 4363.5508 - val_loss: 29732706.0000 - val_mae: 3927.2173\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37078144.0000 - mae: 4306.2334 - val_loss: 29788428.0000 - val_mae: 3866.7256\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37460580.0000 - mae: 4291.8784 - val_loss: 29479574.0000 - val_mae: 3882.7954\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37369988.0000 - mae: 4218.9282 - val_loss: 29038950.0000 - val_mae: 3982.7593\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36540924.0000 - mae: 4293.7827 - val_loss: 28936326.0000 - val_mae: 3919.0532\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36480540.0000 - mae: 4285.9814 - val_loss: 28681288.0000 - val_mae: 3948.3667\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36123744.0000 - mae: 4252.9150 - val_loss: 28475252.0000 - val_mae: 4037.8809\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 35497440.0000 - mae: 4274.6655 - val_loss: 28380888.0000 - val_mae: 3861.5166\n"
     ]
    }
   ],
   "source": [
    "# for relu\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate([x[:i * num_val_samples],x[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([y[:i * num_val_samples],y[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1,validation_data=(val_data, val_targets))\n",
    "    #all_scores.append(np.mean(history.history['val_mae']))\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    all_scores.append(np.mean(mae_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_mae_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3608.828254394531, 4406.277104492187, 4738.879948730469]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4251.328435872395"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for k=3 ----> 4251.328435872395\n",
    " ,for k=5 ----> 7667.279361083984\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(average_mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/500\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 190456416.0000 - mae: 11589.5557 - val_loss: 125923896.0000 - val_mae: 9554.6172\n",
      "Epoch 2/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 143175568.0000 - mae: 9350.5498 - val_loss: 79522928.0000 - val_mae: 6803.9609\n",
      "Epoch 3/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 87993464.0000 - mae: 6421.0396 - val_loss: 42020576.0000 - val_mae: 4313.9238\n",
      "Epoch 4/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 60494464.0000 - mae: 4899.4565 - val_loss: 30782274.0000 - val_mae: 3877.2151\n",
      "Epoch 5/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 50697296.0000 - mae: 4938.1831 - val_loss: 29559226.0000 - val_mae: 3932.0266\n",
      "Epoch 6/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 49351508.0000 - mae: 4911.0835 - val_loss: 29707460.0000 - val_mae: 4037.6484\n",
      "Epoch 7/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 48268692.0000 - mae: 5098.4741 - val_loss: 29555802.0000 - val_mae: 4029.0332\n",
      "Epoch 8/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 48064228.0000 - mae: 5081.0112 - val_loss: 29432628.0000 - val_mae: 4026.8911\n",
      "Epoch 9/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47814480.0000 - mae: 5085.4053 - val_loss: 29279856.0000 - val_mae: 4019.8218\n",
      "Epoch 10/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 48064668.0000 - mae: 4999.6128 - val_loss: 29062612.0000 - val_mae: 3995.5952\n",
      "Epoch 11/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47430072.0000 - mae: 5044.6851 - val_loss: 29021226.0000 - val_mae: 4010.6140\n",
      "Epoch 12/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47366060.0000 - mae: 5038.6875 - val_loss: 28723864.0000 - val_mae: 3972.7844\n",
      "Epoch 13/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46956460.0000 - mae: 4856.0220 - val_loss: 28969502.0000 - val_mae: 4051.1411\n",
      "Epoch 14/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46408496.0000 - mae: 5062.6392 - val_loss: 28347708.0000 - val_mae: 3940.7246\n",
      "Epoch 15/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46424332.0000 - mae: 4998.8872 - val_loss: 28151278.0000 - val_mae: 3920.6926\n",
      "Epoch 16/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46475536.0000 - mae: 4886.3086 - val_loss: 28009140.0000 - val_mae: 3913.8140\n",
      "Epoch 17/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46333428.0000 - mae: 4861.4233 - val_loss: 28143086.0000 - val_mae: 3975.7058\n",
      "Epoch 18/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46005332.0000 - mae: 4881.0435 - val_loss: 27977726.0000 - val_mae: 3965.2881\n",
      "Epoch 19/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45261208.0000 - mae: 4893.2910 - val_loss: 28385174.0000 - val_mae: 4055.2876\n",
      "Epoch 20/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45412804.0000 - mae: 4894.0464 - val_loss: 28127904.0000 - val_mae: 4031.2749\n",
      "Epoch 21/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45026564.0000 - mae: 4907.0029 - val_loss: 27917494.0000 - val_mae: 4014.7280\n",
      "Epoch 22/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45018316.0000 - mae: 4859.5981 - val_loss: 27165108.0000 - val_mae: 3885.3069\n",
      "Epoch 23/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44405956.0000 - mae: 4719.0273 - val_loss: 27837092.0000 - val_mae: 4029.2324\n",
      "Epoch 24/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44114580.0000 - mae: 4936.1055 - val_loss: 27339124.0000 - val_mae: 3967.3770\n",
      "Epoch 25/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43982192.0000 - mae: 4897.9961 - val_loss: 26993424.0000 - val_mae: 3924.2798\n",
      "Epoch 26/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43777984.0000 - mae: 4859.6440 - val_loss: 26392294.0000 - val_mae: 3810.4312\n",
      "Epoch 27/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43757580.0000 - mae: 4772.7148 - val_loss: 26274464.0000 - val_mae: 3814.5723\n",
      "Epoch 28/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43215052.0000 - mae: 4830.2490 - val_loss: 26232568.0000 - val_mae: 3838.7290\n",
      "Epoch 29/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43300892.0000 - mae: 4661.8730 - val_loss: 26332346.0000 - val_mae: 3885.1921\n",
      "Epoch 30/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42700292.0000 - mae: 4829.2695 - val_loss: 26135772.0000 - val_mae: 3870.3672\n",
      "Epoch 31/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42324708.0000 - mae: 4806.9937 - val_loss: 25492682.0000 - val_mae: 3737.4819\n",
      "Epoch 32/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42349048.0000 - mae: 4766.5942 - val_loss: 25313702.0000 - val_mae: 3724.4429\n",
      "Epoch 33/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 45782000.0000 - mae: 4941.959 - 0s 1ms/step - loss: 42204852.0000 - mae: 4720.9561 - val_loss: 25290318.0000 - val_mae: 3762.8184\n",
      "Epoch 34/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42130080.0000 - mae: 4654.8042 - val_loss: 25090404.0000 - val_mae: 3744.1609\n",
      "Epoch 35/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41292848.0000 - mae: 4746.9370 - val_loss: 25048256.0000 - val_mae: 3766.3728\n",
      "Epoch 36/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41114824.0000 - mae: 4718.9727 - val_loss: 24597686.0000 - val_mae: 3668.8608\n",
      "Epoch 37/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41161432.0000 - mae: 4680.4082 - val_loss: 24728756.0000 - val_mae: 3752.0334\n",
      "Epoch 38/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40042088.0000 - mae: 4683.7773 - val_loss: 24121660.0000 - val_mae: 3546.9141\n",
      "Epoch 39/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41157348.0000 - mae: 4554.4023 - val_loss: 24096468.0000 - val_mae: 3654.9775\n",
      "Epoch 40/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40362736.0000 - mae: 4527.8320 - val_loss: 24377738.0000 - val_mae: 3753.4900\n",
      "Epoch 41/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40503036.0000 - mae: 4545.6680 - val_loss: 24073968.0000 - val_mae: 3715.8386\n",
      "Epoch 42/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39856056.0000 - mae: 4570.8340 - val_loss: 23898516.0000 - val_mae: 3706.1365\n",
      "Epoch 43/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39397036.0000 - mae: 4590.0933 - val_loss: 23718922.0000 - val_mae: 3696.8169\n",
      "Epoch 44/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 38695756.0000 - mae: 4626.4375 - val_loss: 23100110.0000 - val_mae: 3568.6116\n",
      "Epoch 45/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39045880.0000 - mae: 4441.8984 - val_loss: 23434562.0000 - val_mae: 3687.7871\n",
      "Epoch 46/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38386016.0000 - mae: 4533.8198 - val_loss: 22742614.0000 - val_mae: 3557.9009\n",
      "Epoch 47/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38362784.0000 - mae: 4335.9409 - val_loss: 23280112.0000 - val_mae: 3700.2666\n",
      "Epoch 48/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37710368.0000 - mae: 4556.3931 - val_loss: 22839132.0000 - val_mae: 3646.5342\n",
      "Epoch 49/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37572568.0000 - mae: 4473.2412 - val_loss: 22632766.0000 - val_mae: 3631.2480\n",
      "Epoch 50/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37248412.0000 - mae: 4356.5850 - val_loss: 22828360.0000 - val_mae: 3688.7087\n",
      "Epoch 51/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36925740.0000 - mae: 4431.1450 - val_loss: 22646890.0000 - val_mae: 3681.6890\n",
      "Epoch 52/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36307180.0000 - mae: 4504.0176 - val_loss: 21805826.0000 - val_mae: 3546.1265\n",
      "Epoch 53/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36525452.0000 - mae: 4364.1523 - val_loss: 21555942.0000 - val_mae: 3523.7278\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 36419388.0000 - mae: 4291.6777 - val_loss: 21474980.0000 - val_mae: 3532.6128\n",
      "Epoch 55/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 35625168.0000 - mae: 4327.2490 - val_loss: 21130846.0000 - val_mae: 3491.6377\n",
      "Epoch 56/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 35070656.0000 - mae: 4312.7695 - val_loss: 20588356.0000 - val_mae: 3395.6206\n",
      "Epoch 57/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34687224.0000 - mae: 4300.1367 - val_loss: 20381608.0000 - val_mae: 3388.4321\n",
      "Epoch 58/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34612356.0000 - mae: 4250.2290 - val_loss: 20148924.0000 - val_mae: 3374.8047\n",
      "Epoch 59/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34389252.0000 - mae: 4202.7476 - val_loss: 20124708.0000 - val_mae: 3418.2354\n",
      "Epoch 60/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33656132.0000 - mae: 4167.9741 - val_loss: 20297436.0000 - val_mae: 3501.5811\n",
      "Epoch 61/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33466334.0000 - mae: 4148.2773 - val_loss: 20016262.0000 - val_mae: 3480.9028\n",
      "Epoch 62/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32689232.0000 - mae: 4194.0713 - val_loss: 19148136.0000 - val_mae: 3306.5178\n",
      "Epoch 63/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33556224.0000 - mae: 3979.4802 - val_loss: 18961972.0000 - val_mae: 3306.4519\n",
      "Epoch 64/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31809872.0000 - mae: 4119.5825 - val_loss: 18561028.0000 - val_mae: 3241.3411\n",
      "Epoch 65/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31736042.0000 - mae: 3958.1897 - val_loss: 18074530.0000 - val_mae: 3099.9033\n",
      "Epoch 66/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31965870.0000 - mae: 3942.1733 - val_loss: 18151002.0000 - val_mae: 3244.9001\n",
      "Epoch 67/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31018458.0000 - mae: 3961.3906 - val_loss: 18249912.0000 - val_mae: 3335.5137\n",
      "Epoch 68/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30400826.0000 - mae: 3950.3176 - val_loss: 18198182.0000 - val_mae: 3378.6880\n",
      "Epoch 69/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29905202.0000 - mae: 3957.0137 - val_loss: 17415066.0000 - val_mae: 3234.9375\n",
      "Epoch 70/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29447542.0000 - mae: 3890.3772 - val_loss: 16775616.0000 - val_mae: 3093.9307\n",
      "Epoch 71/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29344432.0000 - mae: 3792.7908 - val_loss: 17164318.0000 - val_mae: 3282.4863\n",
      "Epoch 72/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 28341600.0000 - mae: 3886.4807 - val_loss: 16261726.0000 - val_mae: 3087.2646\n",
      "Epoch 73/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27973808.0000 - mae: 3767.6768 - val_loss: 15914466.0000 - val_mae: 3066.2092\n",
      "Epoch 74/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27592798.0000 - mae: 3683.0938 - val_loss: 15990263.0000 - val_mae: 3163.7156\n",
      "Epoch 75/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26722832.0000 - mae: 3751.2068 - val_loss: 15045118.0000 - val_mae: 2910.5288\n",
      "Epoch 76/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26913360.0000 - mae: 3592.5151 - val_loss: 14836677.0000 - val_mae: 2936.6650\n",
      "Epoch 77/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26406306.0000 - mae: 3554.9395 - val_loss: 14897248.0000 - val_mae: 3053.4485\n",
      "Epoch 78/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25341792.0000 - mae: 3519.1982 - val_loss: 14158404.0000 - val_mae: 2870.8069\n",
      "Epoch 79/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25235618.0000 - mae: 3557.6726 - val_loss: 13748346.0000 - val_mae: 2808.2410\n",
      "Epoch 80/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24567072.0000 - mae: 3414.7986 - val_loss: 14363696.0000 - val_mae: 3104.9658\n",
      "Epoch 81/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 684486.3750 - mae: 827.33 - 0s 1ms/step - loss: 23798310.0000 - mae: 3464.1199 - val_loss: 14367246.0000 - val_mae: 3152.8115\n",
      "Epoch 82/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23157584.0000 - mae: 3527.4707 - val_loss: 13148810.0000 - val_mae: 2889.7966\n",
      "Epoch 83/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 22911778.0000 - mae: 3429.7744 - val_loss: 12520513.0000 - val_mae: 2743.7878\n",
      "Epoch 84/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 22146246.0000 - mae: 3404.4812 - val_loss: 12042652.0000 - val_mae: 2638.7422\n",
      "Epoch 85/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 21977766.0000 - mae: 3278.7095 - val_loss: 11985715.0000 - val_mae: 2737.2937\n",
      "Epoch 86/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 21673648.0000 - mae: 3163.7168 - val_loss: 12381682.0000 - val_mae: 2907.0105\n",
      "Epoch 87/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 21202268.0000 - mae: 3183.7881 - val_loss: 12483607.0000 - val_mae: 2964.5532\n",
      "Epoch 88/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20255172.0000 - mae: 3190.5674 - val_loss: 12119160.0000 - val_mae: 2921.4092\n",
      "Epoch 89/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 19690486.0000 - mae: 3236.5894 - val_loss: 11473380.0000 - val_mae: 2809.1042\n",
      "Epoch 90/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 19383028.0000 - mae: 3112.5027 - val_loss: 11146733.0000 - val_mae: 2764.6677\n",
      "Epoch 91/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 18790458.0000 - mae: 3073.9106 - val_loss: 11788223.0000 - val_mae: 2922.0449\n",
      "Epoch 92/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 18456596.0000 - mae: 3054.9001 - val_loss: 11436804.0000 - val_mae: 2870.4958\n",
      "Epoch 93/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 17738520.0000 - mae: 3085.9924 - val_loss: 9872387.0000 - val_mae: 2529.4238\n",
      "Epoch 94/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 17548806.0000 - mae: 2902.5664 - val_loss: 10297680.0000 - val_mae: 2656.9517\n",
      "Epoch 95/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 16916370.0000 - mae: 2863.7549 - val_loss: 10864498.0000 - val_mae: 2798.6008\n",
      "Epoch 96/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 16469361.0000 - mae: 3013.2480 - val_loss: 9049785.0000 - val_mae: 2389.1760\n",
      "Epoch 97/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 16737301.0000 - mae: 2801.3809 - val_loss: 8713704.0000 - val_mae: 2309.1614\n",
      "Epoch 98/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 16015006.0000 - mae: 2780.3147 - val_loss: 9273865.0000 - val_mae: 2492.5818\n",
      "Epoch 99/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 15468715.0000 - mae: 2749.9495 - val_loss: 9212018.0000 - val_mae: 2490.2144\n",
      "Epoch 100/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 15226168.0000 - mae: 2729.3374 - val_loss: 8280136.5000 - val_mae: 2234.0020\n",
      "Epoch 101/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 15340584.0000 - mae: 2616.0344 - val_loss: 9181587.0000 - val_mae: 2491.9558\n",
      "Epoch 102/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14855944.0000 - mae: 2650.9634 - val_loss: 9111172.0000 - val_mae: 2479.1672\n",
      "Epoch 103/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14852856.0000 - mae: 2607.2849 - val_loss: 8923752.0000 - val_mae: 2437.7776\n",
      "Epoch 104/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14744935.0000 - mae: 2578.1750 - val_loss: 9285660.0000 - val_mae: 2509.3804\n",
      "Epoch 105/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14187855.0000 - mae: 2508.8801 - val_loss: 9696149.0000 - val_mae: 2578.2979\n",
      "Epoch 106/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13922725.0000 - mae: 2657.2900 - val_loss: 7854107.5000 - val_mae: 2178.8506\n",
      "Epoch 107/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14079773.0000 - mae: 2516.0312 - val_loss: 8949588.0000 - val_mae: 2429.4985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13567328.0000 - mae: 2474.2600 - val_loss: 9351336.0000 - val_mae: 2491.7681\n",
      "Epoch 109/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13056286.0000 - mae: 2579.9941 - val_loss: 7360147.0000 - val_mae: 2030.1737\n",
      "Epoch 110/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13798988.0000 - mae: 2400.5049 - val_loss: 8800538.0000 - val_mae: 2381.1191\n",
      "Epoch 111/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13277218.0000 - mae: 2520.9453 - val_loss: 7835519.0000 - val_mae: 2179.2458\n",
      "Epoch 112/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13499865.0000 - mae: 2428.7102 - val_loss: 8343889.0000 - val_mae: 2284.5122\n",
      "Epoch 113/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12927742.0000 - mae: 2480.0183 - val_loss: 7721508.0000 - val_mae: 2145.0952\n",
      "Epoch 114/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13275988.0000 - mae: 2391.1477 - val_loss: 8823308.0000 - val_mae: 2362.0981\n",
      "Epoch 115/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13010500.0000 - mae: 2448.2742 - val_loss: 8234647.5000 - val_mae: 2252.2598\n",
      "Epoch 116/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12791825.0000 - mae: 2434.9487 - val_loss: 8358789.5000 - val_mae: 2264.0886\n",
      "Epoch 117/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12753983.0000 - mae: 2416.1665 - val_loss: 7986507.5000 - val_mae: 2186.5159\n",
      "Epoch 118/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12453975.0000 - mae: 2400.8418 - val_loss: 7236040.5000 - val_mae: 2012.8794\n",
      "Epoch 119/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12910295.0000 - mae: 2352.5156 - val_loss: 7535963.0000 - val_mae: 2081.0957\n",
      "Epoch 120/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12784082.0000 - mae: 2346.8857 - val_loss: 7584060.5000 - val_mae: 2089.2571\n",
      "Epoch 121/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12849100.0000 - mae: 2315.1504 - val_loss: 8576108.0000 - val_mae: 2270.3306\n",
      "Epoch 122/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12435900.0000 - mae: 2411.2415 - val_loss: 7363484.0000 - val_mae: 2036.1315\n",
      "Epoch 123/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12642736.0000 - mae: 2335.1887 - val_loss: 8600394.0000 - val_mae: 2262.8020\n",
      "Epoch 124/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12653934.0000 - mae: 2305.2898 - val_loss: 8697000.0000 - val_mae: 2279.2085\n",
      "Epoch 125/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12276984.0000 - mae: 2370.9121 - val_loss: 7571076.0000 - val_mae: 2074.7578\n",
      "Epoch 126/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12248947.0000 - mae: 2318.9480 - val_loss: 9590462.0000 - val_mae: 2404.9529\n",
      "Epoch 127/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12086122.0000 - mae: 2391.4109 - val_loss: 7365353.0000 - val_mae: 2034.0112\n",
      "Epoch 128/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12554537.0000 - mae: 2298.8145 - val_loss: 8848304.0000 - val_mae: 2297.5413\n",
      "Epoch 129/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12157973.0000 - mae: 2320.7908 - val_loss: 8215135.0000 - val_mae: 2194.1868\n",
      "Epoch 130/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12288923.0000 - mae: 2345.0332 - val_loss: 7819777.0000 - val_mae: 2116.5901\n",
      "Epoch 131/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11964084.0000 - mae: 2309.3967 - val_loss: 7330427.0000 - val_mae: 2018.0005\n",
      "Epoch 132/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11951827.0000 - mae: 2304.4683 - val_loss: 7263121.0000 - val_mae: 2001.7385\n",
      "Epoch 133/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12517660.0000 - mae: 2286.4587 - val_loss: 8190136.5000 - val_mae: 2175.2148\n",
      "Epoch 134/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12143785.0000 - mae: 2324.6394 - val_loss: 9189070.0000 - val_mae: 2327.6721\n",
      "Epoch 135/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12236178.0000 - mae: 2340.2874 - val_loss: 7781310.0000 - val_mae: 2101.7771\n",
      "Epoch 136/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12299617.0000 - mae: 2250.1829 - val_loss: 8363437.0000 - val_mae: 2196.4480\n",
      "Epoch 137/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12071905.0000 - mae: 2263.5215 - val_loss: 10085382.0000 - val_mae: 2440.5154\n",
      "Epoch 138/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11976018.0000 - mae: 2318.7593 - val_loss: 9878394.0000 - val_mae: 2420.0605\n",
      "Epoch 139/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12061599.0000 - mae: 2352.2285 - val_loss: 8076966.5000 - val_mae: 2149.4155\n",
      "Epoch 140/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12242658.0000 - mae: 2273.3584 - val_loss: 7735523.0000 - val_mae: 2089.2473\n",
      "Epoch 141/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12155971.0000 - mae: 2301.2585 - val_loss: 8293335.5000 - val_mae: 2183.9578\n",
      "Epoch 142/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11879916.0000 - mae: 2292.1506 - val_loss: 8718183.0000 - val_mae: 2246.3140\n",
      "Epoch 143/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12056845.0000 - mae: 2318.5249 - val_loss: 7856894.5000 - val_mae: 2107.8396\n",
      "Epoch 144/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12234637.0000 - mae: 2271.2388 - val_loss: 8726317.0000 - val_mae: 2240.1118\n",
      "Epoch 145/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12114966.0000 - mae: 2322.1394 - val_loss: 7922055.5000 - val_mae: 2108.9797\n",
      "Epoch 146/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11934494.0000 - mae: 2281.6602 - val_loss: 7189534.5000 - val_mae: 1970.3541\n",
      "Epoch 147/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12800667.0000 - mae: 2202.9600 - val_loss: 8916629.0000 - val_mae: 2261.7681\n",
      "Epoch 148/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11867634.0000 - mae: 2336.6582 - val_loss: 8195388.0000 - val_mae: 2146.6465\n",
      "Epoch 149/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12034234.0000 - mae: 2292.7991 - val_loss: 7670600.5000 - val_mae: 2053.0400\n",
      "Epoch 150/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11836849.0000 - mae: 2238.4636 - val_loss: 8580276.0000 - val_mae: 2196.0398\n",
      "Epoch 151/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12036305.0000 - mae: 2262.7959 - val_loss: 7616748.0000 - val_mae: 2042.4948\n",
      "Epoch 152/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11777304.0000 - mae: 2295.1089 - val_loss: 7125657.5000 - val_mae: 1960.3226\n",
      "Epoch 153/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12220791.0000 - mae: 2246.8062 - val_loss: 8809473.0000 - val_mae: 2241.8340\n",
      "Epoch 154/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12069456.0000 - mae: 2266.5823 - val_loss: 8812930.0000 - val_mae: 2241.7205\n",
      "Epoch 155/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11735919.0000 - mae: 2215.3940 - val_loss: 9909368.0000 - val_mae: 2406.2671\n",
      "Epoch 156/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11873671.0000 - mae: 2318.0667 - val_loss: 8840552.0000 - val_mae: 2243.3604\n",
      "Epoch 157/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11827734.0000 - mae: 2226.1343 - val_loss: 9863564.0000 - val_mae: 2390.7363\n",
      "Epoch 158/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11906608.0000 - mae: 2360.8950 - val_loss: 8675066.0000 - val_mae: 2218.1709\n",
      "Epoch 159/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11657905.0000 - mae: 2308.5493 - val_loss: 7228622.0000 - val_mae: 1978.4117\n",
      "Epoch 160/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11603775.0000 - mae: 2208.5918 - val_loss: 10105308.0000 - val_mae: 2425.0522\n",
      "Epoch 161/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11486177.0000 - mae: 2296.7632 - val_loss: 7031132.0000 - val_mae: 1942.7784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11771773.0000 - mae: 2251.5181 - val_loss: 6744311.5000 - val_mae: 1893.3436\n",
      "Epoch 163/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11952949.0000 - mae: 2177.2441 - val_loss: 6901306.5000 - val_mae: 1923.9487\n",
      "Epoch 164/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11695629.0000 - mae: 2247.4436 - val_loss: 8518697.0000 - val_mae: 2189.5222\n",
      "Epoch 165/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11592674.0000 - mae: 2302.6777 - val_loss: 7417647.5000 - val_mae: 2004.4042\n",
      "Epoch 166/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11901272.0000 - mae: 2250.1738 - val_loss: 8950671.0000 - val_mae: 2240.4802\n",
      "Epoch 167/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11773699.0000 - mae: 2292.3870 - val_loss: 8490999.0000 - val_mae: 2175.4260\n",
      "Epoch 168/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11872120.0000 - mae: 2313.0642 - val_loss: 7737156.0000 - val_mae: 2072.9097\n",
      "Epoch 169/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11566603.0000 - mae: 2234.0923 - val_loss: 9934877.0000 - val_mae: 2399.2834\n",
      "Epoch 170/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11660636.0000 - mae: 2370.2529 - val_loss: 9036164.0000 - val_mae: 2260.1663\n",
      "Epoch 171/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11958021.0000 - mae: 2247.2847 - val_loss: 7834924.0000 - val_mae: 2076.0178\n",
      "Epoch 172/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11231906.0000 - mae: 2320.4802 - val_loss: 7229482.0000 - val_mae: 1972.2351\n",
      "Epoch 173/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11826734.0000 - mae: 2249.3594 - val_loss: 7792358.5000 - val_mae: 2063.4844\n",
      "Epoch 174/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12201413.0000 - mae: 2198.4612 - val_loss: 8185948.0000 - val_mae: 2131.9585\n",
      "Epoch 175/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11693923.0000 - mae: 2297.2275 - val_loss: 8000758.5000 - val_mae: 2095.1484\n",
      "Epoch 176/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11727270.0000 - mae: 2257.6895 - val_loss: 8144330.5000 - val_mae: 2111.8313\n",
      "Epoch 177/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11459342.0000 - mae: 2245.2922 - val_loss: 7111721.5000 - val_mae: 1957.8281\n",
      "Epoch 178/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11975771.0000 - mae: 2256.1150 - val_loss: 8041566.0000 - val_mae: 2110.2590\n",
      "Epoch 179/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11608028.0000 - mae: 2267.0125 - val_loss: 9130183.0000 - val_mae: 2288.0083\n",
      "Epoch 180/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11617664.0000 - mae: 2283.4355 - val_loss: 7693855.0000 - val_mae: 2047.7861\n",
      "Epoch 181/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11692653.0000 - mae: 2351.7461 - val_loss: 7143405.5000 - val_mae: 1959.2635\n",
      "Epoch 182/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11591799.0000 - mae: 2229.9309 - val_loss: 8571063.0000 - val_mae: 2187.6272\n",
      "Epoch 183/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 8007449.0000 - mae: 2012.233 - 0s 1ms/step - loss: 11898438.0000 - mae: 2260.0371 - val_loss: 8184618.5000 - val_mae: 2135.9512\n",
      "Epoch 184/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11609130.0000 - mae: 2262.8999 - val_loss: 7922732.0000 - val_mae: 2095.8088\n",
      "Epoch 185/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11933769.0000 - mae: 2267.2598 - val_loss: 7720322.0000 - val_mae: 2053.1787\n",
      "Epoch 186/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11698771.0000 - mae: 2286.6748 - val_loss: 7309268.0000 - val_mae: 1981.8104\n",
      "Epoch 187/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11371128.0000 - mae: 2233.4631 - val_loss: 10592124.0000 - val_mae: 2489.1135\n",
      "Epoch 188/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11481979.0000 - mae: 2377.4487 - val_loss: 7118305.0000 - val_mae: 1953.2258\n",
      "Epoch 189/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11634813.0000 - mae: 2231.6858 - val_loss: 7713249.5000 - val_mae: 2045.7396\n",
      "Epoch 190/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11733595.0000 - mae: 2274.7563 - val_loss: 7301916.5000 - val_mae: 1979.9435\n",
      "Epoch 191/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11692774.0000 - mae: 2305.3911 - val_loss: 8347873.0000 - val_mae: 2134.0850\n",
      "Epoch 192/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11159657.0000 - mae: 2275.6255 - val_loss: 7393971.5000 - val_mae: 1990.0081\n",
      "Epoch 193/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11406332.0000 - mae: 2308.8162 - val_loss: 6688714.5000 - val_mae: 1887.5786\n",
      "Epoch 194/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11606674.0000 - mae: 2306.6240 - val_loss: 8023581.0000 - val_mae: 2091.4062\n",
      "Epoch 195/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11542951.0000 - mae: 2240.3125 - val_loss: 7090994.0000 - val_mae: 1950.9078\n",
      "Epoch 196/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11821128.0000 - mae: 2205.3406 - val_loss: 7784482.5000 - val_mae: 2066.4358\n",
      "Epoch 197/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11889067.0000 - mae: 2256.6860 - val_loss: 7459193.5000 - val_mae: 2034.3466\n",
      "Epoch 198/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11374338.0000 - mae: 2272.8677 - val_loss: 6864052.0000 - val_mae: 1918.7794\n",
      "Epoch 199/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11531238.0000 - mae: 2267.6128 - val_loss: 6957085.5000 - val_mae: 1931.4653\n",
      "Epoch 200/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11675772.0000 - mae: 2265.0425 - val_loss: 8953261.0000 - val_mae: 2259.9604\n",
      "Epoch 201/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11529556.0000 - mae: 2310.8999 - val_loss: 7450574.5000 - val_mae: 2013.2617\n",
      "Epoch 202/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11726805.0000 - mae: 2270.7708 - val_loss: 8099269.5000 - val_mae: 2133.0703\n",
      "Epoch 203/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11888581.0000 - mae: 2217.7026 - val_loss: 7930323.0000 - val_mae: 2115.7646\n",
      "Epoch 204/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11457789.0000 - mae: 2279.2666 - val_loss: 8203996.0000 - val_mae: 2162.6733\n",
      "Epoch 205/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11566089.0000 - mae: 2293.7134 - val_loss: 8543583.0000 - val_mae: 2206.8684\n",
      "Epoch 206/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11067445.0000 - mae: 2268.9792 - val_loss: 6554114.5000 - val_mae: 1873.3644\n",
      "Epoch 207/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11261929.0000 - mae: 2253.8889 - val_loss: 6351516.5000 - val_mae: 1840.6221\n",
      "Epoch 208/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11912197.0000 - mae: 2208.7522 - val_loss: 7826433.0000 - val_mae: 2129.3027\n",
      "Epoch 209/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11861756.0000 - mae: 2217.9626 - val_loss: 7900116.0000 - val_mae: 2159.2041\n",
      "Epoch 210/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11678291.0000 - mae: 2275.7378 - val_loss: 7097330.0000 - val_mae: 2023.0558\n",
      "Epoch 211/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11448761.0000 - mae: 2294.7495 - val_loss: 7105658.5000 - val_mae: 2017.5068\n",
      "Epoch 212/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11156220.0000 - mae: 2286.3457 - val_loss: 6184495.5000 - val_mae: 1828.3513\n",
      "Epoch 213/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11367751.0000 - mae: 2236.5615 - val_loss: 7294305.0000 - val_mae: 2046.0441\n",
      "Epoch 214/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11386281.0000 - mae: 2256.2339 - val_loss: 7231074.0000 - val_mae: 2029.2167\n",
      "Epoch 215/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 11332224.0000 - mae: 2240.7156 - val_loss: 7963827.0000 - val_mae: 2148.7461\n",
      "Epoch 216/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10995871.0000 - mae: 2223.2798 - val_loss: 9110448.0000 - val_mae: 2297.1174\n",
      "Epoch 217/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11397246.0000 - mae: 2303.5315 - val_loss: 7920243.0000 - val_mae: 2121.0566\n",
      "Epoch 218/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11196817.0000 - mae: 2236.3484 - val_loss: 7350271.5000 - val_mae: 2033.4637\n",
      "Epoch 219/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11304788.0000 - mae: 2243.7966 - val_loss: 7292275.0000 - val_mae: 2013.4354\n",
      "Epoch 220/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11124201.0000 - mae: 2227.1023 - val_loss: 6918080.0000 - val_mae: 1950.0958\n",
      "Epoch 221/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11100228.0000 - mae: 2291.8145 - val_loss: 6661300.5000 - val_mae: 1901.5687\n",
      "Epoch 222/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11455443.0000 - mae: 2205.6189 - val_loss: 7593255.5000 - val_mae: 2066.0735\n",
      "Epoch 223/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10986786.0000 - mae: 2274.1655 - val_loss: 6502662.0000 - val_mae: 1878.7546\n",
      "Epoch 224/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11382120.0000 - mae: 2250.9268 - val_loss: 6814634.5000 - val_mae: 1920.2035\n",
      "Epoch 225/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11245403.0000 - mae: 2246.7051 - val_loss: 6830101.5000 - val_mae: 1924.9888\n",
      "Epoch 226/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11056912.0000 - mae: 2214.4844 - val_loss: 8886841.0000 - val_mae: 2253.3188\n",
      "Epoch 227/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11264228.0000 - mae: 2286.5811 - val_loss: 8238221.0000 - val_mae: 2161.2329\n",
      "Epoch 228/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11312184.0000 - mae: 2273.9587 - val_loss: 7398735.5000 - val_mae: 2033.4984\n",
      "Epoch 229/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11063682.0000 - mae: 2278.7170 - val_loss: 6520710.5000 - val_mae: 1880.3776\n",
      "Epoch 230/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10780435.0000 - mae: 2304.4758 - val_loss: 6071810.5000 - val_mae: 1803.7631\n",
      "Epoch 231/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11579750.0000 - mae: 2182.1658 - val_loss: 7121150.0000 - val_mae: 1986.9932\n",
      "Epoch 232/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11194632.0000 - mae: 2265.1406 - val_loss: 7745968.5000 - val_mae: 2083.7703\n",
      "Epoch 233/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11281652.0000 - mae: 2269.7932 - val_loss: 7085966.5000 - val_mae: 1976.7294\n",
      "Epoch 234/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11051505.0000 - mae: 2186.4575 - val_loss: 8837953.0000 - val_mae: 2245.3250\n",
      "Epoch 235/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11108966.0000 - mae: 2264.8105 - val_loss: 6483403.5000 - val_mae: 1873.6841\n",
      "Epoch 236/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11148731.0000 - mae: 2243.9966 - val_loss: 6893886.0000 - val_mae: 1952.5450\n",
      "Epoch 237/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11422946.0000 - mae: 2128.7104 - val_loss: 8320937.5000 - val_mae: 2185.2437\n",
      "Epoch 238/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11145527.0000 - mae: 2215.2441 - val_loss: 7121992.5000 - val_mae: 2004.0813\n",
      "Epoch 239/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11032866.0000 - mae: 2272.2209 - val_loss: 7425511.0000 - val_mae: 2050.7754\n",
      "Epoch 240/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10714739.0000 - mae: 2209.9397 - val_loss: 6362238.0000 - val_mae: 1857.8556\n",
      "Epoch 241/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11416242.0000 - mae: 2230.2949 - val_loss: 7231838.5000 - val_mae: 2010.6370\n",
      "Epoch 242/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11130016.0000 - mae: 2212.6936 - val_loss: 6792538.0000 - val_mae: 1926.5233\n",
      "Epoch 243/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11122258.0000 - mae: 2269.8113 - val_loss: 6994948.5000 - val_mae: 1964.8724\n",
      "Epoch 244/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10022670.0000 - mae: 2173.4932 - val_loss: 10891067.0000 - val_mae: 2554.0120\n",
      "Epoch 245/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11208643.0000 - mae: 2313.9539 - val_loss: 7241017.5000 - val_mae: 1995.6273\n",
      "Epoch 246/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11066575.0000 - mae: 2285.9673 - val_loss: 7389025.5000 - val_mae: 2024.6471\n",
      "Epoch 247/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10918278.0000 - mae: 2198.6880 - val_loss: 8195061.5000 - val_mae: 2137.8469\n",
      "Epoch 248/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10863160.0000 - mae: 2253.9119 - val_loss: 6594074.0000 - val_mae: 1885.9146\n",
      "Epoch 249/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11159059.0000 - mae: 2285.3430 - val_loss: 6806973.0000 - val_mae: 1921.6375\n",
      "Epoch 250/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11113763.0000 - mae: 2243.7698 - val_loss: 6692095.5000 - val_mae: 1895.5406\n",
      "Epoch 251/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11054971.0000 - mae: 2217.4504 - val_loss: 7536889.5000 - val_mae: 2039.6091\n",
      "Epoch 252/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11083548.0000 - mae: 2215.2388 - val_loss: 7616980.0000 - val_mae: 2048.6572\n",
      "Epoch 253/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10523934.0000 - mae: 2208.6741 - val_loss: 6054798.0000 - val_mae: 1806.1581\n",
      "Epoch 254/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11124661.0000 - mae: 2171.0764 - val_loss: 7881821.5000 - val_mae: 2077.3625\n",
      "Epoch 255/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11049726.0000 - mae: 2234.7480 - val_loss: 7858278.0000 - val_mae: 2088.8689\n",
      "Epoch 256/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10910549.0000 - mae: 2280.9514 - val_loss: 8031398.5000 - val_mae: 2105.3083\n",
      "Epoch 257/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10858909.0000 - mae: 2265.8638 - val_loss: 6218794.5000 - val_mae: 1829.7283\n",
      "Epoch 258/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11190923.0000 - mae: 2210.3420 - val_loss: 7604853.0000 - val_mae: 2076.3364\n",
      "Epoch 259/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10893326.0000 - mae: 2292.4053 - val_loss: 7015876.0000 - val_mae: 1975.2734\n",
      "Epoch 260/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11030364.0000 - mae: 2184.9875 - val_loss: 7950965.5000 - val_mae: 2124.7268\n",
      "Epoch 261/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10869372.0000 - mae: 2266.1064 - val_loss: 6424388.0000 - val_mae: 1866.3544\n",
      "Epoch 262/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11251272.0000 - mae: 2261.6292 - val_loss: 6889128.0000 - val_mae: 1950.0784\n",
      "Epoch 263/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10860871.0000 - mae: 2239.5054 - val_loss: 6312686.0000 - val_mae: 1850.0356\n",
      "Epoch 264/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10857371.0000 - mae: 2168.9185 - val_loss: 8452019.0000 - val_mae: 2198.3704\n",
      "Epoch 265/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10827988.0000 - mae: 2256.1111 - val_loss: 8825489.0000 - val_mae: 2234.4895\n",
      "Epoch 266/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11090974.0000 - mae: 2277.5117 - val_loss: 7649992.5000 - val_mae: 2061.1382\n",
      "Epoch 267/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10252040.0000 - mae: 2274.2241 - val_loss: 5930460.0000 - val_mae: 1785.6594\n",
      "Epoch 268/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11038618.0000 - mae: 2114.5911 - val_loss: 8891986.0000 - val_mae: 2261.4333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 269/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10953224.0000 - mae: 2261.4578 - val_loss: 8263413.5000 - val_mae: 2142.3584\n",
      "Epoch 270/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10990266.0000 - mae: 2259.5461 - val_loss: 7433758.0000 - val_mae: 2018.6016\n",
      "Epoch 271/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10779493.0000 - mae: 2274.7437 - val_loss: 6383916.0000 - val_mae: 1853.2803\n",
      "Epoch 272/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10945749.0000 - mae: 2184.1042 - val_loss: 7580333.0000 - val_mae: 2046.8842\n",
      "Epoch 273/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10896109.0000 - mae: 2205.6699 - val_loss: 7645131.5000 - val_mae: 2046.4320\n",
      "Epoch 274/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11012518.0000 - mae: 2223.4624 - val_loss: 7803225.0000 - val_mae: 2083.4385\n",
      "Epoch 275/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10865706.0000 - mae: 2269.3015 - val_loss: 7367692.5000 - val_mae: 2018.4170\n",
      "Epoch 276/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10830682.0000 - mae: 2227.6191 - val_loss: 6859884.5000 - val_mae: 1925.2294\n",
      "Epoch 277/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10791727.0000 - mae: 2182.6189 - val_loss: 7939123.0000 - val_mae: 2087.8889\n",
      "Epoch 278/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10904189.0000 - mae: 2262.9214 - val_loss: 6578740.0000 - val_mae: 1877.0372\n",
      "Epoch 279/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10535647.0000 - mae: 2188.5249 - val_loss: 9178616.0000 - val_mae: 2280.9475\n",
      "Epoch 280/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10772711.0000 - mae: 2271.5269 - val_loss: 7298683.0000 - val_mae: 1982.8300\n",
      "Epoch 281/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10895378.0000 - mae: 2177.7588 - val_loss: 7576264.0000 - val_mae: 2023.0977\n",
      "Epoch 282/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10627327.0000 - mae: 2217.5803 - val_loss: 8063627.5000 - val_mae: 2095.1960\n",
      "Epoch 283/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10399225.0000 - mae: 2224.9121 - val_loss: 5961425.0000 - val_mae: 1787.5737\n",
      "Epoch 284/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11013929.0000 - mae: 2242.6494 - val_loss: 7011463.0000 - val_mae: 1933.6399\n",
      "Epoch 285/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10836710.0000 - mae: 2204.9944 - val_loss: 7318141.5000 - val_mae: 1984.8998\n",
      "Epoch 286/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10725577.0000 - mae: 2220.0725 - val_loss: 6684853.0000 - val_mae: 1887.3367\n",
      "Epoch 287/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10669241.0000 - mae: 2252.7300 - val_loss: 6712992.5000 - val_mae: 1891.7778\n",
      "Epoch 288/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10954518.0000 - mae: 2198.0249 - val_loss: 6590683.0000 - val_mae: 1875.7955\n",
      "Epoch 289/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10450264.0000 - mae: 2211.3496 - val_loss: 6008178.0000 - val_mae: 1800.1268\n",
      "Epoch 290/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10880803.0000 - mae: 2196.2112 - val_loss: 6124786.0000 - val_mae: 1822.4097\n",
      "Epoch 291/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10655497.0000 - mae: 2205.3198 - val_loss: 8214580.5000 - val_mae: 2154.2212\n",
      "Epoch 292/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10412967.0000 - mae: 2276.2195 - val_loss: 6080763.0000 - val_mae: 1810.9995\n",
      "Epoch 293/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10759829.0000 - mae: 2170.5530 - val_loss: 7823922.5000 - val_mae: 2076.3755\n",
      "Epoch 294/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10501980.0000 - mae: 2268.0933 - val_loss: 7987667.0000 - val_mae: 2091.9673\n",
      "Epoch 295/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10879435.0000 - mae: 2263.6921 - val_loss: 6466386.0000 - val_mae: 1861.8330\n",
      "Epoch 296/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10750191.0000 - mae: 2239.8928 - val_loss: 6698021.5000 - val_mae: 1898.6768\n",
      "Epoch 297/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10963162.0000 - mae: 2214.7156 - val_loss: 6099146.5000 - val_mae: 1812.4882\n",
      "Epoch 298/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11064848.0000 - mae: 2188.4143 - val_loss: 7515896.5000 - val_mae: 2050.8618\n",
      "Epoch 299/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10524885.0000 - mae: 2241.6306 - val_loss: 6092742.0000 - val_mae: 1811.3810\n",
      "Epoch 300/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10948039.0000 - mae: 2145.7063 - val_loss: 7275127.0000 - val_mae: 2006.2979\n",
      "Epoch 301/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10444711.0000 - mae: 2184.9431 - val_loss: 9203083.0000 - val_mae: 2312.3887\n",
      "Epoch 302/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10525975.0000 - mae: 2198.1455 - val_loss: 8841043.0000 - val_mae: 2246.7791\n",
      "Epoch 303/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10713371.0000 - mae: 2271.9487 - val_loss: 8293720.5000 - val_mae: 2146.5156\n",
      "Epoch 304/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10504762.0000 - mae: 2278.6467 - val_loss: 5847351.5000 - val_mae: 1776.3295\n",
      "Epoch 305/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10876262.0000 - mae: 2191.8208 - val_loss: 6869709.5000 - val_mae: 1918.6012\n",
      "Epoch 306/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10490464.0000 - mae: 2204.8254 - val_loss: 6303680.5000 - val_mae: 1834.9467\n",
      "Epoch 307/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10364203.0000 - mae: 2071.6309 - val_loss: 9266108.0000 - val_mae: 2327.5811\n",
      "Epoch 308/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10654817.0000 - mae: 2302.6699 - val_loss: 6641383.5000 - val_mae: 1889.2876\n",
      "Epoch 309/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10418955.0000 - mae: 2202.3479 - val_loss: 7864580.0000 - val_mae: 2075.5273\n",
      "Epoch 310/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10438470.0000 - mae: 2225.7542 - val_loss: 6295393.0000 - val_mae: 1843.4058\n",
      "Epoch 311/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10640265.0000 - mae: 2263.1694 - val_loss: 6300060.5000 - val_mae: 1843.2627\n",
      "Epoch 312/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10779992.0000 - mae: 2216.6453 - val_loss: 6259771.0000 - val_mae: 1837.3259\n",
      "Epoch 313/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10566024.0000 - mae: 2263.4536 - val_loss: 6523380.0000 - val_mae: 1878.1423\n",
      "Epoch 314/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10519333.0000 - mae: 2139.1323 - val_loss: 5800600.0000 - val_mae: 1773.4191\n",
      "Epoch 315/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10947663.0000 - mae: 2192.9026 - val_loss: 7356055.5000 - val_mae: 2022.1036\n",
      "Epoch 316/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10616175.0000 - mae: 2224.7522 - val_loss: 5770882.5000 - val_mae: 1769.8668\n",
      "Epoch 317/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10831969.0000 - mae: 2215.6060 - val_loss: 7191843.5000 - val_mae: 2003.3888\n",
      "Epoch 318/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10533567.0000 - mae: 2291.3711 - val_loss: 6933737.0000 - val_mae: 1960.5618\n",
      "Epoch 319/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10528686.0000 - mae: 2234.3997 - val_loss: 6122629.5000 - val_mae: 1822.6233\n",
      "Epoch 320/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10540868.0000 - mae: 2263.9404 - val_loss: 6790849.5000 - val_mae: 1924.4695\n",
      "Epoch 321/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10675782.0000 - mae: 2230.6980 - val_loss: 7096597.0000 - val_mae: 1972.4993\n",
      "Epoch 322/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10414917.0000 - mae: 2202.4199 - val_loss: 6010896.0000 - val_mae: 1802.3741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10361710.0000 - mae: 2114.1113 - val_loss: 6579444.0000 - val_mae: 1895.1953\n",
      "Epoch 324/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10381772.0000 - mae: 2258.3467 - val_loss: 6129670.0000 - val_mae: 1814.2842\n",
      "Epoch 325/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10504150.0000 - mae: 2231.4741 - val_loss: 5864726.0000 - val_mae: 1774.6464\n",
      "Epoch 326/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10710776.0000 - mae: 2259.5093 - val_loss: 6510937.0000 - val_mae: 1871.0153\n",
      "Epoch 327/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10496251.0000 - mae: 2184.6907 - val_loss: 7057981.5000 - val_mae: 1950.7406\n",
      "Epoch 328/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10569511.0000 - mae: 2213.4629 - val_loss: 7212673.5000 - val_mae: 1973.2959\n",
      "Epoch 329/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10611069.0000 - mae: 2221.8584 - val_loss: 7583268.5000 - val_mae: 2021.4026\n",
      "Epoch 330/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10453873.0000 - mae: 2230.2847 - val_loss: 6563320.5000 - val_mae: 1878.7521\n",
      "Epoch 331/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10718229.0000 - mae: 2222.1697 - val_loss: 6390769.0000 - val_mae: 1846.0981\n",
      "Epoch 332/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10702375.0000 - mae: 2211.7390 - val_loss: 6824586.5000 - val_mae: 1911.5635\n",
      "Epoch 333/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10494894.0000 - mae: 2207.8960 - val_loss: 8062213.5000 - val_mae: 2118.6641\n",
      "Epoch 334/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10551940.0000 - mae: 2218.4414 - val_loss: 7365727.0000 - val_mae: 1994.1335\n",
      "Epoch 335/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10600546.0000 - mae: 2160.7451 - val_loss: 7855017.5000 - val_mae: 2060.7866\n",
      "Epoch 336/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10535165.0000 - mae: 2164.2773 - val_loss: 7921934.0000 - val_mae: 2076.9468\n",
      "Epoch 337/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10373923.0000 - mae: 2198.7036 - val_loss: 6290800.0000 - val_mae: 1824.7957\n",
      "Epoch 338/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10530056.0000 - mae: 2178.3787 - val_loss: 7241659.5000 - val_mae: 1943.7438\n",
      "Epoch 339/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10449368.0000 - mae: 2181.2366 - val_loss: 7392069.0000 - val_mae: 1993.7904\n",
      "Epoch 340/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10619048.0000 - mae: 2191.9944 - val_loss: 7694135.5000 - val_mae: 2040.4846\n",
      "Epoch 341/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10557599.0000 - mae: 2247.1016 - val_loss: 6493865.5000 - val_mae: 1852.9854\n",
      "Epoch 342/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10222437.0000 - mae: 2185.2056 - val_loss: 6177607.0000 - val_mae: 1818.6927\n",
      "Epoch 343/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10654235.0000 - mae: 2104.6084 - val_loss: 6694464.5000 - val_mae: 1893.3636\n",
      "Epoch 344/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10524152.0000 - mae: 2157.0996 - val_loss: 7846381.5000 - val_mae: 2076.9744\n",
      "Epoch 345/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10337765.0000 - mae: 2170.7686 - val_loss: 9190963.0000 - val_mae: 2336.6096\n",
      "Epoch 346/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10728520.0000 - mae: 2198.0120 - val_loss: 7531116.5000 - val_mae: 2029.9290\n",
      "Epoch 347/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10173554.0000 - mae: 2182.6057 - val_loss: 9260718.0000 - val_mae: 2351.5884\n",
      "Epoch 348/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10324032.0000 - mae: 2270.4656 - val_loss: 6074814.5000 - val_mae: 1806.3955\n",
      "Epoch 349/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10252803.0000 - mae: 2250.3254 - val_loss: 5902609.0000 - val_mae: 1785.1122\n",
      "Epoch 350/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10705279.0000 - mae: 2185.8530 - val_loss: 6799515.0000 - val_mae: 1925.5212\n",
      "Epoch 351/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10543560.0000 - mae: 2152.1521 - val_loss: 7012729.5000 - val_mae: 1960.9053\n",
      "Epoch 352/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10432549.0000 - mae: 2200.5698 - val_loss: 6661431.5000 - val_mae: 1887.9767\n",
      "Epoch 353/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10555199.0000 - mae: 2205.0679 - val_loss: 6649609.0000 - val_mae: 1879.5603\n",
      "Epoch 354/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10331163.0000 - mae: 2203.9460 - val_loss: 6196579.5000 - val_mae: 1814.1073\n",
      "Epoch 355/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10345879.0000 - mae: 2228.8362 - val_loss: 6645032.5000 - val_mae: 1878.2228\n",
      "Epoch 356/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10404566.0000 - mae: 2223.6091 - val_loss: 7150339.0000 - val_mae: 1946.9060\n",
      "Epoch 357/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10594587.0000 - mae: 2148.6948 - val_loss: 7186208.0000 - val_mae: 1973.9873\n",
      "Epoch 358/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10425542.0000 - mae: 2197.1616 - val_loss: 8254765.0000 - val_mae: 2168.3083\n",
      "Epoch 359/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10599170.0000 - mae: 2229.2246 - val_loss: 7142103.0000 - val_mae: 1975.8956\n",
      "Epoch 360/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10220860.0000 - mae: 2227.2314 - val_loss: 7375736.0000 - val_mae: 1995.9120\n",
      "Epoch 361/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10190157.0000 - mae: 2204.2952 - val_loss: 6225447.5000 - val_mae: 1821.7322\n",
      "Epoch 362/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10381249.0000 - mae: 2187.4973 - val_loss: 6827742.5000 - val_mae: 1917.4052\n",
      "Epoch 363/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10095829.0000 - mae: 2119.2263 - val_loss: 8456618.0000 - val_mae: 2206.9429\n",
      "Epoch 364/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9429489.0000 - mae: 2205.3767 - val_loss: 5406797.0000 - val_mae: 1711.8027\n",
      "Epoch 365/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10761390.0000 - mae: 2175.5132 - val_loss: 6788836.5000 - val_mae: 1913.7329\n",
      "Epoch 366/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10343107.0000 - mae: 2177.0837 - val_loss: 7552723.0000 - val_mae: 2044.9419\n",
      "Epoch 367/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10013184.0000 - mae: 2244.4683 - val_loss: 5561112.0000 - val_mae: 1737.6724\n",
      "Epoch 368/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10604051.0000 - mae: 2185.8484 - val_loss: 7471465.5000 - val_mae: 2050.9902\n",
      "Epoch 369/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10421595.0000 - mae: 2214.5278 - val_loss: 6089756.5000 - val_mae: 1822.9237\n",
      "Epoch 370/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10379442.0000 - mae: 2203.9636 - val_loss: 6299586.5000 - val_mae: 1844.4514\n",
      "Epoch 371/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10281377.0000 - mae: 2225.3938 - val_loss: 6799709.0000 - val_mae: 1913.4874\n",
      "Epoch 372/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10485135.0000 - mae: 2191.4260 - val_loss: 7073023.5000 - val_mae: 1956.3966\n",
      "Epoch 373/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10337801.0000 - mae: 2191.9812 - val_loss: 6244409.5000 - val_mae: 1824.4091\n",
      "Epoch 374/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10082829.0000 - mae: 2169.2856 - val_loss: 5711320.0000 - val_mae: 1751.3754\n",
      "Epoch 375/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10273811.0000 - mae: 2177.2039 - val_loss: 6851711.5000 - val_mae: 1908.3402\n",
      "Epoch 376/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10380369.0000 - mae: 2176.6108 - val_loss: 6478519.0000 - val_mae: 1860.9009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10245526.0000 - mae: 2192.7637 - val_loss: 7373813.0000 - val_mae: 1994.4977\n",
      "Epoch 378/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10248129.0000 - mae: 2233.9587 - val_loss: 6250724.0000 - val_mae: 1818.1274\n",
      "Epoch 379/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10282290.0000 - mae: 2150.1187 - val_loss: 7454624.0000 - val_mae: 2002.8768\n",
      "Epoch 380/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10022207.0000 - mae: 2193.5598 - val_loss: 6610614.0000 - val_mae: 1861.0245\n",
      "Epoch 381/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10103453.0000 - mae: 2227.7429 - val_loss: 5803774.5000 - val_mae: 1768.1110\n",
      "Epoch 382/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10187165.0000 - mae: 2165.8960 - val_loss: 6511304.5000 - val_mae: 1844.4432\n",
      "Epoch 383/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10371201.0000 - mae: 2170.5776 - val_loss: 7874401.5000 - val_mae: 2094.0281\n",
      "Epoch 384/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10250466.0000 - mae: 2141.9429 - val_loss: 6001049.0000 - val_mae: 1785.0093\n",
      "Epoch 385/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10158893.0000 - mae: 2125.3604 - val_loss: 5841807.0000 - val_mae: 1771.2720\n",
      "Epoch 386/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10524808.0000 - mae: 2142.3074 - val_loss: 6917572.0000 - val_mae: 1925.5295\n",
      "Epoch 387/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10066784.0000 - mae: 2180.1235 - val_loss: 8030650.5000 - val_mae: 2134.4543\n",
      "Epoch 388/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10421442.0000 - mae: 2145.3496 - val_loss: 6213337.5000 - val_mae: 1816.3564\n",
      "Epoch 389/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10312577.0000 - mae: 2081.5762 - val_loss: 6421788.0000 - val_mae: 1841.2263\n",
      "Epoch 390/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10304920.0000 - mae: 2169.2346 - val_loss: 6761019.5000 - val_mae: 1884.1750\n",
      "Epoch 391/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10095229.0000 - mae: 2168.3442 - val_loss: 5689789.0000 - val_mae: 1744.1553\n",
      "Epoch 392/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10361933.0000 - mae: 2129.3865 - val_loss: 7895675.5000 - val_mae: 2112.1086\n",
      "Epoch 393/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10227201.0000 - mae: 2203.5037 - val_loss: 7220388.5000 - val_mae: 1966.2271\n",
      "Epoch 394/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10130520.0000 - mae: 2159.9094 - val_loss: 7589876.5000 - val_mae: 2059.4402\n",
      "Epoch 395/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10135304.0000 - mae: 2217.2090 - val_loss: 7445102.5000 - val_mae: 2021.2877\n",
      "Epoch 396/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10162060.0000 - mae: 2191.5569 - val_loss: 6445979.0000 - val_mae: 1831.1919\n",
      "Epoch 397/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10074292.0000 - mae: 2137.8188 - val_loss: 7418748.5000 - val_mae: 2012.5745\n",
      "Epoch 398/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10089610.0000 - mae: 2191.1333 - val_loss: 6650812.5000 - val_mae: 1865.4896\n",
      "Epoch 399/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10186120.0000 - mae: 2194.8516 - val_loss: 6015579.5000 - val_mae: 1784.2764\n",
      "Epoch 400/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10070675.0000 - mae: 2140.6204 - val_loss: 7486744.0000 - val_mae: 2023.1886\n",
      "Epoch 401/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9996274.0000 - mae: 2205.1907 - val_loss: 6145969.5000 - val_mae: 1787.2640\n",
      "Epoch 402/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10211192.0000 - mae: 2176.0505 - val_loss: 5663976.5000 - val_mae: 1725.7683\n",
      "Epoch 403/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9856205.0000 - mae: 2100.1338 - val_loss: 8222260.5000 - val_mae: 2191.9934\n",
      "Epoch 404/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10399533.0000 - mae: 2171.2515 - val_loss: 7009158.5000 - val_mae: 1951.1783\n",
      "Epoch 405/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10113359.0000 - mae: 2188.9407 - val_loss: 5842585.5000 - val_mae: 1750.2731\n",
      "Epoch 406/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10149427.0000 - mae: 2157.9714 - val_loss: 6254564.0000 - val_mae: 1809.4209\n",
      "Epoch 407/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10073132.0000 - mae: 2143.9150 - val_loss: 7213981.0000 - val_mae: 1993.5990\n",
      "Epoch 408/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9965914.0000 - mae: 2098.7739 - val_loss: 7848723.5000 - val_mae: 2131.3083\n",
      "Epoch 409/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10120556.0000 - mae: 2140.6204 - val_loss: 6896928.0000 - val_mae: 1944.9347\n",
      "Epoch 410/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9924777.0000 - mae: 2102.5906 - val_loss: 7718221.0000 - val_mae: 2107.6787\n",
      "Epoch 411/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10136984.0000 - mae: 2219.4307 - val_loss: 6544370.0000 - val_mae: 1880.5281\n",
      "Epoch 412/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9984205.0000 - mae: 2106.7322 - val_loss: 8005264.0000 - val_mae: 2168.8992\n",
      "Epoch 413/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9976616.0000 - mae: 2167.3989 - val_loss: 8275974.5000 - val_mae: 2217.8108\n",
      "Epoch 414/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9467290.0000 - mae: 2188.1772 - val_loss: 5209395.0000 - val_mae: 1660.8260\n",
      "Epoch 415/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10460497.0000 - mae: 2155.4578 - val_loss: 6001179.0000 - val_mae: 1783.2017\n",
      "Epoch 416/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10111207.0000 - mae: 2155.3420 - val_loss: 6716962.5000 - val_mae: 1914.7153\n",
      "Epoch 417/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10239511.0000 - mae: 2155.8572 - val_loss: 6663412.0000 - val_mae: 1895.4279\n",
      "Epoch 418/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9801366.0000 - mae: 2138.0361 - val_loss: 9365352.0000 - val_mae: 2401.5415\n",
      "Epoch 419/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10110832.0000 - mae: 2197.1035 - val_loss: 6155868.0000 - val_mae: 1788.1466\n",
      "Epoch 420/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9918965.0000 - mae: 2102.8130 - val_loss: 7108993.0000 - val_mae: 1973.0336\n",
      "Epoch 421/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9939503.0000 - mae: 2154.6677 - val_loss: 8174371.0000 - val_mae: 2194.5339\n",
      "Epoch 422/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9972285.0000 - mae: 2205.6453 - val_loss: 6134973.0000 - val_mae: 1787.3928\n",
      "Epoch 423/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9637800.0000 - mae: 2140.3752 - val_loss: 5332980.0000 - val_mae: 1682.6061\n",
      "Epoch 424/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10192650.0000 - mae: 2167.9814 - val_loss: 6297779.0000 - val_mae: 1816.5342\n",
      "Epoch 425/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9708142.0000 - mae: 2171.4683 - val_loss: 5240683.0000 - val_mae: 1663.4915\n",
      "Epoch 426/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10036866.0000 - mae: 2136.8936 - val_loss: 5524559.5000 - val_mae: 1707.5710\n",
      "Epoch 427/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10323197.0000 - mae: 2111.3530 - val_loss: 6917459.0000 - val_mae: 1963.2797\n",
      "Epoch 428/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9871035.0000 - mae: 2240.6614 - val_loss: 6826974.0000 - val_mae: 1937.6823\n",
      "Epoch 429/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9679414.0000 - mae: 2197.3933 - val_loss: 5727247.5000 - val_mae: 1717.9379\n",
      "Epoch 430/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10062231.0000 - mae: 2175.8352 - val_loss: 5723881.0000 - val_mae: 1710.2997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 431/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10032278.0000 - mae: 2150.5051 - val_loss: 5566546.0000 - val_mae: 1705.9777\n",
      "Epoch 432/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10059158.0000 - mae: 2142.7146 - val_loss: 7008088.5000 - val_mae: 1965.5724\n",
      "Epoch 433/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9674595.0000 - mae: 2158.5000 - val_loss: 5739892.5000 - val_mae: 1726.9054\n",
      "Epoch 434/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9855735.0000 - mae: 2131.2898 - val_loss: 6078708.5000 - val_mae: 1781.2087\n",
      "Epoch 435/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9963069.0000 - mae: 2095.7607 - val_loss: 6303915.5000 - val_mae: 1838.1318\n",
      "Epoch 436/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10041864.0000 - mae: 2057.6021 - val_loss: 8106807.5000 - val_mae: 2204.8230\n",
      "Epoch 437/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9912120.0000 - mae: 2160.0598 - val_loss: 6514637.0000 - val_mae: 1887.0763\n",
      "Epoch 438/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9812243.0000 - mae: 2157.5950 - val_loss: 5479690.0000 - val_mae: 1699.9340\n",
      "Epoch 439/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9987509.0000 - mae: 2100.7002 - val_loss: 6912330.0000 - val_mae: 1965.9122\n",
      "Epoch 440/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10006648.0000 - mae: 2145.9712 - val_loss: 5534758.0000 - val_mae: 1704.5343\n",
      "Epoch 441/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10235975.0000 - mae: 2101.5286 - val_loss: 6098135.0000 - val_mae: 1822.5297\n",
      "Epoch 442/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9547391.0000 - mae: 2140.7192 - val_loss: 5072336.5000 - val_mae: 1642.6187\n",
      "Epoch 443/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10338159.0000 - mae: 2148.1250 - val_loss: 6058535.5000 - val_mae: 1818.8663\n",
      "Epoch 444/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10139022.0000 - mae: 2127.8320 - val_loss: 6769561.0000 - val_mae: 1960.4159\n",
      "Epoch 445/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9885105.0000 - mae: 2189.0759 - val_loss: 5885792.0000 - val_mae: 1770.0289\n",
      "Epoch 446/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9806038.0000 - mae: 2088.6064 - val_loss: 7000374.5000 - val_mae: 2009.4795\n",
      "Epoch 447/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9348058.0000 - mae: 2216.3770 - val_loss: 5317554.5000 - val_mae: 1667.1321\n",
      "Epoch 448/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9991226.0000 - mae: 2095.1309 - val_loss: 5860120.5000 - val_mae: 1765.7627\n",
      "Epoch 449/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9713062.0000 - mae: 2194.3992 - val_loss: 5649898.0000 - val_mae: 1727.9385\n",
      "Epoch 450/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9933935.0000 - mae: 2095.3230 - val_loss: 5896710.0000 - val_mae: 1788.6913\n",
      "Epoch 451/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9705480.0000 - mae: 2116.1074 - val_loss: 6400249.5000 - val_mae: 1905.7592\n",
      "Epoch 452/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9608307.0000 - mae: 2067.4792 - val_loss: 7504992.0000 - val_mae: 2118.3958\n",
      "Epoch 453/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9531040.0000 - mae: 2173.8730 - val_loss: 5289841.5000 - val_mae: 1646.5699\n",
      "Epoch 454/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9701283.0000 - mae: 2161.3708 - val_loss: 5704431.0000 - val_mae: 1739.1855\n",
      "Epoch 455/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9611705.0000 - mae: 2110.1589 - val_loss: 7337256.0000 - val_mae: 2099.4209\n",
      "Epoch 456/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9460106.0000 - mae: 2114.2026 - val_loss: 6848820.0000 - val_mae: 1982.4520\n",
      "Epoch 457/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9168806.0000 - mae: 2111.2603 - val_loss: 5065151.0000 - val_mae: 1615.9786\n",
      "Epoch 458/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9899897.0000 - mae: 2079.2478 - val_loss: 6226191.5000 - val_mae: 1869.4235\n",
      "Epoch 459/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9252666.0000 - mae: 2148.1326 - val_loss: 5462995.0000 - val_mae: 1691.0625\n",
      "Epoch 460/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9651012.0000 - mae: 2085.6763 - val_loss: 5767284.0000 - val_mae: 1773.1377\n",
      "Epoch 461/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9557365.0000 - mae: 2182.2156 - val_loss: 5692920.0000 - val_mae: 1747.6362\n",
      "Epoch 462/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9532859.0000 - mae: 2098.7234 - val_loss: 6979351.0000 - val_mae: 2016.4833\n",
      "Epoch 463/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9554475.0000 - mae: 2088.9629 - val_loss: 8752439.0000 - val_mae: 2354.4197\n",
      "Epoch 464/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9693982.0000 - mae: 2168.9924 - val_loss: 5642511.0000 - val_mae: 1739.2035\n",
      "Epoch 465/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9565899.0000 - mae: 2143.0823 - val_loss: 6200177.5000 - val_mae: 1862.7764\n",
      "Epoch 466/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9554198.0000 - mae: 2090.0046 - val_loss: 5994827.5000 - val_mae: 1829.0540\n",
      "Epoch 467/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9749715.0000 - mae: 2100.7461 - val_loss: 5775235.0000 - val_mae: 1801.1320\n",
      "Epoch 468/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9459085.0000 - mae: 2110.5388 - val_loss: 5720510.5000 - val_mae: 1775.0548\n",
      "Epoch 469/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9539848.0000 - mae: 2107.7876 - val_loss: 6137199.0000 - val_mae: 1861.1573\n",
      "Epoch 470/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9450848.0000 - mae: 2147.0488 - val_loss: 5548743.0000 - val_mae: 1742.4263\n",
      "Epoch 471/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9629631.0000 - mae: 2111.3926 - val_loss: 6175321.5000 - val_mae: 1882.4833\n",
      "Epoch 472/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9569030.0000 - mae: 2085.7297 - val_loss: 6645575.0000 - val_mae: 1970.8773\n",
      "Epoch 473/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9438673.0000 - mae: 2154.4636 - val_loss: 5531367.5000 - val_mae: 1709.2192\n",
      "Epoch 474/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9466680.0000 - mae: 2132.6436 - val_loss: 6244895.0000 - val_mae: 1880.8516\n",
      "Epoch 475/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9403974.0000 - mae: 2088.1719 - val_loss: 6037336.5000 - val_mae: 1837.2666\n",
      "Epoch 476/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9482176.0000 - mae: 2159.1248 - val_loss: 5214588.5000 - val_mae: 1647.6826\n",
      "Epoch 477/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9372829.0000 - mae: 2076.7449 - val_loss: 4818380.0000 - val_mae: 1577.1969\n",
      "Epoch 478/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9707390.0000 - mae: 2091.2542 - val_loss: 5978939.0000 - val_mae: 1848.7198\n",
      "Epoch 479/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9601666.0000 - mae: 2032.4575 - val_loss: 4950844.0000 - val_mae: 1593.3252\n",
      "Epoch 480/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9146791.0000 - mae: 2115.6189 - val_loss: 6190852.5000 - val_mae: 1876.5044\n",
      "Epoch 481/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9091603.0000 - mae: 2069.2021 - val_loss: 5319237.5000 - val_mae: 1688.9941\n",
      "Epoch 482/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9427784.0000 - mae: 2096.8254 - val_loss: 6039042.0000 - val_mae: 1838.3527\n",
      "Epoch 483/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 8856504.0000 - mae: 2074.85 - 0s 1ms/step - loss: 9124216.0000 - mae: 2141.0229 - val_loss: 5083322.5000 - val_mae: 1622.9412\n",
      "Epoch 484/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9271865.0000 - mae: 2103.3162 - val_loss: 6726220.0000 - val_mae: 1993.3911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9428056.0000 - mae: 2102.6162 - val_loss: 5710660.0000 - val_mae: 1775.0355\n",
      "Epoch 486/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9137168.0000 - mae: 2123.8596 - val_loss: 6015680.5000 - val_mae: 1829.8359\n",
      "Epoch 487/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9250542.0000 - mae: 2068.4175 - val_loss: 6468868.0000 - val_mae: 1939.0503\n",
      "Epoch 488/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9244946.0000 - mae: 2134.8337 - val_loss: 5640966.0000 - val_mae: 1759.1680\n",
      "Epoch 489/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8635448.0000 - mae: 2142.5835 - val_loss: 4649403.0000 - val_mae: 1550.3763\n",
      "Epoch 490/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9531412.0000 - mae: 2090.9336 - val_loss: 5414821.5000 - val_mae: 1714.4111\n",
      "Epoch 491/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9513969.0000 - mae: 2067.4988 - val_loss: 5540850.5000 - val_mae: 1739.7299\n",
      "Epoch 492/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9400536.0000 - mae: 2106.3091 - val_loss: 5346724.0000 - val_mae: 1696.6416\n",
      "Epoch 493/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9432680.0000 - mae: 2122.6440 - val_loss: 5431401.0000 - val_mae: 1727.7183\n",
      "Epoch 494/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9331320.0000 - mae: 2097.1086 - val_loss: 5076056.0000 - val_mae: 1634.7664\n",
      "Epoch 495/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9242218.0000 - mae: 2078.0764 - val_loss: 5806198.5000 - val_mae: 1790.3971\n",
      "Epoch 496/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9090903.0000 - mae: 2108.3264 - val_loss: 6166188.0000 - val_mae: 1881.3805\n",
      "Epoch 497/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9224851.0000 - mae: 2091.6228 - val_loss: 5878021.5000 - val_mae: 1821.0073\n",
      "Epoch 498/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9132108.0000 - mae: 2104.7759 - val_loss: 4936111.0000 - val_mae: 1595.8954\n",
      "Epoch 499/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9352646.0000 - mae: 2065.6099 - val_loss: 5241746.5000 - val_mae: 1679.4169\n",
      "Epoch 500/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9187431.0000 - mae: 2048.7219 - val_loss: 5179364.0000 - val_mae: 1658.0693\n",
      "processing fold # 1\n",
      "Epoch 1/500\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 181496192.0000 - mae: 11940.7344 - val_loss: 243534448.0000 - val_mae: 13123.1611\n",
      "Epoch 2/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 170146272.0000 - mae: 11441.2549 - val_loss: 226221968.0000 - val_mae: 12466.8125\n",
      "Epoch 3/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 150040096.0000 - mae: 10513.9717 - val_loss: 195690192.0000 - val_mae: 11221.9824\n",
      "Epoch 4/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 119440608.0000 - mae: 8994.3398 - val_loss: 158631728.0000 - val_mae: 9505.0547\n",
      "Epoch 5/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 87446392.0000 - mae: 7050.7715 - val_loss: 119759480.0000 - val_mae: 7460.3574\n",
      "Epoch 6/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 56527072.0000 - mae: 5091.7891 - val_loss: 85456568.0000 - val_mae: 5981.7212\n",
      "Epoch 7/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42336588.0000 - mae: 4207.9600 - val_loss: 71460888.0000 - val_mae: 5477.8179\n",
      "Epoch 8/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36368096.0000 - mae: 4193.7256 - val_loss: 66071008.0000 - val_mae: 5377.9702\n",
      "Epoch 9/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 35061800.0000 - mae: 4131.2168 - val_loss: 63658180.0000 - val_mae: 5394.3848\n",
      "Epoch 10/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34873784.0000 - mae: 4172.5200 - val_loss: 63304124.0000 - val_mae: 5394.5103\n",
      "Epoch 11/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34119404.0000 - mae: 4187.4707 - val_loss: 63598940.0000 - val_mae: 5370.2974\n",
      "Epoch 12/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34339524.0000 - mae: 4169.8496 - val_loss: 62634516.0000 - val_mae: 5391.2925\n",
      "Epoch 13/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34111464.0000 - mae: 4142.2192 - val_loss: 61684880.0000 - val_mae: 5420.7607\n",
      "Epoch 14/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33924568.0000 - mae: 4172.2832 - val_loss: 61446780.0000 - val_mae: 5415.5664\n",
      "Epoch 15/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33200414.0000 - mae: 4213.3755 - val_loss: 63463628.0000 - val_mae: 5323.4639\n",
      "Epoch 16/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34079280.0000 - mae: 4115.0264 - val_loss: 62217744.0000 - val_mae: 5349.2832\n",
      "Epoch 17/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33287428.0000 - mae: 4215.3320 - val_loss: 61995960.0000 - val_mae: 5341.0156\n",
      "Epoch 18/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33239278.0000 - mae: 4067.2458 - val_loss: 60588828.0000 - val_mae: 5391.8267\n",
      "Epoch 19/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33367156.0000 - mae: 4140.1763 - val_loss: 60991640.0000 - val_mae: 5355.6406\n",
      "Epoch 20/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33481314.0000 - mae: 4064.0156 - val_loss: 61313260.0000 - val_mae: 5327.3604\n",
      "Epoch 21/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32917760.0000 - mae: 4140.5444 - val_loss: 61591160.0000 - val_mae: 5299.1909\n",
      "Epoch 22/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32690564.0000 - mae: 4137.2676 - val_loss: 62050644.0000 - val_mae: 5269.7720\n",
      "Epoch 23/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32690474.0000 - mae: 4115.2739 - val_loss: 61456028.0000 - val_mae: 5270.6357\n",
      "Epoch 24/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32622246.0000 - mae: 4107.4629 - val_loss: 61082264.0000 - val_mae: 5269.0527\n",
      "Epoch 25/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32600538.0000 - mae: 4080.1812 - val_loss: 60684256.0000 - val_mae: 5268.5254\n",
      "Epoch 26/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32373722.0000 - mae: 4052.1177 - val_loss: 60518800.0000 - val_mae: 5260.2505\n",
      "Epoch 27/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32481988.0000 - mae: 4006.9526 - val_loss: 59965948.0000 - val_mae: 5269.5820\n",
      "Epoch 28/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32130168.0000 - mae: 4041.5059 - val_loss: 59231492.0000 - val_mae: 5283.8286\n",
      "Epoch 29/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31824504.0000 - mae: 4064.2178 - val_loss: 58892532.0000 - val_mae: 5281.0854\n",
      "Epoch 30/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31555844.0000 - mae: 4071.2041 - val_loss: 59405164.0000 - val_mae: 5239.5166\n",
      "Epoch 31/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31857784.0000 - mae: 3960.0083 - val_loss: 58568732.0000 - val_mae: 5259.6548\n",
      "Epoch 32/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31362612.0000 - mae: 3981.0046 - val_loss: 57715408.0000 - val_mae: 5281.7148\n",
      "Epoch 33/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31207838.0000 - mae: 4067.5391 - val_loss: 57966996.0000 - val_mae: 5250.0024\n",
      "Epoch 34/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31143960.0000 - mae: 4025.6223 - val_loss: 58079736.0000 - val_mae: 5226.6040\n",
      "Epoch 35/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 31012122.0000 - mae: 3998.9673 - val_loss: 57508220.0000 - val_mae: 5232.6792\n",
      "Epoch 36/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30600458.0000 - mae: 4040.7390 - val_loss: 58368232.0000 - val_mae: 5178.0654\n",
      "Epoch 37/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30892624.0000 - mae: 3934.7854 - val_loss: 57464136.0000 - val_mae: 5198.9600\n",
      "Epoch 38/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30854768.0000 - mae: 3914.8809 - val_loss: 57875240.0000 - val_mae: 5165.2637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30440626.0000 - mae: 3972.5151 - val_loss: 57140028.0000 - val_mae: 5177.1660\n",
      "Epoch 40/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30535784.0000 - mae: 3908.2395 - val_loss: 56998552.0000 - val_mae: 5165.8999\n",
      "Epoch 41/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30161772.0000 - mae: 3930.6365 - val_loss: 57487784.0000 - val_mae: 5127.8125\n",
      "Epoch 42/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30084320.0000 - mae: 3917.4521 - val_loss: 56861132.0000 - val_mae: 5135.4038\n",
      "Epoch 43/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30300034.0000 - mae: 3874.2151 - val_loss: 56788404.0000 - val_mae: 5123.4326\n",
      "Epoch 44/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29610056.0000 - mae: 3891.2913 - val_loss: 57954016.0000 - val_mae: 5065.4927\n",
      "Epoch 45/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29949770.0000 - mae: 3840.3232 - val_loss: 56414916.0000 - val_mae: 5104.8149\n",
      "Epoch 46/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29495410.0000 - mae: 3872.7224 - val_loss: 56341752.0000 - val_mae: 5091.9458\n",
      "Epoch 47/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29608054.0000 - mae: 3862.6704 - val_loss: 56331764.0000 - val_mae: 5074.6895\n",
      "Epoch 48/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29256014.0000 - mae: 3854.5200 - val_loss: 56084516.0000 - val_mae: 5067.5977\n",
      "Epoch 49/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29270622.0000 - mae: 3823.1619 - val_loss: 55413964.0000 - val_mae: 5074.5430\n",
      "Epoch 50/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29079506.0000 - mae: 3824.3848 - val_loss: 55300976.0000 - val_mae: 5060.2300\n",
      "Epoch 51/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29051856.0000 - mae: 3798.3621 - val_loss: 54926068.0000 - val_mae: 5056.3140\n",
      "Epoch 52/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 28636178.0000 - mae: 3839.4417 - val_loss: 54677460.0000 - val_mae: 5046.6553\n",
      "Epoch 53/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 28627028.0000 - mae: 3797.3730 - val_loss: 55143012.0000 - val_mae: 5010.4517\n",
      "Epoch 54/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 28524880.0000 - mae: 3750.8708 - val_loss: 53769224.0000 - val_mae: 5045.6602\n",
      "Epoch 55/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 28340156.0000 - mae: 3776.2122 - val_loss: 53939160.0000 - val_mae: 5020.6924\n",
      "Epoch 56/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27908232.0000 - mae: 3806.4426 - val_loss: 54063356.0000 - val_mae: 4995.7744\n",
      "Epoch 57/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27960678.0000 - mae: 3758.4536 - val_loss: 53985772.0000 - val_mae: 4979.1338\n",
      "Epoch 58/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27977256.0000 - mae: 3689.9980 - val_loss: 52906348.0000 - val_mae: 5001.7261\n",
      "Epoch 59/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27652556.0000 - mae: 3727.5190 - val_loss: 52894500.0000 - val_mae: 4981.8447\n",
      "Epoch 60/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27232574.0000 - mae: 3734.0706 - val_loss: 53853732.0000 - val_mae: 4924.5713\n",
      "Epoch 61/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27566142.0000 - mae: 3634.5066 - val_loss: 52284080.0000 - val_mae: 4965.6304\n",
      "Epoch 62/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 27128628.0000 - mae: 3711.4585 - val_loss: 51585280.0000 - val_mae: 4973.2368\n",
      "Epoch 63/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26858448.0000 - mae: 3749.4702 - val_loss: 51522660.0000 - val_mae: 4951.7578\n",
      "Epoch 64/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26610172.0000 - mae: 3722.7832 - val_loss: 51489752.0000 - val_mae: 4928.4331\n",
      "Epoch 65/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26552438.0000 - mae: 3685.7676 - val_loss: 51525208.0000 - val_mae: 4903.7251\n",
      "Epoch 66/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26602056.0000 - mae: 3639.7063 - val_loss: 51371536.0000 - val_mae: 4888.8311\n",
      "Epoch 67/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26324976.0000 - mae: 3656.3735 - val_loss: 51264648.0000 - val_mae: 4869.8843\n",
      "Epoch 68/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25977816.0000 - mae: 3551.5532 - val_loss: 49789196.0000 - val_mae: 4903.6992\n",
      "Epoch 69/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25861074.0000 - mae: 3655.2651 - val_loss: 50163136.0000 - val_mae: 4862.7539\n",
      "Epoch 70/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25749434.0000 - mae: 3611.2832 - val_loss: 50229528.0000 - val_mae: 4838.0557\n",
      "Epoch 71/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25623870.0000 - mae: 3551.3105 - val_loss: 49350432.0000 - val_mae: 4846.5615\n",
      "Epoch 72/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24766992.0000 - mae: 3603.6584 - val_loss: 51674252.0000 - val_mae: 4746.1885\n",
      "Epoch 73/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25571002.0000 - mae: 3527.5398 - val_loss: 49659972.0000 - val_mae: 4791.4634\n",
      "Epoch 74/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25049964.0000 - mae: 3547.2549 - val_loss: 49090276.0000 - val_mae: 4785.4478\n",
      "Epoch 75/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24805890.0000 - mae: 3558.6145 - val_loss: 49096524.0000 - val_mae: 4760.7231\n",
      "Epoch 76/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24793094.0000 - mae: 3449.1670 - val_loss: 48235660.0000 - val_mae: 4766.6475\n",
      "Epoch 77/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24479294.0000 - mae: 3470.8584 - val_loss: 47503164.0000 - val_mae: 4769.9414\n",
      "Epoch 78/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24233498.0000 - mae: 3520.3616 - val_loss: 47000476.0000 - val_mae: 4762.4780\n",
      "Epoch 79/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23995506.0000 - mae: 3536.7861 - val_loss: 47045408.0000 - val_mae: 4729.6704\n",
      "Epoch 80/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23874400.0000 - mae: 3406.8728 - val_loss: 46417632.0000 - val_mae: 4726.1133\n",
      "Epoch 81/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23752180.0000 - mae: 3436.7820 - val_loss: 46421600.0000 - val_mae: 4698.4087\n",
      "Epoch 82/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23420694.0000 - mae: 3432.2402 - val_loss: 45967096.0000 - val_mae: 4687.2217\n",
      "Epoch 83/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23297148.0000 - mae: 3418.6335 - val_loss: 45933660.0000 - val_mae: 4658.5859\n",
      "Epoch 84/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 22757294.0000 - mae: 3422.0947 - val_loss: 46929488.0000 - val_mae: 4594.7866\n",
      "Epoch 85/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 22652642.0000 - mae: 3431.3623 - val_loss: 47113548.0000 - val_mae: 4558.7930\n",
      "Epoch 86/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23040294.0000 - mae: 3297.2996 - val_loss: 45813124.0000 - val_mae: 4572.4727\n",
      "Epoch 87/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 22433000.0000 - mae: 3317.7271 - val_loss: 46237724.0000 - val_mae: 4530.5708\n",
      "Epoch 88/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 22264274.0000 - mae: 3227.9646 - val_loss: 44052284.0000 - val_mae: 4572.3164\n",
      "Epoch 89/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 21907328.0000 - mae: 3317.8948 - val_loss: 43425760.0000 - val_mae: 4548.5747\n",
      "Epoch 90/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 21262850.0000 - mae: 3332.7983 - val_loss: 43530392.0000 - val_mae: 4456.9761\n",
      "Epoch 91/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 21061566.0000 - mae: 3207.0327 - val_loss: 43001020.0000 - val_mae: 4423.8330\n",
      "Epoch 92/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20749212.0000 - mae: 3122.8650 - val_loss: 42623572.0000 - val_mae: 4391.0977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20507634.0000 - mae: 3089.8425 - val_loss: 41500516.0000 - val_mae: 4392.4985\n",
      "Epoch 94/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20074750.0000 - mae: 3170.9587 - val_loss: 42213516.0000 - val_mae: 4321.7002\n",
      "Epoch 95/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20457018.0000 - mae: 3006.0085 - val_loss: 42490112.0000 - val_mae: 4282.5107\n",
      "Epoch 96/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 19549844.0000 - mae: 3090.8750 - val_loss: 42252708.0000 - val_mae: 4244.1406\n",
      "Epoch 97/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 19430680.0000 - mae: 3077.7961 - val_loss: 40936984.0000 - val_mae: 4240.1592\n",
      "Epoch 98/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 19247938.0000 - mae: 3006.6831 - val_loss: 39901832.0000 - val_mae: 4232.4351\n",
      "Epoch 99/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 18736638.0000 - mae: 3008.0193 - val_loss: 40074652.0000 - val_mae: 4179.8721\n",
      "Epoch 100/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 18674608.0000 - mae: 2920.7537 - val_loss: 38907400.0000 - val_mae: 4178.1885\n",
      "Epoch 101/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 18171408.0000 - mae: 2928.0193 - val_loss: 38308072.0000 - val_mae: 4147.9302\n",
      "Epoch 102/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 17894640.0000 - mae: 2919.6570 - val_loss: 38423140.0000 - val_mae: 4088.9844\n",
      "Epoch 103/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 17766572.0000 - mae: 2881.7871 - val_loss: 39270792.0000 - val_mae: 4022.8772\n",
      "Epoch 104/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 17339036.0000 - mae: 2716.4260 - val_loss: 36217184.0000 - val_mae: 4086.2793\n",
      "Epoch 105/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 17108054.0000 - mae: 2818.6135 - val_loss: 35984040.0000 - val_mae: 4044.8796\n",
      "Epoch 106/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 16298114.0000 - mae: 2882.1191 - val_loss: 37776032.0000 - val_mae: 3923.5718\n",
      "Epoch 107/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 16702432.0000 - mae: 2661.6890 - val_loss: 35122472.0000 - val_mae: 3973.6152\n",
      "Epoch 108/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 16003799.0000 - mae: 2712.2971 - val_loss: 33571256.0000 - val_mae: 4013.9724\n",
      "Epoch 109/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 15917286.0000 - mae: 2742.5376 - val_loss: 33080238.0000 - val_mae: 3982.8188\n",
      "Epoch 110/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 15771286.0000 - mae: 2682.9678 - val_loss: 33447150.0000 - val_mae: 3893.2417\n",
      "Epoch 111/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 15220824.0000 - mae: 2754.4883 - val_loss: 34353196.0000 - val_mae: 3779.1233\n",
      "Epoch 112/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14941211.0000 - mae: 2592.0430 - val_loss: 32624508.0000 - val_mae: 3768.9929\n",
      "Epoch 113/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14670379.0000 - mae: 2639.5571 - val_loss: 32641536.0000 - val_mae: 3696.7695\n",
      "Epoch 114/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14390622.0000 - mae: 2592.3967 - val_loss: 32991948.0000 - val_mae: 3629.0190\n",
      "Epoch 115/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14335234.0000 - mae: 2475.5947 - val_loss: 30813388.0000 - val_mae: 3689.3152\n",
      "Epoch 116/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13900246.0000 - mae: 2515.6641 - val_loss: 31664140.0000 - val_mae: 3566.3396\n",
      "Epoch 117/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13394056.0000 - mae: 2475.4375 - val_loss: 29610010.0000 - val_mae: 3631.8198\n",
      "Epoch 118/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13310840.0000 - mae: 2559.7830 - val_loss: 30275976.0000 - val_mae: 3515.0886\n",
      "Epoch 119/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13312957.0000 - mae: 2399.9365 - val_loss: 29623990.0000 - val_mae: 3514.4541\n",
      "Epoch 120/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12708736.0000 - mae: 2463.3921 - val_loss: 30395044.0000 - val_mae: 3404.3994\n",
      "Epoch 121/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12940229.0000 - mae: 2351.4043 - val_loss: 29351866.0000 - val_mae: 3402.6553\n",
      "Epoch 122/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12726300.0000 - mae: 2360.5991 - val_loss: 29033890.0000 - val_mae: 3371.9219\n",
      "Epoch 123/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 10746727.0000 - mae: 2219.197 - 0s 1ms/step - loss: 12392670.0000 - mae: 2325.7285 - val_loss: 26884040.0000 - val_mae: 3492.8713\n",
      "Epoch 124/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12187247.0000 - mae: 2424.7368 - val_loss: 27625456.0000 - val_mae: 3354.1716\n",
      "Epoch 125/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11576571.0000 - mae: 2369.5056 - val_loss: 29321102.0000 - val_mae: 3222.6353\n",
      "Epoch 126/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12157186.0000 - mae: 2304.4929 - val_loss: 28032106.0000 - val_mae: 3223.2544\n",
      "Epoch 127/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11830322.0000 - mae: 2325.7358 - val_loss: 27224768.0000 - val_mae: 3217.6287\n",
      "Epoch 128/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11688394.0000 - mae: 2243.3425 - val_loss: 26437560.0000 - val_mae: 3225.9875\n",
      "Epoch 129/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11457995.0000 - mae: 2297.8169 - val_loss: 25494668.0000 - val_mae: 3241.5151\n",
      "Epoch 130/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11509906.0000 - mae: 2226.8752 - val_loss: 25040086.0000 - val_mae: 3252.5513\n",
      "Epoch 131/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11267470.0000 - mae: 2249.4900 - val_loss: 24775138.0000 - val_mae: 3225.7109\n",
      "Epoch 132/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11132134.0000 - mae: 2280.5928 - val_loss: 24450862.0000 - val_mae: 3201.8740\n",
      "Epoch 133/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10752001.0000 - mae: 2260.4739 - val_loss: 25735708.0000 - val_mae: 3098.8794\n",
      "Epoch 134/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10934344.0000 - mae: 2213.6157 - val_loss: 23901668.0000 - val_mae: 3178.2969\n",
      "Epoch 135/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10610764.0000 - mae: 2293.0342 - val_loss: 25449370.0000 - val_mae: 3058.0566\n",
      "Epoch 136/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10809669.0000 - mae: 2157.7815 - val_loss: 23609564.0000 - val_mae: 3111.9705\n",
      "Epoch 137/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10680408.0000 - mae: 2259.1133 - val_loss: 24059472.0000 - val_mae: 3052.8350\n",
      "Epoch 138/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10498301.0000 - mae: 2229.2512 - val_loss: 24838614.0000 - val_mae: 3018.3889\n",
      "Epoch 139/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10709256.0000 - mae: 2186.0208 - val_loss: 24510740.0000 - val_mae: 3015.1870\n",
      "Epoch 140/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10475245.0000 - mae: 2210.9595 - val_loss: 23685766.0000 - val_mae: 3017.5510\n",
      "Epoch 141/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10408416.0000 - mae: 2157.3533 - val_loss: 22954200.0000 - val_mae: 3023.8457\n",
      "Epoch 142/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10502431.0000 - mae: 2179.8848 - val_loss: 22934242.0000 - val_mae: 3009.1636\n",
      "Epoch 143/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10425628.0000 - mae: 2151.3049 - val_loss: 22189298.0000 - val_mae: 3034.3242\n",
      "Epoch 144/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10228915.0000 - mae: 2253.5830 - val_loss: 23094934.0000 - val_mae: 2976.9187\n",
      "Epoch 145/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10177020.0000 - mae: 2175.0044 - val_loss: 22318944.0000 - val_mae: 2984.5928\n",
      "Epoch 146/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 10170965.0000 - mae: 2136.0305 - val_loss: 22113480.0000 - val_mae: 2978.0449\n",
      "Epoch 147/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10086621.0000 - mae: 2203.0579 - val_loss: 22599670.0000 - val_mae: 2947.2339\n",
      "Epoch 148/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10185720.0000 - mae: 2150.0183 - val_loss: 22595066.0000 - val_mae: 2941.4006\n",
      "Epoch 149/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9759114.0000 - mae: 2192.8005 - val_loss: 24039212.0000 - val_mae: 2903.9917\n",
      "Epoch 150/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10093175.0000 - mae: 2095.3611 - val_loss: 21183382.0000 - val_mae: 2985.3547\n",
      "Epoch 151/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9855682.0000 - mae: 2186.7954 - val_loss: 22012256.0000 - val_mae: 2921.7043\n",
      "Epoch 152/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9747525.0000 - mae: 2193.0083 - val_loss: 23887590.0000 - val_mae: 2878.6416\n",
      "Epoch 153/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10234576.0000 - mae: 2073.5332 - val_loss: 21463822.0000 - val_mae: 2921.1147\n",
      "Epoch 154/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9964943.0000 - mae: 2093.7915 - val_loss: 21293090.0000 - val_mae: 2913.3682\n",
      "Epoch 155/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9900208.0000 - mae: 2173.4280 - val_loss: 21943246.0000 - val_mae: 2882.7954\n",
      "Epoch 156/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9723375.0000 - mae: 2104.1172 - val_loss: 20455700.0000 - val_mae: 2934.4019\n",
      "Epoch 157/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10047707.0000 - mae: 2095.8447 - val_loss: 20841258.0000 - val_mae: 2902.3921\n",
      "Epoch 158/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 9706315.0000 - mae: 2179.14 - 0s 1ms/step - loss: 9523165.0000 - mae: 2137.5762 - val_loss: 22928928.0000 - val_mae: 2844.4551\n",
      "Epoch 159/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9723704.0000 - mae: 2063.0488 - val_loss: 20455238.0000 - val_mae: 2914.3809\n",
      "Epoch 160/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9755871.0000 - mae: 2184.6067 - val_loss: 21705636.0000 - val_mae: 2853.4155\n",
      "Epoch 161/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9466812.0000 - mae: 2079.6653 - val_loss: 19756840.0000 - val_mae: 2942.2068\n",
      "Epoch 162/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9824833.0000 - mae: 2185.8281 - val_loss: 20328320.0000 - val_mae: 2879.2559\n",
      "Epoch 163/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9552746.0000 - mae: 2132.9065 - val_loss: 19862162.0000 - val_mae: 2903.2283\n",
      "Epoch 164/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9692611.0000 - mae: 2166.0474 - val_loss: 20201576.0000 - val_mae: 2866.0100\n",
      "Epoch 165/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9617479.0000 - mae: 2144.1660 - val_loss: 20726124.0000 - val_mae: 2841.9189\n",
      "Epoch 166/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9487569.0000 - mae: 2185.4009 - val_loss: 21828636.0000 - val_mae: 2806.3472\n",
      "Epoch 167/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9639848.0000 - mae: 2135.5684 - val_loss: 21253174.0000 - val_mae: 2804.8513\n",
      "Epoch 168/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9475688.0000 - mae: 2136.7668 - val_loss: 20369880.0000 - val_mae: 2824.7012\n",
      "Epoch 169/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9473418.0000 - mae: 2183.0793 - val_loss: 21611018.0000 - val_mae: 2792.3984\n",
      "Epoch 170/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9366722.0000 - mae: 2026.8849 - val_loss: 19910092.0000 - val_mae: 2841.5527\n",
      "Epoch 171/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9550195.0000 - mae: 2151.1421 - val_loss: 20876508.0000 - val_mae: 2801.0342\n",
      "Epoch 172/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 4242586.0000 - mae: 2059.75 - 0s 1ms/step - loss: 9318476.0000 - mae: 2189.2676 - val_loss: 21766254.0000 - val_mae: 2792.5171\n",
      "Epoch 173/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9611432.0000 - mae: 2108.7932 - val_loss: 20278362.0000 - val_mae: 2815.7280\n",
      "Epoch 174/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9520248.0000 - mae: 2099.7446 - val_loss: 20161822.0000 - val_mae: 2805.1262\n",
      "Epoch 175/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9404865.0000 - mae: 2174.9785 - val_loss: 20422454.0000 - val_mae: 2788.2141\n",
      "Epoch 176/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9427190.0000 - mae: 2124.3389 - val_loss: 20353236.0000 - val_mae: 2785.5190\n",
      "Epoch 177/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9377900.0000 - mae: 2096.7666 - val_loss: 21288968.0000 - val_mae: 2775.2395\n",
      "Epoch 178/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9492382.0000 - mae: 2078.8838 - val_loss: 19713904.0000 - val_mae: 2795.6738\n",
      "Epoch 179/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9468006.0000 - mae: 2140.0942 - val_loss: 20213484.0000 - val_mae: 2765.9778\n",
      "Epoch 180/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9238411.0000 - mae: 2098.7471 - val_loss: 21757314.0000 - val_mae: 2764.0496\n",
      "Epoch 181/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9482632.0000 - mae: 2097.0449 - val_loss: 20143950.0000 - val_mae: 2754.6963\n",
      "Epoch 182/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9394392.0000 - mae: 2083.7422 - val_loss: 19867398.0000 - val_mae: 2769.1323\n",
      "Epoch 183/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9267891.0000 - mae: 2138.5220 - val_loss: 19828978.0000 - val_mae: 2751.4006\n",
      "Epoch 184/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9325155.0000 - mae: 2079.6941 - val_loss: 19891934.0000 - val_mae: 2748.8728\n",
      "Epoch 185/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8940854.0000 - mae: 2106.2778 - val_loss: 22107040.0000 - val_mae: 2753.5254\n",
      "Epoch 186/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9352254.0000 - mae: 2116.8621 - val_loss: 20150164.0000 - val_mae: 2745.3132\n",
      "Epoch 187/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9096600.0000 - mae: 2145.8621 - val_loss: 19113942.0000 - val_mae: 2767.2131\n",
      "Epoch 188/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9122259.0000 - mae: 2147.8628 - val_loss: 20739034.0000 - val_mae: 2735.6467\n",
      "Epoch 189/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9251514.0000 - mae: 2124.4353 - val_loss: 19832462.0000 - val_mae: 2729.8542\n",
      "Epoch 190/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8994753.0000 - mae: 1998.5885 - val_loss: 18413504.0000 - val_mae: 2796.3887\n",
      "Epoch 191/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9262587.0000 - mae: 2130.2742 - val_loss: 18444192.0000 - val_mae: 2793.4575\n",
      "Epoch 192/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 9589064.0000 - mae: 2325.13 - 0s 1ms/step - loss: 9032976.0000 - mae: 2171.0491 - val_loss: 20387752.0000 - val_mae: 2724.6248\n",
      "Epoch 193/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 3680.2471 - mae: 60.665 - 0s 1ms/step - loss: 9048809.0000 - mae: 2145.0972 - val_loss: 20079794.0000 - val_mae: 2723.8257\n",
      "Epoch 194/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9033251.0000 - mae: 2138.0950 - val_loss: 20714778.0000 - val_mae: 2720.2480\n",
      "Epoch 195/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9241264.0000 - mae: 2101.1238 - val_loss: 20955168.0000 - val_mae: 2723.3682\n",
      "Epoch 196/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9114822.0000 - mae: 2059.9216 - val_loss: 18928142.0000 - val_mae: 2747.1172\n",
      "Epoch 197/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8989460.0000 - mae: 2169.9316 - val_loss: 20229754.0000 - val_mae: 2723.6392\n",
      "Epoch 198/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8826179.0000 - mae: 2171.8662 - val_loss: 21413946.0000 - val_mae: 2719.7004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8996659.0000 - mae: 2089.1750 - val_loss: 18542500.0000 - val_mae: 2732.3030\n",
      "Epoch 200/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8547899.0000 - mae: 2115.7703 - val_loss: 21970510.0000 - val_mae: 2729.6890\n",
      "Epoch 201/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9193916.0000 - mae: 2101.8140 - val_loss: 20413116.0000 - val_mae: 2708.3999\n",
      "Epoch 202/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8994400.0000 - mae: 2076.4253 - val_loss: 18978960.0000 - val_mae: 2714.1765\n",
      "Epoch 203/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8963800.0000 - mae: 2120.3989 - val_loss: 19280232.0000 - val_mae: 2705.0120\n",
      "Epoch 204/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8505464.0000 - mae: 2155.2405 - val_loss: 22790712.0000 - val_mae: 2775.2324\n",
      "Epoch 205/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9078200.0000 - mae: 1996.0575 - val_loss: 17848770.0000 - val_mae: 2751.2419\n",
      "Epoch 206/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8997286.0000 - mae: 2174.8489 - val_loss: 18681836.0000 - val_mae: 2705.0317\n",
      "Epoch 207/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8663008.0000 - mae: 2084.5671 - val_loss: 21292800.0000 - val_mae: 2704.2583\n",
      "Epoch 208/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8815563.0000 - mae: 2104.1924 - val_loss: 21431208.0000 - val_mae: 2707.6409\n",
      "Epoch 209/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8970176.0000 - mae: 2037.9396 - val_loss: 18483276.0000 - val_mae: 2699.3262\n",
      "Epoch 210/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8824460.0000 - mae: 2114.9414 - val_loss: 19115382.0000 - val_mae: 2674.9417\n",
      "Epoch 211/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8791220.0000 - mae: 2062.2300 - val_loss: 18757328.0000 - val_mae: 2679.5183\n",
      "Epoch 212/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8816438.0000 - mae: 2073.5515 - val_loss: 18287098.0000 - val_mae: 2681.5181\n",
      "Epoch 213/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8877048.0000 - mae: 2068.8848 - val_loss: 18090310.0000 - val_mae: 2690.0593\n",
      "Epoch 214/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8754657.0000 - mae: 2090.9141 - val_loss: 17848208.0000 - val_mae: 2687.6277\n",
      "Epoch 215/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8542127.0000 - mae: 2122.0457 - val_loss: 20698230.0000 - val_mae: 2671.6367\n",
      "Epoch 216/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8479168.0000 - mae: 2057.7478 - val_loss: 18164460.0000 - val_mae: 2669.2922\n",
      "Epoch 217/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8717592.0000 - mae: 2116.0735 - val_loss: 19090384.0000 - val_mae: 2655.0820\n",
      "Epoch 218/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8681305.0000 - mae: 2045.8224 - val_loss: 19988748.0000 - val_mae: 2660.1692\n",
      "Epoch 219/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8460559.0000 - mae: 2086.0176 - val_loss: 20691354.0000 - val_mae: 2674.7871\n",
      "Epoch 220/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8712657.0000 - mae: 2067.2144 - val_loss: 18881052.0000 - val_mae: 2670.2480\n",
      "Epoch 221/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8701894.0000 - mae: 2068.9849 - val_loss: 17930992.0000 - val_mae: 2689.6821\n",
      "Epoch 222/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8594714.0000 - mae: 2119.9148 - val_loss: 18865778.0000 - val_mae: 2663.1855\n",
      "Epoch 223/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8515242.0000 - mae: 2045.5953 - val_loss: 18358248.0000 - val_mae: 2670.3262\n",
      "Epoch 224/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8623189.0000 - mae: 2104.4402 - val_loss: 18211692.0000 - val_mae: 2651.8491\n",
      "Epoch 225/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8522337.0000 - mae: 2067.7939 - val_loss: 18727896.0000 - val_mae: 2644.8523\n",
      "Epoch 226/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8626677.0000 - mae: 2097.4204 - val_loss: 19433712.0000 - val_mae: 2633.4438\n",
      "Epoch 227/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8598924.0000 - mae: 2020.8097 - val_loss: 17953444.0000 - val_mae: 2662.4102\n",
      "Epoch 228/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8644447.0000 - mae: 2087.5325 - val_loss: 19262956.0000 - val_mae: 2632.0938\n",
      "Epoch 229/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8648309.0000 - mae: 2016.8716 - val_loss: 18435510.0000 - val_mae: 2633.0881\n",
      "Epoch 230/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8736613.0000 - mae: 2027.5221 - val_loss: 18878512.0000 - val_mae: 2624.1360\n",
      "Epoch 231/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8450246.0000 - mae: 2081.2542 - val_loss: 19063802.0000 - val_mae: 2614.9048\n",
      "Epoch 232/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8531688.0000 - mae: 2069.8262 - val_loss: 19209536.0000 - val_mae: 2610.2634\n",
      "Epoch 233/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8457874.0000 - mae: 2087.4160 - val_loss: 19299966.0000 - val_mae: 2602.8865\n",
      "Epoch 234/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8507798.0000 - mae: 2083.2756 - val_loss: 19685648.0000 - val_mae: 2613.2354\n",
      "Epoch 235/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8365147.5000 - mae: 2089.5098 - val_loss: 20530434.0000 - val_mae: 2659.0356\n",
      "Epoch 236/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8646691.0000 - mae: 2044.4014 - val_loss: 19254298.0000 - val_mae: 2591.8013\n",
      "Epoch 237/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8196268.0000 - mae: 2067.7432 - val_loss: 21320168.0000 - val_mae: 2701.8867\n",
      "Epoch 238/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8485208.0000 - mae: 2023.0956 - val_loss: 17836026.0000 - val_mae: 2587.8079\n",
      "Epoch 239/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8421208.0000 - mae: 2085.1184 - val_loss: 18804004.0000 - val_mae: 2569.9072\n",
      "Epoch 240/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8507393.0000 - mae: 2009.0961 - val_loss: 17839334.0000 - val_mae: 2574.2441\n",
      "Epoch 241/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8544459.0000 - mae: 2066.4951 - val_loss: 18077506.0000 - val_mae: 2567.3379\n",
      "Epoch 242/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8489356.0000 - mae: 2064.6792 - val_loss: 18460044.0000 - val_mae: 2561.7188\n",
      "Epoch 243/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8532264.0000 - mae: 2021.4033 - val_loss: 18230434.0000 - val_mae: 2561.4680\n",
      "Epoch 244/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8087441.0000 - mae: 2138.6389 - val_loss: 19095686.0000 - val_mae: 2572.1516\n",
      "Epoch 245/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8558087.0000 - mae: 2032.4536 - val_loss: 18161126.0000 - val_mae: 2551.8457\n",
      "Epoch 246/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8308636.0000 - mae: 2068.3672 - val_loss: 17620114.0000 - val_mae: 2545.6477\n",
      "Epoch 247/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8441199.0000 - mae: 2062.2415 - val_loss: 17800854.0000 - val_mae: 2542.0896\n",
      "Epoch 248/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8266994.0000 - mae: 2020.8544 - val_loss: 16835232.0000 - val_mae: 2562.2112\n",
      "Epoch 249/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8448370.0000 - mae: 2071.5706 - val_loss: 17382322.0000 - val_mae: 2542.6035\n",
      "Epoch 250/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8256260.5000 - mae: 2062.8145 - val_loss: 17993464.0000 - val_mae: 2523.9883\n",
      "Epoch 251/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8301476.0000 - mae: 2072.0125 - val_loss: 19845006.0000 - val_mae: 2612.9771\n",
      "Epoch 252/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8258964.5000 - mae: 2051.4324 - val_loss: 17278356.0000 - val_mae: 2546.1763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8339286.5000 - mae: 2067.7407 - val_loss: 18469890.0000 - val_mae: 2536.7083\n",
      "Epoch 254/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8285994.5000 - mae: 2041.6891 - val_loss: 17051504.0000 - val_mae: 2534.3906\n",
      "Epoch 255/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8225646.0000 - mae: 2066.6353 - val_loss: 18564344.0000 - val_mae: 2535.5215\n",
      "Epoch 256/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8245959.5000 - mae: 2026.7510 - val_loss: 19586458.0000 - val_mae: 2591.4719\n",
      "Epoch 257/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8490209.0000 - mae: 1996.8047 - val_loss: 17465712.0000 - val_mae: 2523.5840\n",
      "Epoch 258/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8258230.5000 - mae: 2036.4899 - val_loss: 17427260.0000 - val_mae: 2507.1440\n",
      "Epoch 259/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8187668.0000 - mae: 2058.5869 - val_loss: 18198166.0000 - val_mae: 2513.9043\n",
      "Epoch 260/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8370491.5000 - mae: 1989.3047 - val_loss: 16790988.0000 - val_mae: 2516.3801\n",
      "Epoch 261/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8210457.5000 - mae: 2075.7473 - val_loss: 17109776.0000 - val_mae: 2502.1765\n",
      "Epoch 262/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7956653.0000 - mae: 2041.2922 - val_loss: 17841112.0000 - val_mae: 2494.3726\n",
      "Epoch 263/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8268341.5000 - mae: 2032.9927 - val_loss: 17086460.0000 - val_mae: 2481.2646\n",
      "Epoch 264/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7848366.0000 - mae: 1964.6804 - val_loss: 15813195.0000 - val_mae: 2572.5217\n",
      "Epoch 265/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8227731.0000 - mae: 2095.6255 - val_loss: 17463728.0000 - val_mae: 2485.9668\n",
      "Epoch 266/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8071434.5000 - mae: 2034.4963 - val_loss: 18387662.0000 - val_mae: 2518.2573\n",
      "Epoch 267/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8202542.0000 - mae: 2073.4873 - val_loss: 17466438.0000 - val_mae: 2485.4766\n",
      "Epoch 268/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8188663.5000 - mae: 2058.9053 - val_loss: 17628018.0000 - val_mae: 2480.8711\n",
      "Epoch 269/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8334013.0000 - mae: 2051.9302 - val_loss: 17796660.0000 - val_mae: 2483.3718\n",
      "Epoch 270/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8233508.5000 - mae: 2010.8383 - val_loss: 17191882.0000 - val_mae: 2468.1033\n",
      "Epoch 271/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8154821.5000 - mae: 2036.6208 - val_loss: 17462278.0000 - val_mae: 2461.3721\n",
      "Epoch 272/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8055240.5000 - mae: 2067.1624 - val_loss: 17612276.0000 - val_mae: 2468.6216\n",
      "Epoch 273/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8101883.5000 - mae: 2046.0221 - val_loss: 17304906.0000 - val_mae: 2457.0645\n",
      "Epoch 274/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8195326.0000 - mae: 2023.5638 - val_loss: 17037526.0000 - val_mae: 2450.0105\n",
      "Epoch 275/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8085136.0000 - mae: 2026.1326 - val_loss: 17684342.0000 - val_mae: 2470.2461\n",
      "Epoch 276/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8004783.0000 - mae: 2019.5901 - val_loss: 19509360.0000 - val_mae: 2584.0002\n",
      "Epoch 277/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8238857.5000 - mae: 1995.6940 - val_loss: 16647503.0000 - val_mae: 2455.3240\n",
      "Epoch 278/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7994578.0000 - mae: 2049.2910 - val_loss: 18538132.0000 - val_mae: 2519.1936\n",
      "Epoch 279/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8156856.5000 - mae: 2026.5696 - val_loss: 18205990.0000 - val_mae: 2497.4229\n",
      "Epoch 280/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8029638.5000 - mae: 2084.6096 - val_loss: 17525190.0000 - val_mae: 2458.2559\n",
      "Epoch 281/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8096143.0000 - mae: 2071.1062 - val_loss: 17554356.0000 - val_mae: 2458.8865\n",
      "Epoch 282/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7940164.5000 - mae: 2052.2402 - val_loss: 16076314.0000 - val_mae: 2443.6245\n",
      "Epoch 283/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8081533.0000 - mae: 2045.6031 - val_loss: 16017203.0000 - val_mae: 2439.1575\n",
      "Epoch 284/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8122156.0000 - mae: 2061.8438 - val_loss: 16948210.0000 - val_mae: 2427.9260\n",
      "Epoch 285/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8075178.5000 - mae: 2002.6937 - val_loss: 16405532.0000 - val_mae: 2430.9663\n",
      "Epoch 286/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7927718.5000 - mae: 2061.9773 - val_loss: 18143344.0000 - val_mae: 2491.2781\n",
      "Epoch 287/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7934663.5000 - mae: 2018.3807 - val_loss: 16188762.0000 - val_mae: 2428.2068\n",
      "Epoch 288/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7822961.0000 - mae: 2090.1807 - val_loss: 18385796.0000 - val_mae: 2506.6086\n",
      "Epoch 289/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7971754.5000 - mae: 2053.3945 - val_loss: 18435870.0000 - val_mae: 2509.3191\n",
      "Epoch 290/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8076474.5000 - mae: 2054.9043 - val_loss: 17091428.0000 - val_mae: 2424.0679\n",
      "Epoch 291/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8092703.0000 - mae: 2050.7246 - val_loss: 16614449.0000 - val_mae: 2414.1655\n",
      "Epoch 292/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7996242.0000 - mae: 2015.7236 - val_loss: 17074730.0000 - val_mae: 2422.9736\n",
      "Epoch 293/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7478284.0000 - mae: 1907.5674 - val_loss: 15186897.0000 - val_mae: 2475.0847\n",
      "Epoch 294/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7609906.5000 - mae: 2027.3214 - val_loss: 18161932.0000 - val_mae: 2493.2686\n",
      "Epoch 295/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7979619.0000 - mae: 2020.3484 - val_loss: 17466480.0000 - val_mae: 2443.6958\n",
      "Epoch 296/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8065289.5000 - mae: 2019.2982 - val_loss: 17022928.0000 - val_mae: 2416.0613\n",
      "Epoch 297/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8007548.0000 - mae: 2037.3182 - val_loss: 17240284.0000 - val_mae: 2430.3887\n",
      "Epoch 298/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7869656.0000 - mae: 2014.5190 - val_loss: 17110256.0000 - val_mae: 2423.9507\n",
      "Epoch 299/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8029555.0000 - mae: 2038.9276 - val_loss: 16475671.0000 - val_mae: 2404.0137\n",
      "Epoch 300/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7977357.0000 - mae: 2054.1067 - val_loss: 17513292.0000 - val_mae: 2447.4563\n",
      "Epoch 301/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8020282.5000 - mae: 2037.4091 - val_loss: 16158274.0000 - val_mae: 2405.0894\n",
      "Epoch 302/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7604851.5000 - mae: 2047.2893 - val_loss: 18194032.0000 - val_mae: 2489.3062\n",
      "Epoch 303/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 8031359.0000 - mae: 2083.268 - 0s 1ms/step - loss: 7913251.0000 - mae: 2052.7092 - val_loss: 18102832.0000 - val_mae: 2482.9102\n",
      "Epoch 304/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7892520.0000 - mae: 1991.9692 - val_loss: 15862573.0000 - val_mae: 2456.3865\n",
      "Epoch 305/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8027300.5000 - mae: 2069.2563 - val_loss: 18143484.0000 - val_mae: 2483.6016\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 8053260.0000 - mae: 2011.0028 - val_loss: 17186332.0000 - val_mae: 2434.2554\n",
      "Epoch 307/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7988071.5000 - mae: 2018.3644 - val_loss: 18090132.0000 - val_mae: 2476.4043\n",
      "Epoch 308/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8064560.0000 - mae: 2020.0107 - val_loss: 16855298.0000 - val_mae: 2423.9153\n",
      "Epoch 309/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8066015.0000 - mae: 2028.9094 - val_loss: 17519832.0000 - val_mae: 2438.6250\n",
      "Epoch 310/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7928747.5000 - mae: 1991.9086 - val_loss: 16015258.0000 - val_mae: 2419.9597\n",
      "Epoch 311/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7953259.5000 - mae: 2045.0248 - val_loss: 16613013.0000 - val_mae: 2413.3379\n",
      "Epoch 312/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7388338.5000 - mae: 2004.8484 - val_loss: 19468896.0000 - val_mae: 2564.8557\n",
      "Epoch 313/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8023120.0000 - mae: 2007.8422 - val_loss: 18311096.0000 - val_mae: 2479.8137\n",
      "Epoch 314/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7920159.0000 - mae: 1980.1696 - val_loss: 16220296.0000 - val_mae: 2443.0974\n",
      "Epoch 315/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7687218.5000 - mae: 2040.4911 - val_loss: 18933692.0000 - val_mae: 2518.4172\n",
      "Epoch 316/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7890266.0000 - mae: 2022.1487 - val_loss: 18460434.0000 - val_mae: 2481.0054\n",
      "Epoch 317/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8018405.5000 - mae: 1975.7472 - val_loss: 16469771.0000 - val_mae: 2443.8921\n",
      "Epoch 318/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7850198.0000 - mae: 2063.8904 - val_loss: 17166322.0000 - val_mae: 2432.6816\n",
      "Epoch 319/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7764300.5000 - mae: 2011.6565 - val_loss: 15814366.0000 - val_mae: 2506.9824\n",
      "Epoch 320/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8053848.5000 - mae: 2025.3245 - val_loss: 16139823.0000 - val_mae: 2458.2803\n",
      "Epoch 321/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7783968.5000 - mae: 2036.6948 - val_loss: 16666249.0000 - val_mae: 2422.7292\n",
      "Epoch 322/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7872578.5000 - mae: 2044.3292 - val_loss: 16439130.0000 - val_mae: 2423.0566\n",
      "Epoch 323/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7504806.0000 - mae: 1944.1799 - val_loss: 15155506.0000 - val_mae: 2520.2834\n",
      "Epoch 324/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7445621.5000 - mae: 2093.3696 - val_loss: 19098342.0000 - val_mae: 2515.2483\n",
      "Epoch 325/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8062595.0000 - mae: 1945.9407 - val_loss: 16143206.0000 - val_mae: 2428.3496\n",
      "Epoch 326/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7797925.0000 - mae: 2083.6069 - val_loss: 17019228.0000 - val_mae: 2403.2329\n",
      "Epoch 327/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7792288.5000 - mae: 2007.7583 - val_loss: 17084330.0000 - val_mae: 2394.2412\n",
      "Epoch 328/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7805258.5000 - mae: 1999.6045 - val_loss: 16412241.0000 - val_mae: 2397.6846\n",
      "Epoch 329/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7692808.5000 - mae: 2034.3521 - val_loss: 16812190.0000 - val_mae: 2387.6343\n",
      "Epoch 330/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7745079.0000 - mae: 2027.9224 - val_loss: 16835924.0000 - val_mae: 2380.2874\n",
      "Epoch 331/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7736069.5000 - mae: 1983.8708 - val_loss: 15624299.0000 - val_mae: 2392.8381\n",
      "Epoch 332/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7715448.0000 - mae: 2053.1736 - val_loss: 16851618.0000 - val_mae: 2362.7986\n",
      "Epoch 333/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7707416.5000 - mae: 2009.6859 - val_loss: 16365715.0000 - val_mae: 2351.5198\n",
      "Epoch 334/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7650395.0000 - mae: 1964.7596 - val_loss: 15659077.0000 - val_mae: 2368.8262\n",
      "Epoch 335/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7633551.0000 - mae: 2004.7635 - val_loss: 15377016.0000 - val_mae: 2386.7166\n",
      "Epoch 336/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7676984.0000 - mae: 2021.7916 - val_loss: 16249525.0000 - val_mae: 2357.0271\n",
      "Epoch 337/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7448265.0000 - mae: 2016.1539 - val_loss: 18107906.0000 - val_mae: 2432.3506\n",
      "Epoch 338/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7666688.5000 - mae: 1940.3247 - val_loss: 15151149.0000 - val_mae: 2386.1880\n",
      "Epoch 339/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7562452.0000 - mae: 2066.4246 - val_loss: 15667415.0000 - val_mae: 2344.0764\n",
      "Epoch 340/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7085522.5000 - mae: 2015.0159 - val_loss: 19437838.0000 - val_mae: 2561.8306\n",
      "Epoch 341/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7629940.0000 - mae: 1988.1146 - val_loss: 15559583.0000 - val_mae: 2348.0305\n",
      "Epoch 342/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7630887.5000 - mae: 1991.9968 - val_loss: 15899059.0000 - val_mae: 2332.3135\n",
      "Epoch 343/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7556903.0000 - mae: 1966.3534 - val_loss: 15405926.0000 - val_mae: 2345.3154\n",
      "Epoch 344/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7511550.0000 - mae: 1996.0724 - val_loss: 15400274.0000 - val_mae: 2338.5339\n",
      "Epoch 345/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7557927.5000 - mae: 1986.3713 - val_loss: 16733792.0000 - val_mae: 2327.5027\n",
      "Epoch 346/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7466712.5000 - mae: 2024.9768 - val_loss: 15019236.0000 - val_mae: 2363.1086\n",
      "Epoch 347/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7492416.0000 - mae: 2043.3289 - val_loss: 15966955.0000 - val_mae: 2339.2019\n",
      "Epoch 348/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7459300.5000 - mae: 1966.0271 - val_loss: 17233870.0000 - val_mae: 2372.4746\n",
      "Epoch 349/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 7583358.5000 - mae: 2004.65 - 0s 1ms/step - loss: 7583358.5000 - mae: 2004.6549 - val_loss: 16927170.0000 - val_mae: 2359.5046\n",
      "Epoch 350/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7424135.5000 - mae: 1933.9541 - val_loss: 15128198.0000 - val_mae: 2405.7102\n",
      "Epoch 351/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7536846.5000 - mae: 2015.3171 - val_loss: 16310193.0000 - val_mae: 2354.9434\n",
      "Epoch 352/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7352810.5000 - mae: 1985.4230 - val_loss: 16947666.0000 - val_mae: 2363.0923\n",
      "Epoch 353/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7358741.5000 - mae: 1966.8341 - val_loss: 16889814.0000 - val_mae: 2366.4648\n",
      "Epoch 354/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7462011.5000 - mae: 2022.8773 - val_loss: 17383400.0000 - val_mae: 2377.3442\n",
      "Epoch 355/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7500287.5000 - mae: 1957.6510 - val_loss: 16025591.0000 - val_mae: 2354.5244\n",
      "Epoch 356/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7352371.0000 - mae: 1944.3203 - val_loss: 14779928.0000 - val_mae: 2444.6694\n",
      "Epoch 357/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 7797614.0000 - mae: 1982.285 - 0s 1ms/step - loss: 7429580.0000 - mae: 1972.7013 - val_loss: 16044597.0000 - val_mae: 2361.7849\n",
      "Epoch 358/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7104750.5000 - mae: 1998.3075 - val_loss: 18366712.0000 - val_mae: 2449.0325\n",
      "Epoch 359/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 7613321.0000 - mae: 1945.6875 - val_loss: 16489600.0000 - val_mae: 2354.8433\n",
      "Epoch 360/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7343036.0000 - mae: 1932.0363 - val_loss: 15279362.0000 - val_mae: 2439.5410\n",
      "Epoch 361/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7070976.5000 - mae: 1992.5558 - val_loss: 18533878.0000 - val_mae: 2458.1470\n",
      "Epoch 362/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7556265.5000 - mae: 1990.6016 - val_loss: 16144614.0000 - val_mae: 2368.3960\n",
      "Epoch 363/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 7464164.0000 - mae: 2018.40 - 0s 1ms/step - loss: 7201706.5000 - mae: 1967.7961 - val_loss: 15147661.0000 - val_mae: 2394.4875\n",
      "Epoch 364/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7426656.5000 - mae: 1992.3075 - val_loss: 16008395.0000 - val_mae: 2365.6584\n",
      "Epoch 365/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7356094.0000 - mae: 1938.8734 - val_loss: 16042720.0000 - val_mae: 2352.5100\n",
      "Epoch 366/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7337444.5000 - mae: 1951.0729 - val_loss: 15213283.0000 - val_mae: 2381.4260\n",
      "Epoch 367/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7274647.0000 - mae: 1940.4474 - val_loss: 16018554.0000 - val_mae: 2341.8909\n",
      "Epoch 368/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7405008.5000 - mae: 1953.0375 - val_loss: 16644036.0000 - val_mae: 2342.9980\n",
      "Epoch 369/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7301324.0000 - mae: 1996.3427 - val_loss: 15646480.0000 - val_mae: 2359.3706\n",
      "Epoch 370/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7351684.0000 - mae: 1974.7672 - val_loss: 15831249.0000 - val_mae: 2361.6753\n",
      "Epoch 371/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7286117.5000 - mae: 1998.4407 - val_loss: 16082445.0000 - val_mae: 2346.0662\n",
      "Epoch 372/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7293063.0000 - mae: 1930.8799 - val_loss: 15116993.0000 - val_mae: 2377.3638\n",
      "Epoch 373/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7357813.5000 - mae: 1952.4117 - val_loss: 16114298.0000 - val_mae: 2345.3501\n",
      "Epoch 374/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7224390.5000 - mae: 1942.3669 - val_loss: 17229146.0000 - val_mae: 2348.2004\n",
      "Epoch 375/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7398766.0000 - mae: 1925.7020 - val_loss: 15733893.0000 - val_mae: 2392.8186\n",
      "Epoch 376/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7195571.5000 - mae: 1986.8240 - val_loss: 15494740.0000 - val_mae: 2381.3716\n",
      "Epoch 377/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7118038.0000 - mae: 1958.0076 - val_loss: 17192206.0000 - val_mae: 2343.5498\n",
      "Epoch 378/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7262390.5000 - mae: 1964.8787 - val_loss: 15702673.0000 - val_mae: 2346.7820\n",
      "Epoch 379/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7195186.0000 - mae: 1905.0040 - val_loss: 15016267.0000 - val_mae: 2376.1382\n",
      "Epoch 380/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7218619.0000 - mae: 1929.8906 - val_loss: 14857953.0000 - val_mae: 2382.1831\n",
      "Epoch 381/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7227641.0000 - mae: 1964.1248 - val_loss: 15544333.0000 - val_mae: 2338.9268\n",
      "Epoch 382/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7135314.0000 - mae: 1933.2817 - val_loss: 15111949.0000 - val_mae: 2354.9807\n",
      "Epoch 383/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7155859.5000 - mae: 1950.4935 - val_loss: 15371704.0000 - val_mae: 2344.0222\n",
      "Epoch 384/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7297430.5000 - mae: 1950.4625 - val_loss: 15877572.0000 - val_mae: 2336.7563\n",
      "Epoch 385/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7138708.5000 - mae: 1928.6349 - val_loss: 15572394.0000 - val_mae: 2343.2322\n",
      "Epoch 386/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7193704.0000 - mae: 1978.7378 - val_loss: 16026848.0000 - val_mae: 2317.5408\n",
      "Epoch 387/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7078566.5000 - mae: 1902.2388 - val_loss: 16236885.0000 - val_mae: 2324.5376\n",
      "Epoch 388/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7138689.5000 - mae: 1861.0962 - val_loss: 16721954.0000 - val_mae: 2326.2051\n",
      "Epoch 389/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7151370.5000 - mae: 1931.1836 - val_loss: 16421201.0000 - val_mae: 2322.6587\n",
      "Epoch 390/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7135224.5000 - mae: 1960.9536 - val_loss: 15430820.0000 - val_mae: 2334.9233\n",
      "Epoch 391/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7127658.0000 - mae: 1947.0854 - val_loss: 15363015.0000 - val_mae: 2334.3069\n",
      "Epoch 392/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7153275.0000 - mae: 1948.8849 - val_loss: 15826424.0000 - val_mae: 2324.4487\n",
      "Epoch 393/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7140700.0000 - mae: 1906.6917 - val_loss: 15990246.0000 - val_mae: 2325.8716\n",
      "Epoch 394/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6977920.0000 - mae: 1924.2686 - val_loss: 17760082.0000 - val_mae: 2395.0244\n",
      "Epoch 395/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7166182.0000 - mae: 1881.1700 - val_loss: 15184543.0000 - val_mae: 2351.3269\n",
      "Epoch 396/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7134790.5000 - mae: 1922.1428 - val_loss: 14837609.0000 - val_mae: 2359.7048\n",
      "Epoch 397/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7041612.0000 - mae: 1934.3036 - val_loss: 15396826.0000 - val_mae: 2337.6282\n",
      "Epoch 398/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7036646.5000 - mae: 1920.4379 - val_loss: 15458224.0000 - val_mae: 2338.7476\n",
      "Epoch 399/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7051454.0000 - mae: 1975.2688 - val_loss: 15858302.0000 - val_mae: 2327.7102\n",
      "Epoch 400/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6997391.0000 - mae: 1938.0096 - val_loss: 15190046.0000 - val_mae: 2344.5071\n",
      "Epoch 401/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6991862.5000 - mae: 1902.9745 - val_loss: 14692696.0000 - val_mae: 2378.3423\n",
      "Epoch 402/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6982180.0000 - mae: 1941.9563 - val_loss: 16229843.0000 - val_mae: 2328.6445\n",
      "Epoch 403/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6995749.5000 - mae: 1922.5475 - val_loss: 14808690.0000 - val_mae: 2371.4463\n",
      "Epoch 404/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6945321.0000 - mae: 1950.2997 - val_loss: 15999200.0000 - val_mae: 2312.0337\n",
      "Epoch 405/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7023031.0000 - mae: 1925.4784 - val_loss: 14825850.0000 - val_mae: 2359.9512\n",
      "Epoch 406/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7013651.0000 - mae: 1926.3571 - val_loss: 16005508.0000 - val_mae: 2329.3452\n",
      "Epoch 407/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7008254.5000 - mae: 1894.3062 - val_loss: 15089401.0000 - val_mae: 2346.2771\n",
      "Epoch 408/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7038645.0000 - mae: 1925.1302 - val_loss: 15719070.0000 - val_mae: 2325.8162\n",
      "Epoch 409/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6929097.5000 - mae: 1828.6062 - val_loss: 16032083.0000 - val_mae: 2317.8042\n",
      "Epoch 410/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6921547.5000 - mae: 1935.0922 - val_loss: 16383266.0000 - val_mae: 2326.0381\n",
      "Epoch 411/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6913162.0000 - mae: 1939.8185 - val_loss: 17022258.0000 - val_mae: 2362.0735\n",
      "Epoch 412/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7028380.5000 - mae: 1904.2476 - val_loss: 16903500.0000 - val_mae: 2357.4846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6650622.5000 - mae: 1822.5293 - val_loss: 13941352.0000 - val_mae: 2452.6873\n",
      "Epoch 414/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6959378.0000 - mae: 1929.8810 - val_loss: 16339294.0000 - val_mae: 2326.2156\n",
      "Epoch 415/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7016410.5000 - mae: 1891.6771 - val_loss: 15730016.0000 - val_mae: 2327.4143\n",
      "Epoch 416/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6787676.0000 - mae: 1881.9062 - val_loss: 14155470.0000 - val_mae: 2411.0991\n",
      "Epoch 417/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6947332.0000 - mae: 1921.3083 - val_loss: 15887194.0000 - val_mae: 2316.5728\n",
      "Epoch 418/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6925705.5000 - mae: 1911.0414 - val_loss: 15103499.0000 - val_mae: 2323.8652\n",
      "Epoch 419/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6918074.5000 - mae: 1885.5072 - val_loss: 15295975.0000 - val_mae: 2337.0708\n",
      "Epoch 420/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6854582.5000 - mae: 1892.9830 - val_loss: 15727330.0000 - val_mae: 2321.0701\n",
      "Epoch 421/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6632403.5000 - mae: 1925.9158 - val_loss: 16825602.0000 - val_mae: 2347.1614\n",
      "Epoch 422/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6739808.5000 - mae: 1865.8419 - val_loss: 16314748.0000 - val_mae: 2330.3982\n",
      "Epoch 423/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6931156.0000 - mae: 1884.7781 - val_loss: 16140576.0000 - val_mae: 2324.6526\n",
      "Epoch 424/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6694017.5000 - mae: 1831.0024 - val_loss: 14218460.0000 - val_mae: 2410.6301\n",
      "Epoch 425/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6919981.0000 - mae: 1923.0297 - val_loss: 14509752.0000 - val_mae: 2376.2502\n",
      "Epoch 426/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6781867.0000 - mae: 1918.2645 - val_loss: 16339977.0000 - val_mae: 2327.5891\n",
      "Epoch 427/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6891327.0000 - mae: 1907.1201 - val_loss: 16072392.0000 - val_mae: 2317.9980\n",
      "Epoch 428/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6802666.0000 - mae: 1903.9062 - val_loss: 16678511.0000 - val_mae: 2345.2520\n",
      "Epoch 429/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6724437.5000 - mae: 1932.5533 - val_loss: 16736627.0000 - val_mae: 2346.8425\n",
      "Epoch 430/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6946091.5000 - mae: 1889.6382 - val_loss: 15183464.0000 - val_mae: 2332.8511\n",
      "Epoch 431/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6434033.5000 - mae: 1865.6437 - val_loss: 18117712.0000 - val_mae: 2445.3975\n",
      "Epoch 432/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6961779.0000 - mae: 1860.5577 - val_loss: 16700339.0000 - val_mae: 2344.5664\n",
      "Epoch 433/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6710814.0000 - mae: 1842.4592 - val_loss: 14400617.0000 - val_mae: 2373.9683\n",
      "Epoch 434/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6815189.5000 - mae: 1909.5094 - val_loss: 15198082.0000 - val_mae: 2337.3218\n",
      "Epoch 435/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6875745.0000 - mae: 1889.2802 - val_loss: 15179217.0000 - val_mae: 2335.0071\n",
      "Epoch 436/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6789060.0000 - mae: 1874.2139 - val_loss: 14819470.0000 - val_mae: 2346.2578\n",
      "Epoch 437/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6814472.0000 - mae: 1924.6384 - val_loss: 15885367.0000 - val_mae: 2311.1184\n",
      "Epoch 438/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6514815.0000 - mae: 1865.2012 - val_loss: 17535280.0000 - val_mae: 2406.8926\n",
      "Epoch 439/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6878189.0000 - mae: 1869.2424 - val_loss: 15766387.0000 - val_mae: 2321.5298\n",
      "Epoch 440/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6716793.5000 - mae: 1817.2378 - val_loss: 14064878.0000 - val_mae: 2382.7161\n",
      "Epoch 441/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6760490.5000 - mae: 1875.1803 - val_loss: 14150018.0000 - val_mae: 2375.1719\n",
      "Epoch 442/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6791377.5000 - mae: 1871.8038 - val_loss: 15248410.0000 - val_mae: 2297.0959\n",
      "Epoch 443/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6761174.0000 - mae: 1886.0702 - val_loss: 14982793.0000 - val_mae: 2300.1299\n",
      "Epoch 444/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6780372.5000 - mae: 1878.6543 - val_loss: 15128747.0000 - val_mae: 2310.6226\n",
      "Epoch 445/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6489555.0000 - mae: 1852.6427 - val_loss: 17902450.0000 - val_mae: 2442.5408\n",
      "Epoch 446/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6873646.0000 - mae: 1881.1068 - val_loss: 17074302.0000 - val_mae: 2372.2908\n",
      "Epoch 447/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6662622.0000 - mae: 1858.9962 - val_loss: 16213576.0000 - val_mae: 2320.5107\n",
      "Epoch 448/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6729775.5000 - mae: 1915.8893 - val_loss: 16263605.0000 - val_mae: 2321.9443\n",
      "Epoch 449/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6708459.5000 - mae: 1827.7477 - val_loss: 16344595.0000 - val_mae: 2324.8977\n",
      "Epoch 450/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6758476.0000 - mae: 1860.8123 - val_loss: 15323491.0000 - val_mae: 2318.1658\n",
      "Epoch 451/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6491273.0000 - mae: 1903.1895 - val_loss: 16925056.0000 - val_mae: 2376.1956\n",
      "Epoch 452/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6751356.0000 - mae: 1828.6029 - val_loss: 15573340.0000 - val_mae: 2301.6257\n",
      "Epoch 453/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6727361.0000 - mae: 1833.0411 - val_loss: 14772410.0000 - val_mae: 2339.1492\n",
      "Epoch 454/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6715169.5000 - mae: 1864.4462 - val_loss: 15823966.0000 - val_mae: 2308.5042\n",
      "Epoch 455/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6605831.0000 - mae: 1844.8173 - val_loss: 16064013.0000 - val_mae: 2322.1350\n",
      "Epoch 456/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6590405.5000 - mae: 1870.9490 - val_loss: 17394566.0000 - val_mae: 2398.6931\n",
      "Epoch 457/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6732076.5000 - mae: 1892.8544 - val_loss: 16014726.0000 - val_mae: 2323.3027\n",
      "Epoch 458/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6527237.5000 - mae: 1848.5983 - val_loss: 16901450.0000 - val_mae: 2360.3887\n",
      "Epoch 459/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6746219.5000 - mae: 1781.6385 - val_loss: 14552585.0000 - val_mae: 2356.3545\n",
      "Epoch 460/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6591602.0000 - mae: 1825.8901 - val_loss: 14053367.0000 - val_mae: 2401.4343\n",
      "Epoch 461/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6303075.0000 - mae: 1946.9172 - val_loss: 16693500.0000 - val_mae: 2352.9719\n",
      "Epoch 462/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6598534.5000 - mae: 1886.0806 - val_loss: 17145130.0000 - val_mae: 2386.8528\n",
      "Epoch 463/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6637771.0000 - mae: 1835.9221 - val_loss: 15782716.0000 - val_mae: 2309.0339\n",
      "Epoch 464/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6487913.5000 - mae: 1816.1151 - val_loss: 17171696.0000 - val_mae: 2391.0488\n",
      "Epoch 465/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6739974.5000 - mae: 1837.0068 - val_loss: 15628533.0000 - val_mae: 2311.2029\n",
      "Epoch 466/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6629846.5000 - mae: 1878.6013 - val_loss: 15107979.0000 - val_mae: 2324.1807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6498526.0000 - mae: 1853.1104 - val_loss: 14027763.0000 - val_mae: 2381.5071\n",
      "Epoch 468/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6527501.0000 - mae: 1863.3658 - val_loss: 14988698.0000 - val_mae: 2325.4875\n",
      "Epoch 469/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6602254.5000 - mae: 1855.7693 - val_loss: 14386952.0000 - val_mae: 2387.0867\n",
      "Epoch 470/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6732732.0000 - mae: 1866.3257 - val_loss: 15324772.0000 - val_mae: 2316.3137\n",
      "Epoch 471/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6549922.0000 - mae: 1867.2761 - val_loss: 14385476.0000 - val_mae: 2347.2078\n",
      "Epoch 472/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6560836.0000 - mae: 1887.6519 - val_loss: 15453555.0000 - val_mae: 2294.9526\n",
      "Epoch 473/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6581892.0000 - mae: 1845.8540 - val_loss: 15183641.0000 - val_mae: 2299.1543\n",
      "Epoch 474/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6557868.0000 - mae: 1858.5486 - val_loss: 15856235.0000 - val_mae: 2307.4175\n",
      "Epoch 475/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6223723.5000 - mae: 1842.1058 - val_loss: 13807656.0000 - val_mae: 2373.0286\n",
      "Epoch 476/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6371810.5000 - mae: 1845.6249 - val_loss: 16718155.0000 - val_mae: 2370.8274\n",
      "Epoch 477/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6483409.5000 - mae: 1772.6178 - val_loss: 14226520.0000 - val_mae: 2335.9844\n",
      "Epoch 478/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6541760.5000 - mae: 1874.8502 - val_loss: 14897576.0000 - val_mae: 2306.6982\n",
      "Epoch 479/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6265096.5000 - mae: 1854.7483 - val_loss: 14019336.0000 - val_mae: 2327.7993\n",
      "Epoch 480/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6633538.0000 - mae: 1828.4482 - val_loss: 14980085.0000 - val_mae: 2314.0178\n",
      "Epoch 481/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6506645.5000 - mae: 1845.8311 - val_loss: 15273654.0000 - val_mae: 2300.7722\n",
      "Epoch 482/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6244180.5000 - mae: 1848.6617 - val_loss: 17622600.0000 - val_mae: 2444.0393\n",
      "Epoch 483/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6642559.5000 - mae: 1826.3512 - val_loss: 15463811.0000 - val_mae: 2291.7832\n",
      "Epoch 484/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6503278.0000 - mae: 1813.5399 - val_loss: 15797969.0000 - val_mae: 2304.0129\n",
      "Epoch 485/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6239175.0000 - mae: 1805.2784 - val_loss: 14542624.0000 - val_mae: 2321.1216\n",
      "Epoch 486/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6513783.5000 - mae: 1866.8566 - val_loss: 14480634.0000 - val_mae: 2325.5542\n",
      "Epoch 487/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5971310.5000 - mae: 1828.6252 - val_loss: 16920776.0000 - val_mae: 2373.9055\n",
      "Epoch 488/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6168908.0000 - mae: 1821.4772 - val_loss: 13770724.0000 - val_mae: 2381.4629\n",
      "Epoch 489/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6306597.5000 - mae: 1832.1409 - val_loss: 13516951.0000 - val_mae: 2390.6306\n",
      "Epoch 490/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6481293.0000 - mae: 1867.1989 - val_loss: 14149002.0000 - val_mae: 2329.6641\n",
      "Epoch 491/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6418074.0000 - mae: 1877.8435 - val_loss: 14321793.0000 - val_mae: 2296.2849\n",
      "Epoch 492/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6329814.5000 - mae: 1823.5948 - val_loss: 16510771.0000 - val_mae: 2345.0366\n",
      "Epoch 493/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6262066.5000 - mae: 1810.9756 - val_loss: 16764277.0000 - val_mae: 2371.3667\n",
      "Epoch 494/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6562956.0000 - mae: 1824.1378 - val_loss: 14347303.0000 - val_mae: 2329.3992\n",
      "Epoch 495/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6383488.0000 - mae: 1823.8021 - val_loss: 14586425.0000 - val_mae: 2307.9233\n",
      "Epoch 496/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6425227.0000 - mae: 1816.8237 - val_loss: 15027666.0000 - val_mae: 2273.2581\n",
      "Epoch 497/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 6531288.5000 - mae: 1830.33 - 0s 1ms/step - loss: 6443542.5000 - mae: 1814.4650 - val_loss: 14357740.0000 - val_mae: 2287.1489\n",
      "Epoch 498/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6366424.0000 - mae: 1846.3225 - val_loss: 15561810.0000 - val_mae: 2291.6360\n",
      "Epoch 499/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6449982.5000 - mae: 1819.0857 - val_loss: 15347378.0000 - val_mae: 2281.8655\n",
      "Epoch 500/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6049345.0000 - mae: 1798.2886 - val_loss: 15736232.0000 - val_mae: 2299.6716\n",
      "processing fold # 2\n",
      "Epoch 1/500\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 113902880.0000 - mae: 7910.5811 - val_loss: 71172040.0000 - val_mae: 5668.1572\n",
      "Epoch 2/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 67949624.0000 - mae: 5432.7070 - val_loss: 45490164.0000 - val_mae: 4335.3057\n",
      "Epoch 3/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 52161956.0000 - mae: 4749.7539 - val_loss: 39183880.0000 - val_mae: 4450.5615\n",
      "Epoch 4/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 47831304.0000 - mae: 4749.9961 - val_loss: 37788880.0000 - val_mae: 4608.9302\n",
      "Epoch 5/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 46689092.0000 - mae: 4764.4971 - val_loss: 36977424.0000 - val_mae: 4577.0859\n",
      "Epoch 6/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 45973792.0000 - mae: 4763.5361 - val_loss: 36276408.0000 - val_mae: 4500.0352\n",
      "Epoch 7/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44927164.0000 - mae: 4766.6636 - val_loss: 35637436.0000 - val_mae: 4492.3789\n",
      "Epoch 8/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 44061940.0000 - mae: 4692.8491 - val_loss: 34990128.0000 - val_mae: 4304.6875\n",
      "Epoch 9/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 42828796.0000 - mae: 4635.4976 - val_loss: 35698796.0000 - val_mae: 4079.0762\n",
      "Epoch 10/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 43499696.0000 - mae: 4523.7900 - val_loss: 33796552.0000 - val_mae: 4142.2217\n",
      "Epoch 11/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41673312.0000 - mae: 4463.4336 - val_loss: 32816622.0000 - val_mae: 4294.2212\n",
      "Epoch 12/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 41153644.0000 - mae: 4565.4438 - val_loss: 31958456.0000 - val_mae: 4151.6680\n",
      "Epoch 13/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 40337028.0000 - mae: 4528.0933 - val_loss: 31072794.0000 - val_mae: 4120.7114\n",
      "Epoch 14/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 39828128.0000 - mae: 4353.6519 - val_loss: 30269592.0000 - val_mae: 4018.1370\n",
      "Epoch 15/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 38010588.0000 - mae: 4443.8125 - val_loss: 29488984.0000 - val_mae: 3861.3147\n",
      "Epoch 16/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 37473520.0000 - mae: 4301.7515 - val_loss: 28689226.0000 - val_mae: 3768.9031\n",
      "Epoch 17/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 36870268.0000 - mae: 4212.7725 - val_loss: 27666928.0000 - val_mae: 3813.7009\n",
      "Epoch 18/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 35809364.0000 - mae: 4195.5439 - val_loss: 26894848.0000 - val_mae: 3656.0251\n",
      "Epoch 19/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 34545888.0000 - mae: 4152.8516 - val_loss: 25857072.0000 - val_mae: 3578.0918\n",
      "Epoch 20/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 33241766.0000 - mae: 4053.5037 - val_loss: 25903566.0000 - val_mae: 3354.6399\n",
      "Epoch 21/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 33526984.0000 - mae: 3824.4192 - val_loss: 24038800.0000 - val_mae: 3531.2302\n",
      "Epoch 22/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 32287628.0000 - mae: 3842.2312 - val_loss: 23424598.0000 - val_mae: 3334.3584\n",
      "Epoch 23/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30952480.0000 - mae: 3791.3210 - val_loss: 22188412.0000 - val_mae: 3356.7302\n",
      "Epoch 24/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 29566194.0000 - mae: 3809.6060 - val_loss: 21263224.0000 - val_mae: 3246.0947\n",
      "Epoch 25/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 28618824.0000 - mae: 3540.8518 - val_loss: 20480304.0000 - val_mae: 3266.6663\n",
      "Epoch 26/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26596060.0000 - mae: 3675.4910 - val_loss: 20210402.0000 - val_mae: 2869.2441\n",
      "Epoch 27/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 26207552.0000 - mae: 3479.2791 - val_loss: 19676554.0000 - val_mae: 2787.8142\n",
      "Epoch 28/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 25495060.0000 - mae: 3342.0032 - val_loss: 17624814.0000 - val_mae: 2936.5562\n",
      "Epoch 29/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 24524448.0000 - mae: 3411.5745 - val_loss: 17646820.0000 - val_mae: 2644.9109\n",
      "Epoch 30/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 23732456.0000 - mae: 3211.9182 - val_loss: 16018852.0000 - val_mae: 2689.0449\n",
      "Epoch 31/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 21095376.0000 - mae: 2978.1851 - val_loss: 15593497.0000 - val_mae: 2877.4565\n",
      "Epoch 32/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20985964.0000 - mae: 3063.0383 - val_loss: 15076459.0000 - val_mae: 2495.6812\n",
      "Epoch 33/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 20617202.0000 - mae: 2982.3538 - val_loss: 14021497.0000 - val_mae: 2635.1301\n",
      "Epoch 34/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 19015342.0000 - mae: 3120.4175 - val_loss: 13257271.0000 - val_mae: 2523.0042\n",
      "Epoch 35/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 18840100.0000 - mae: 2934.9666 - val_loss: 12888504.0000 - val_mae: 2372.1499\n",
      "Epoch 36/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 17390940.0000 - mae: 2828.1304 - val_loss: 13996806.0000 - val_mae: 2280.2712\n",
      "Epoch 37/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 17455848.0000 - mae: 2731.1030 - val_loss: 12507419.0000 - val_mae: 2264.7224\n",
      "Epoch 38/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 17035730.0000 - mae: 2590.0449 - val_loss: 11654963.0000 - val_mae: 2534.3652\n",
      "Epoch 39/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 16354466.0000 - mae: 2647.1731 - val_loss: 11461211.0000 - val_mae: 2255.4944\n",
      "Epoch 40/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14797230.0000 - mae: 2451.0435 - val_loss: 11479617.0000 - val_mae: 2618.0459\n",
      "Epoch 41/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14664488.0000 - mae: 2506.5588 - val_loss: 12243498.0000 - val_mae: 2811.6409\n",
      "Epoch 42/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 15064367.0000 - mae: 2735.1135 - val_loss: 10483150.0000 - val_mae: 2314.6445\n",
      "Epoch 43/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14137968.0000 - mae: 2437.3582 - val_loss: 10865257.0000 - val_mae: 2278.8508\n",
      "Epoch 44/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14017879.0000 - mae: 2484.6121 - val_loss: 10268434.0000 - val_mae: 2336.4827\n",
      "Epoch 45/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 14230260.0000 - mae: 2458.5796 - val_loss: 10259479.0000 - val_mae: 2315.2605\n",
      "Epoch 46/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13735480.0000 - mae: 2421.1733 - val_loss: 10304505.0000 - val_mae: 2311.7144\n",
      "Epoch 47/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13844356.0000 - mae: 2457.7046 - val_loss: 10235867.0000 - val_mae: 2322.4075\n",
      "Epoch 48/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13554289.0000 - mae: 2483.5012 - val_loss: 11158798.0000 - val_mae: 2464.4121\n",
      "Epoch 49/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13193771.0000 - mae: 2499.4785 - val_loss: 10670280.0000 - val_mae: 2422.3438\n",
      "Epoch 50/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12987916.0000 - mae: 2336.4829 - val_loss: 10265381.0000 - val_mae: 2377.4937\n",
      "Epoch 51/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12802014.0000 - mae: 2382.7231 - val_loss: 10407633.0000 - val_mae: 2430.7490\n",
      "Epoch 52/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12707699.0000 - mae: 2367.5566 - val_loss: 10355271.0000 - val_mae: 2423.8457\n",
      "Epoch 53/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13082293.0000 - mae: 2380.0649 - val_loss: 11812966.0000 - val_mae: 2586.2559\n",
      "Epoch 54/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13164866.0000 - mae: 2408.3545 - val_loss: 10262925.0000 - val_mae: 2410.7314\n",
      "Epoch 55/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12657909.0000 - mae: 2395.5696 - val_loss: 10128488.0000 - val_mae: 2393.4670\n",
      "Epoch 56/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12887942.0000 - mae: 2385.3457 - val_loss: 9998168.0000 - val_mae: 2370.7231\n",
      "Epoch 57/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12053336.0000 - mae: 2436.5393 - val_loss: 12600760.0000 - val_mae: 2703.2793\n",
      "Epoch 58/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12675283.0000 - mae: 2356.4824 - val_loss: 10759733.0000 - val_mae: 2476.8787\n",
      "Epoch 59/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12874308.0000 - mae: 2262.8115 - val_loss: 11163498.0000 - val_mae: 2527.2695\n",
      "Epoch 60/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11670217.0000 - mae: 2213.0967 - val_loss: 11787352.0000 - val_mae: 2693.9153\n",
      "Epoch 61/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13040375.0000 - mae: 2473.9373 - val_loss: 10008809.0000 - val_mae: 2383.2996\n",
      "Epoch 62/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12654833.0000 - mae: 2343.0837 - val_loss: 10037036.0000 - val_mae: 2385.7573\n",
      "Epoch 63/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12325673.0000 - mae: 2325.0608 - val_loss: 10238075.0000 - val_mae: 2428.5620\n",
      "Epoch 64/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11367934.0000 - mae: 2326.8562 - val_loss: 11707896.0000 - val_mae: 2610.5591\n",
      "Epoch 65/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12632228.0000 - mae: 2342.6670 - val_loss: 10032987.0000 - val_mae: 2402.3235\n",
      "Epoch 66/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12522964.0000 - mae: 2351.4263 - val_loss: 10339549.0000 - val_mae: 2448.2734\n",
      "Epoch 67/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12885784.0000 - mae: 2296.3462 - val_loss: 10043576.0000 - val_mae: 2401.5293\n",
      "Epoch 68/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11908608.0000 - mae: 2404.2913 - val_loss: 10053176.0000 - val_mae: 2405.9705\n",
      "Epoch 69/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12069659.0000 - mae: 2401.2512 - val_loss: 10046278.0000 - val_mae: 2397.2000\n",
      "Epoch 70/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12336960.0000 - mae: 2398.5422 - val_loss: 10224123.0000 - val_mae: 2431.4746\n",
      "Epoch 71/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12265215.0000 - mae: 2450.7354 - val_loss: 10039052.0000 - val_mae: 2414.3030\n",
      "Epoch 72/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11670483.0000 - mae: 2327.0876 - val_loss: 10426683.0000 - val_mae: 2450.5686\n",
      "Epoch 73/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11969322.0000 - mae: 2305.5620 - val_loss: 10733882.0000 - val_mae: 2502.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12515704.0000 - mae: 2321.7122 - val_loss: 10000199.0000 - val_mae: 2405.4709\n",
      "Epoch 75/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12044721.0000 - mae: 2309.7178 - val_loss: 10625784.0000 - val_mae: 2501.0776\n",
      "Epoch 76/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11878427.0000 - mae: 2310.9531 - val_loss: 10815238.0000 - val_mae: 2519.6331\n",
      "Epoch 77/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11953990.0000 - mae: 2351.3633 - val_loss: 10750913.0000 - val_mae: 2514.5996\n",
      "Epoch 78/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11911403.0000 - mae: 2352.8823 - val_loss: 10129858.0000 - val_mae: 2436.0571\n",
      "Epoch 79/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12008560.0000 - mae: 2341.9761 - val_loss: 12959365.0000 - val_mae: 2795.3540\n",
      "Epoch 80/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12187089.0000 - mae: 2364.4417 - val_loss: 10036381.0000 - val_mae: 2416.9871\n",
      "Epoch 81/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12203772.0000 - mae: 2320.4780 - val_loss: 10847508.0000 - val_mae: 2520.7676\n",
      "Epoch 82/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11616425.0000 - mae: 2203.2510 - val_loss: 10233411.0000 - val_mae: 2420.2239\n",
      "Epoch 83/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11519860.0000 - mae: 2302.1746 - val_loss: 12207448.0000 - val_mae: 2694.9041\n",
      "Epoch 84/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12332171.0000 - mae: 2428.6875 - val_loss: 10077660.0000 - val_mae: 2434.9395\n",
      "Epoch 85/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11786173.0000 - mae: 2242.9724 - val_loss: 10714985.0000 - val_mae: 2515.1758\n",
      "Epoch 86/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11870243.0000 - mae: 2296.9199 - val_loss: 10001226.0000 - val_mae: 2413.9692\n",
      "Epoch 87/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11516799.0000 - mae: 2268.3757 - val_loss: 9971470.0000 - val_mae: 2408.5347\n",
      "Epoch 88/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11862470.0000 - mae: 2396.8733 - val_loss: 10448214.0000 - val_mae: 2474.9365\n",
      "Epoch 89/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11934955.0000 - mae: 2321.4727 - val_loss: 9962492.0000 - val_mae: 2407.8604\n",
      "Epoch 90/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11782384.0000 - mae: 2295.9082 - val_loss: 10529848.0000 - val_mae: 2485.7856\n",
      "Epoch 91/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11439253.0000 - mae: 2162.1699 - val_loss: 10844379.0000 - val_mae: 2526.7451\n",
      "Epoch 92/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12223669.0000 - mae: 2314.4766 - val_loss: 10896232.0000 - val_mae: 2518.8315\n",
      "Epoch 93/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11729082.0000 - mae: 2284.4246 - val_loss: 10189186.0000 - val_mae: 2422.8010\n",
      "Epoch 94/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10727724.0000 - mae: 2220.3435 - val_loss: 10780108.0000 - val_mae: 2530.9321\n",
      "Epoch 95/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11921994.0000 - mae: 2319.3848 - val_loss: 9949508.0000 - val_mae: 2393.9668\n",
      "Epoch 96/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11256192.0000 - mae: 2240.6069 - val_loss: 11134915.0000 - val_mae: 2537.2732\n",
      "Epoch 97/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12039613.0000 - mae: 2263.7708 - val_loss: 9929016.0000 - val_mae: 2391.6418\n",
      "Epoch 98/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11731158.0000 - mae: 2322.6692 - val_loss: 9916296.0000 - val_mae: 2388.6897\n",
      "Epoch 99/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11527657.0000 - mae: 2239.7896 - val_loss: 9811834.0000 - val_mae: 2376.5237\n",
      "Epoch 100/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11478806.0000 - mae: 2232.5837 - val_loss: 9788833.0000 - val_mae: 2371.7422\n",
      "Epoch 101/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11495660.0000 - mae: 2277.2634 - val_loss: 10853845.0000 - val_mae: 2493.2712\n",
      "Epoch 102/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11499917.0000 - mae: 2288.3911 - val_loss: 9719579.0000 - val_mae: 2361.9675\n",
      "Epoch 103/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11889135.0000 - mae: 2204.4717 - val_loss: 9751565.0000 - val_mae: 2366.7122\n",
      "Epoch 104/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11481061.0000 - mae: 2225.6626 - val_loss: 9797036.0000 - val_mae: 2372.1631\n",
      "Epoch 105/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11782364.0000 - mae: 2207.5046 - val_loss: 10491800.0000 - val_mae: 2437.7441\n",
      "Epoch 106/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11688945.0000 - mae: 2274.0876 - val_loss: 9690989.0000 - val_mae: 2353.2798\n",
      "Epoch 107/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11502520.0000 - mae: 2221.9844 - val_loss: 9647123.0000 - val_mae: 2349.0518\n",
      "Epoch 108/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11046053.0000 - mae: 2291.4436 - val_loss: 9671504.0000 - val_mae: 2353.8220\n",
      "Epoch 109/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11162023.0000 - mae: 2283.0320 - val_loss: 10192246.0000 - val_mae: 2392.8867\n",
      "Epoch 110/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11494810.0000 - mae: 2249.7356 - val_loss: 9706757.0000 - val_mae: 2353.6018\n",
      "Epoch 111/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11340973.0000 - mae: 2278.0007 - val_loss: 9580341.0000 - val_mae: 2330.2246\n",
      "Epoch 112/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11437100.0000 - mae: 2287.9629 - val_loss: 9701863.0000 - val_mae: 2347.6956\n",
      "Epoch 113/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11247116.0000 - mae: 2248.5134 - val_loss: 11147843.0000 - val_mae: 2542.3813\n",
      "Epoch 114/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11232145.0000 - mae: 2255.7798 - val_loss: 10318830.0000 - val_mae: 2423.5723\n",
      "Epoch 115/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10355651.0000 - mae: 2228.9424 - val_loss: 10223408.0000 - val_mae: 2423.6943\n",
      "Epoch 116/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11542225.0000 - mae: 2214.0012 - val_loss: 9749973.0000 - val_mae: 2364.5527\n",
      "Epoch 117/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10433355.0000 - mae: 2144.9185 - val_loss: 14218219.0000 - val_mae: 2988.4399\n",
      "Epoch 118/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11474805.0000 - mae: 2184.8142 - val_loss: 9725475.0000 - val_mae: 2356.5078\n",
      "Epoch 119/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11174252.0000 - mae: 2142.6357 - val_loss: 9960018.0000 - val_mae: 2391.7190\n",
      "Epoch 120/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11172259.0000 - mae: 2276.9104 - val_loss: 9637043.0000 - val_mae: 2346.2795\n",
      "Epoch 121/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10434037.0000 - mae: 2231.6506 - val_loss: 11186437.0000 - val_mae: 2572.8516\n",
      "Epoch 122/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11028997.0000 - mae: 2239.3379 - val_loss: 9732339.0000 - val_mae: 2364.1191\n",
      "Epoch 123/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11467295.0000 - mae: 2186.2788 - val_loss: 9559704.0000 - val_mae: 2331.2795\n",
      "Epoch 124/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11294434.0000 - mae: 2216.1052 - val_loss: 9725656.0000 - val_mae: 2358.1794\n",
      "Epoch 125/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10922243.0000 - mae: 2199.3862 - val_loss: 9814627.0000 - val_mae: 2373.9900\n",
      "Epoch 126/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10205398.0000 - mae: 2145.1257 - val_loss: 11669031.0000 - val_mae: 2638.6660\n",
      "Epoch 127/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11087855.0000 - mae: 2291.5076 - val_loss: 10704056.0000 - val_mae: 2515.0686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10408438.0000 - mae: 2250.9043 - val_loss: 10376583.0000 - val_mae: 2442.1609\n",
      "Epoch 129/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11299855.0000 - mae: 2248.0415 - val_loss: 9553645.0000 - val_mae: 2333.4783\n",
      "Epoch 130/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10999298.0000 - mae: 2190.8132 - val_loss: 10389412.0000 - val_mae: 2442.2439\n",
      "Epoch 131/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10882683.0000 - mae: 2201.2939 - val_loss: 9553294.0000 - val_mae: 2331.8018\n",
      "Epoch 132/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10400304.0000 - mae: 2174.3223 - val_loss: 9517557.0000 - val_mae: 2323.8621\n",
      "Epoch 133/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11682390.0000 - mae: 2202.5962 - val_loss: 9491870.0000 - val_mae: 2321.5698\n",
      "Epoch 134/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10686738.0000 - mae: 2189.2778 - val_loss: 11085224.0000 - val_mae: 2551.0825\n",
      "Epoch 135/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11159986.0000 - mae: 2098.7715 - val_loss: 9477388.0000 - val_mae: 2319.9180\n",
      "Epoch 136/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10792627.0000 - mae: 2172.4832 - val_loss: 9539312.0000 - val_mae: 2329.3848\n",
      "Epoch 137/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10863049.0000 - mae: 2217.4590 - val_loss: 9500776.0000 - val_mae: 2326.9016\n",
      "Epoch 138/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11116598.0000 - mae: 2200.5757 - val_loss: 9517645.0000 - val_mae: 2325.8835\n",
      "Epoch 139/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10644248.0000 - mae: 2158.0994 - val_loss: 9480158.0000 - val_mae: 2322.7634\n",
      "Epoch 140/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10816135.0000 - mae: 2160.7358 - val_loss: 9977795.0000 - val_mae: 2398.5627\n",
      "Epoch 141/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10738625.0000 - mae: 2165.3745 - val_loss: 10459709.0000 - val_mae: 2444.6360\n",
      "Epoch 142/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10536616.0000 - mae: 2167.9683 - val_loss: 10115888.0000 - val_mae: 2388.3518\n",
      "Epoch 143/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10682121.0000 - mae: 2146.6792 - val_loss: 9611209.0000 - val_mae: 2342.2754\n",
      "Epoch 144/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10776247.0000 - mae: 2191.3547 - val_loss: 9577840.0000 - val_mae: 2329.3115\n",
      "Epoch 145/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10583152.0000 - mae: 2194.8472 - val_loss: 9665672.0000 - val_mae: 2340.5291\n",
      "Epoch 146/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10748222.0000 - mae: 2173.0720 - val_loss: 9441619.0000 - val_mae: 2313.4080\n",
      "Epoch 147/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10664636.0000 - mae: 2131.8499 - val_loss: 9413524.0000 - val_mae: 2311.9395\n",
      "Epoch 148/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10747219.0000 - mae: 2130.4834 - val_loss: 9517980.0000 - val_mae: 2328.2046\n",
      "Epoch 149/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10779094.0000 - mae: 2139.8914 - val_loss: 9420623.0000 - val_mae: 2311.6528\n",
      "Epoch 150/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10331951.0000 - mae: 2190.5396 - val_loss: 10590517.0000 - val_mae: 2483.1584\n",
      "Epoch 151/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10419490.0000 - mae: 2182.8254 - val_loss: 10928282.0000 - val_mae: 2523.4995\n",
      "Epoch 152/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9618503.0000 - mae: 2199.2205 - val_loss: 9463305.0000 - val_mae: 2317.0957\n",
      "Epoch 153/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10215802.0000 - mae: 2087.9629 - val_loss: 9793039.0000 - val_mae: 2366.0828\n",
      "Epoch 154/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9772523.0000 - mae: 2080.8340 - val_loss: 11284816.0000 - val_mae: 2611.8284\n",
      "Epoch 155/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10649807.0000 - mae: 2215.9177 - val_loss: 9507642.0000 - val_mae: 2319.8145\n",
      "Epoch 156/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9751400.0000 - mae: 2096.8535 - val_loss: 11674823.0000 - val_mae: 2614.1147\n",
      "Epoch 157/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10962516.0000 - mae: 2178.7585 - val_loss: 9818076.0000 - val_mae: 2374.5369\n",
      "Epoch 158/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10359232.0000 - mae: 2236.1755 - val_loss: 9438589.0000 - val_mae: 2310.5999\n",
      "Epoch 159/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10348186.0000 - mae: 2123.7090 - val_loss: 9656886.0000 - val_mae: 2349.5054\n",
      "Epoch 160/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10501062.0000 - mae: 2126.6392 - val_loss: 11000085.0000 - val_mae: 2528.6350\n",
      "Epoch 161/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10722946.0000 - mae: 2050.9465 - val_loss: 12024964.0000 - val_mae: 2652.1851\n",
      "Epoch 162/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 11213579.0000 - mae: 2059.9490 - val_loss: 9644901.0000 - val_mae: 2341.9365\n",
      "Epoch 163/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10729841.0000 - mae: 2108.6899 - val_loss: 9439003.0000 - val_mae: 2315.9636\n",
      "Epoch 164/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10015627.0000 - mae: 2070.3623 - val_loss: 10247071.0000 - val_mae: 2416.9478\n",
      "Epoch 165/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10400679.0000 - mae: 2210.1733 - val_loss: 9352679.0000 - val_mae: 2301.0015\n",
      "Epoch 166/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10273560.0000 - mae: 2074.0344 - val_loss: 9467221.0000 - val_mae: 2303.2734\n",
      "Epoch 167/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10897217.0000 - mae: 2044.0443 - val_loss: 9335687.0000 - val_mae: 2299.7556\n",
      "Epoch 168/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10522069.0000 - mae: 2108.6428 - val_loss: 10049308.0000 - val_mae: 2392.1062\n",
      "Epoch 169/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10001243.0000 - mae: 2118.2009 - val_loss: 9557800.0000 - val_mae: 2330.4751\n",
      "Epoch 170/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10307240.0000 - mae: 2108.2812 - val_loss: 9570835.0000 - val_mae: 2326.2073\n",
      "Epoch 171/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10234866.0000 - mae: 2063.5769 - val_loss: 9730930.0000 - val_mae: 2343.0774\n",
      "Epoch 172/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10524354.0000 - mae: 2213.5178 - val_loss: 9278123.0000 - val_mae: 2287.4707\n",
      "Epoch 173/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10209155.0000 - mae: 2099.8694 - val_loss: 9355340.0000 - val_mae: 2288.9243\n",
      "Epoch 174/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10490148.0000 - mae: 2155.0649 - val_loss: 9463763.0000 - val_mae: 2314.4053\n",
      "Epoch 175/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10219959.0000 - mae: 2013.4154 - val_loss: 9612163.0000 - val_mae: 2320.8726\n",
      "Epoch 176/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10343372.0000 - mae: 2145.4446 - val_loss: 9243381.0000 - val_mae: 2284.5381\n",
      "Epoch 177/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10589771.0000 - mae: 2022.0995 - val_loss: 9269579.0000 - val_mae: 2285.1143\n",
      "Epoch 178/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10166289.0000 - mae: 2066.1987 - val_loss: 9581696.0000 - val_mae: 2323.7859\n",
      "Epoch 179/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10942520.0000 - mae: 2053.0728 - val_loss: 9962518.0000 - val_mae: 2371.0508\n",
      "Epoch 180/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9988540.0000 - mae: 2000.2729 - val_loss: 9345523.0000 - val_mae: 2287.9656\n",
      "Epoch 181/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9951011.0000 - mae: 2060.4309 - val_loss: 10032912.0000 - val_mae: 2387.1777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9700408.0000 - mae: 2161.8765 - val_loss: 9357880.0000 - val_mae: 2291.6558\n",
      "Epoch 183/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10211691.0000 - mae: 2087.5964 - val_loss: 9291180.0000 - val_mae: 2277.5042\n",
      "Epoch 184/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9832070.0000 - mae: 2126.4170 - val_loss: 9579434.0000 - val_mae: 2318.1011\n",
      "Epoch 185/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10546457.0000 - mae: 2056.1296 - val_loss: 9186568.0000 - val_mae: 2267.5466\n",
      "Epoch 186/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9941709.0000 - mae: 2050.8535 - val_loss: 9219961.0000 - val_mae: 2271.4741\n",
      "Epoch 187/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9809362.0000 - mae: 2013.0828 - val_loss: 10251171.0000 - val_mae: 2387.9277\n",
      "Epoch 188/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10560235.0000 - mae: 2054.7197 - val_loss: 9198854.0000 - val_mae: 2270.5586\n",
      "Epoch 189/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10263914.0000 - mae: 2009.1820 - val_loss: 9500276.0000 - val_mae: 2306.7314\n",
      "Epoch 190/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10232519.0000 - mae: 2056.9763 - val_loss: 9263169.0000 - val_mae: 2278.6775\n",
      "Epoch 191/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10554393.0000 - mae: 2034.0735 - val_loss: 9095297.0000 - val_mae: 2254.7756\n",
      "Epoch 192/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9945187.0000 - mae: 2086.4272 - val_loss: 9306178.0000 - val_mae: 2270.6365\n",
      "Epoch 193/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9604910.0000 - mae: 2007.7521 - val_loss: 9450523.0000 - val_mae: 2274.6384\n",
      "Epoch 194/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9945054.0000 - mae: 2096.4551 - val_loss: 9108840.0000 - val_mae: 2249.4441\n",
      "Epoch 195/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10065883.0000 - mae: 2062.6985 - val_loss: 9570963.0000 - val_mae: 2320.1758\n",
      "Epoch 196/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10150841.0000 - mae: 2094.6438 - val_loss: 9073704.0000 - val_mae: 2249.4023\n",
      "Epoch 197/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10029148.0000 - mae: 2061.1970 - val_loss: 9039063.0000 - val_mae: 2238.8069\n",
      "Epoch 198/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10058150.0000 - mae: 2067.7461 - val_loss: 9072695.0000 - val_mae: 2242.6758\n",
      "Epoch 199/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9971943.0000 - mae: 2060.6172 - val_loss: 9272517.0000 - val_mae: 2267.8623\n",
      "Epoch 200/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10268864.0000 - mae: 2063.4446 - val_loss: 9041990.0000 - val_mae: 2247.2354\n",
      "Epoch 201/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10109403.0000 - mae: 2028.2909 - val_loss: 9199813.0000 - val_mae: 2265.4348\n",
      "Epoch 202/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9406436.0000 - mae: 1880.4866 - val_loss: 10697994.0000 - val_mae: 2482.3652\n",
      "Epoch 203/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10209220.0000 - mae: 2041.5406 - val_loss: 9007966.0000 - val_mae: 2241.8025\n",
      "Epoch 204/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10097210.0000 - mae: 2144.9426 - val_loss: 9011501.0000 - val_mae: 2248.9673\n",
      "Epoch 205/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10409974.0000 - mae: 2004.5312 - val_loss: 8989816.0000 - val_mae: 2244.5959\n",
      "Epoch 206/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9891466.0000 - mae: 2026.8956 - val_loss: 9079789.0000 - val_mae: 2256.1997\n",
      "Epoch 207/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10158864.0000 - mae: 2075.7749 - val_loss: 9073015.0000 - val_mae: 2259.6470\n",
      "Epoch 208/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9477807.0000 - mae: 1972.2236 - val_loss: 8970399.0000 - val_mae: 2248.6699\n",
      "Epoch 209/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9807078.0000 - mae: 2020.5448 - val_loss: 9058486.0000 - val_mae: 2265.4678\n",
      "Epoch 210/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9742520.0000 - mae: 2011.1768 - val_loss: 9021944.0000 - val_mae: 2251.5176\n",
      "Epoch 211/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9806632.0000 - mae: 2034.2236 - val_loss: 9105064.0000 - val_mae: 2258.0732\n",
      "Epoch 212/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10079194.0000 - mae: 2051.1626 - val_loss: 9054458.0000 - val_mae: 2263.3079\n",
      "Epoch 213/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9871230.0000 - mae: 2030.4487 - val_loss: 9182454.0000 - val_mae: 2263.6919\n",
      "Epoch 214/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 10086950.0000 - mae: 2051.8264 - val_loss: 8992927.0000 - val_mae: 2252.5237\n",
      "Epoch 215/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9311342.0000 - mae: 2041.2500 - val_loss: 9107308.0000 - val_mae: 2261.0051\n",
      "Epoch 216/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9948561.0000 - mae: 1955.9253 - val_loss: 9149583.0000 - val_mae: 2276.9255\n",
      "Epoch 217/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9827425.0000 - mae: 2029.7750 - val_loss: 8898221.0000 - val_mae: 2233.8218\n",
      "Epoch 218/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9604563.0000 - mae: 2011.5763 - val_loss: 10183079.0000 - val_mae: 2353.8328\n",
      "Epoch 219/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9709599.0000 - mae: 2012.3297 - val_loss: 8954146.0000 - val_mae: 2250.9119\n",
      "Epoch 220/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9240576.0000 - mae: 1978.9320 - val_loss: 10689017.0000 - val_mae: 2440.6814\n",
      "Epoch 221/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9378380.0000 - mae: 1991.5515 - val_loss: 10604661.0000 - val_mae: 2475.6272\n",
      "Epoch 222/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9407377.0000 - mae: 2012.4779 - val_loss: 9241854.0000 - val_mae: 2272.2976\n",
      "Epoch 223/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9373499.0000 - mae: 1942.6089 - val_loss: 9020664.0000 - val_mae: 2261.6396\n",
      "Epoch 224/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9757912.0000 - mae: 1965.6029 - val_loss: 9216947.0000 - val_mae: 2254.6135\n",
      "Epoch 225/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9802508.0000 - mae: 2009.8406 - val_loss: 8896105.0000 - val_mae: 2239.1948\n",
      "Epoch 226/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9746555.0000 - mae: 1982.9352 - val_loss: 9220215.0000 - val_mae: 2271.2820\n",
      "Epoch 227/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9456158.0000 - mae: 2032.6995 - val_loss: 9430637.0000 - val_mae: 2289.0093\n",
      "Epoch 228/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9571948.0000 - mae: 1993.5034 - val_loss: 9183214.0000 - val_mae: 2264.5947\n",
      "Epoch 229/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9429251.0000 - mae: 1941.6279 - val_loss: 9070625.0000 - val_mae: 2260.4194\n",
      "Epoch 230/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9511127.0000 - mae: 2062.6289 - val_loss: 9190149.0000 - val_mae: 2277.2593\n",
      "Epoch 231/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9280676.0000 - mae: 1940.8644 - val_loss: 9872137.0000 - val_mae: 2361.7168\n",
      "Epoch 232/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9628632.0000 - mae: 2039.0184 - val_loss: 9231999.0000 - val_mae: 2257.2542\n",
      "Epoch 233/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9492841.0000 - mae: 2030.3812 - val_loss: 8954090.0000 - val_mae: 2246.0120\n",
      "Epoch 234/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9758004.0000 - mae: 1986.8628 - val_loss: 9376923.0000 - val_mae: 2293.6221\n",
      "Epoch 235/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9529542.0000 - mae: 2003.6865 - val_loss: 8989960.0000 - val_mae: 2253.9485\n",
      "Epoch 236/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 9421749.0000 - mae: 1977.9862 - val_loss: 9219158.0000 - val_mae: 2273.6914\n",
      "Epoch 237/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9002974.0000 - mae: 2016.0615 - val_loss: 9554561.0000 - val_mae: 2314.4180\n",
      "Epoch 238/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9492546.0000 - mae: 1998.9341 - val_loss: 9223729.0000 - val_mae: 2278.4707\n",
      "Epoch 239/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9516494.0000 - mae: 1905.4655 - val_loss: 9115351.0000 - val_mae: 2259.0515\n",
      "Epoch 240/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9615511.0000 - mae: 2048.1689 - val_loss: 9044202.0000 - val_mae: 2260.7295\n",
      "Epoch 241/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9767660.0000 - mae: 2026.1650 - val_loss: 9044423.0000 - val_mae: 2262.6418\n",
      "Epoch 242/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9277544.0000 - mae: 1971.8948 - val_loss: 9435593.0000 - val_mae: 2308.9724\n",
      "Epoch 243/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9397087.0000 - mae: 2054.3220 - val_loss: 9145982.0000 - val_mae: 2263.0088\n",
      "Epoch 244/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9442519.0000 - mae: 1976.9954 - val_loss: 9345761.0000 - val_mae: 2302.2766\n",
      "Epoch 245/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9082376.0000 - mae: 1954.6768 - val_loss: 10442893.0000 - val_mae: 2430.8203\n",
      "Epoch 246/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9936251.0000 - mae: 1953.2454 - val_loss: 8962561.0000 - val_mae: 2252.5161\n",
      "Epoch 247/500\n",
      "68/68 [==============================] - ETA: 0s - loss: 13872293.0000 - mae: 3724.552 - 0s 1ms/step - loss: 9503425.0000 - mae: 1993.9810 - val_loss: 9155372.0000 - val_mae: 2257.4851\n",
      "Epoch 248/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9439371.0000 - mae: 2017.2490 - val_loss: 9057807.0000 - val_mae: 2252.0723\n",
      "Epoch 249/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8707976.0000 - mae: 1925.9509 - val_loss: 10034077.0000 - val_mae: 2397.4395\n",
      "Epoch 250/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8908220.0000 - mae: 2062.8081 - val_loss: 9974380.0000 - val_mae: 2369.7610\n",
      "Epoch 251/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9553534.0000 - mae: 1905.5332 - val_loss: 9252954.0000 - val_mae: 2305.6021\n",
      "Epoch 252/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8681155.0000 - mae: 2099.6499 - val_loss: 8990283.0000 - val_mae: 2240.0447\n",
      "Epoch 253/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8467016.0000 - mae: 1941.6919 - val_loss: 9394700.0000 - val_mae: 2326.8135\n",
      "Epoch 254/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9171316.0000 - mae: 2039.7518 - val_loss: 9409589.0000 - val_mae: 2289.6912\n",
      "Epoch 255/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9218093.0000 - mae: 1953.9458 - val_loss: 9033416.0000 - val_mae: 2258.9856\n",
      "Epoch 256/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9808841.0000 - mae: 1970.0149 - val_loss: 8912242.0000 - val_mae: 2228.5986\n",
      "Epoch 257/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9446292.0000 - mae: 1995.9502 - val_loss: 8955441.0000 - val_mae: 2235.7380\n",
      "Epoch 258/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9193638.0000 - mae: 1923.7196 - val_loss: 9373046.0000 - val_mae: 2308.3262\n",
      "Epoch 259/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9210282.0000 - mae: 1978.4869 - val_loss: 9798023.0000 - val_mae: 2363.3293\n",
      "Epoch 260/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9835702.0000 - mae: 1954.3838 - val_loss: 8957817.0000 - val_mae: 2235.6399\n",
      "Epoch 261/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9151911.0000 - mae: 1938.4750 - val_loss: 9444763.0000 - val_mae: 2306.7529\n",
      "Epoch 262/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9201912.0000 - mae: 1992.6356 - val_loss: 8900319.0000 - val_mae: 2233.7644\n",
      "Epoch 263/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9166421.0000 - mae: 1973.6888 - val_loss: 9226478.0000 - val_mae: 2259.2585\n",
      "Epoch 264/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8576147.0000 - mae: 1940.5887 - val_loss: 8982472.0000 - val_mae: 2219.7214\n",
      "Epoch 265/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8968094.0000 - mae: 1959.5558 - val_loss: 8920504.0000 - val_mae: 2216.6409\n",
      "Epoch 266/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9199540.0000 - mae: 1983.6018 - val_loss: 8851085.0000 - val_mae: 2209.7239\n",
      "Epoch 267/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8641413.0000 - mae: 1932.5889 - val_loss: 8714838.0000 - val_mae: 2236.5405\n",
      "Epoch 268/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8539872.0000 - mae: 1866.7723 - val_loss: 10327915.0000 - val_mae: 2394.8057\n",
      "Epoch 269/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8957189.0000 - mae: 1987.7939 - val_loss: 8744511.0000 - val_mae: 2187.0549\n",
      "Epoch 270/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9250332.0000 - mae: 1837.7716 - val_loss: 8990853.0000 - val_mae: 2217.4131\n",
      "Epoch 271/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8801490.0000 - mae: 1978.4200 - val_loss: 9393571.0000 - val_mae: 2266.4043\n",
      "Epoch 272/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9126069.0000 - mae: 1932.3857 - val_loss: 8689693.0000 - val_mae: 2176.6208\n",
      "Epoch 273/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9234893.0000 - mae: 1845.3339 - val_loss: 8950668.0000 - val_mae: 2218.4126\n",
      "Epoch 274/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9227780.0000 - mae: 1821.8096 - val_loss: 8794886.0000 - val_mae: 2187.3044\n",
      "Epoch 275/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8582004.0000 - mae: 2000.4867 - val_loss: 8898927.0000 - val_mae: 2217.1235\n",
      "Epoch 276/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8019681.0000 - mae: 1922.9048 - val_loss: 9779489.0000 - val_mae: 2325.6270\n",
      "Epoch 277/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8832983.0000 - mae: 1798.8781 - val_loss: 10610976.0000 - val_mae: 2405.9551\n",
      "Epoch 278/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9154891.0000 - mae: 1934.8428 - val_loss: 8871758.0000 - val_mae: 2210.7200\n",
      "Epoch 279/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8680118.0000 - mae: 1857.1591 - val_loss: 9590538.0000 - val_mae: 2255.2793\n",
      "Epoch 280/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8563350.0000 - mae: 1929.7148 - val_loss: 8662696.0000 - val_mae: 2188.1646\n",
      "Epoch 281/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9053884.0000 - mae: 1912.9854 - val_loss: 8693630.0000 - val_mae: 2197.9673\n",
      "Epoch 282/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8278435.0000 - mae: 1882.7634 - val_loss: 8767420.0000 - val_mae: 2174.8340\n",
      "Epoch 283/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9213886.0000 - mae: 1931.8856 - val_loss: 8981979.0000 - val_mae: 2247.0984\n",
      "Epoch 284/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8563861.0000 - mae: 1888.8865 - val_loss: 8940599.0000 - val_mae: 2246.2319\n",
      "Epoch 285/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9006632.0000 - mae: 1977.4407 - val_loss: 8722407.0000 - val_mae: 2216.9646\n",
      "Epoch 286/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8359875.0000 - mae: 1845.5891 - val_loss: 9786095.0000 - val_mae: 2298.7385\n",
      "Epoch 287/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8084087.5000 - mae: 1838.5779 - val_loss: 11142448.0000 - val_mae: 2459.9321\n",
      "Epoch 288/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9187432.0000 - mae: 1915.5938 - val_loss: 9067031.0000 - val_mae: 2267.7361\n",
      "Epoch 289/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 8663826.0000 - mae: 1828.5244 - val_loss: 9033763.0000 - val_mae: 2258.2473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8708788.0000 - mae: 1931.8833 - val_loss: 9383863.0000 - val_mae: 2262.4922\n",
      "Epoch 291/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8663471.0000 - mae: 1911.0991 - val_loss: 9298340.0000 - val_mae: 2255.2913\n",
      "Epoch 292/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8035161.5000 - mae: 1843.7618 - val_loss: 10291496.0000 - val_mae: 2412.9861\n",
      "Epoch 293/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8332391.5000 - mae: 1929.0221 - val_loss: 8792041.0000 - val_mae: 2234.7493\n",
      "Epoch 294/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8814545.0000 - mae: 1909.0526 - val_loss: 8704649.0000 - val_mae: 2225.6287\n",
      "Epoch 295/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8828801.0000 - mae: 1851.2251 - val_loss: 8987382.0000 - val_mae: 2258.4824\n",
      "Epoch 296/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8582790.0000 - mae: 1849.7528 - val_loss: 8753860.0000 - val_mae: 2221.9556\n",
      "Epoch 297/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8681217.0000 - mae: 1928.9646 - val_loss: 9160324.0000 - val_mae: 2293.0591\n",
      "Epoch 298/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8985541.0000 - mae: 1892.7238 - val_loss: 8672151.0000 - val_mae: 2225.3320\n",
      "Epoch 299/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8432720.0000 - mae: 1861.9681 - val_loss: 9035775.0000 - val_mae: 2270.9917\n",
      "Epoch 300/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7887663.5000 - mae: 1865.1694 - val_loss: 10349758.0000 - val_mae: 2363.1179\n",
      "Epoch 301/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8569009.0000 - mae: 1950.7275 - val_loss: 9334888.0000 - val_mae: 2253.3311\n",
      "Epoch 302/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7988336.0000 - mae: 1810.2843 - val_loss: 8701249.0000 - val_mae: 2216.7524\n",
      "Epoch 303/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8625528.0000 - mae: 1846.7758 - val_loss: 8801453.0000 - val_mae: 2205.7607\n",
      "Epoch 304/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 9084021.0000 - mae: 1895.8240 - val_loss: 8538466.0000 - val_mae: 2187.7554\n",
      "Epoch 305/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8450229.0000 - mae: 1923.4916 - val_loss: 8626712.0000 - val_mae: 2210.8508\n",
      "Epoch 306/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8326760.5000 - mae: 1792.9092 - val_loss: 8876121.0000 - val_mae: 2232.6011\n",
      "Epoch 307/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7865873.0000 - mae: 1926.6317 - val_loss: 8903718.0000 - val_mae: 2246.5513\n",
      "Epoch 308/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 8117795.0000 - mae: 1843.6183 - val_loss: 8718876.0000 - val_mae: 2215.5254\n",
      "Epoch 309/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8711318.0000 - mae: 1838.2581 - val_loss: 9278777.0000 - val_mae: 2286.1113\n",
      "Epoch 310/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8629783.0000 - mae: 1853.1086 - val_loss: 8953742.0000 - val_mae: 2247.0569\n",
      "Epoch 311/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8691796.0000 - mae: 1798.5763 - val_loss: 8901832.0000 - val_mae: 2221.7622\n",
      "Epoch 312/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7694766.5000 - mae: 1914.1320 - val_loss: 9975089.0000 - val_mae: 2423.3572\n",
      "Epoch 313/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8791769.0000 - mae: 1878.3838 - val_loss: 8852470.0000 - val_mae: 2237.6018\n",
      "Epoch 314/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8088582.5000 - mae: 1930.6967 - val_loss: 8787733.0000 - val_mae: 2225.1626\n",
      "Epoch 315/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7714813.5000 - mae: 1860.9269 - val_loss: 10765199.0000 - val_mae: 2420.3921\n",
      "Epoch 316/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8297446.5000 - mae: 1945.6377 - val_loss: 9283540.0000 - val_mae: 2241.1907\n",
      "Epoch 317/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8202325.5000 - mae: 1890.1533 - val_loss: 8748106.0000 - val_mae: 2229.2988\n",
      "Epoch 318/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8696269.0000 - mae: 1810.6915 - val_loss: 8660344.0000 - val_mae: 2187.7024\n",
      "Epoch 319/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7896110.0000 - mae: 1830.4755 - val_loss: 8370166.5000 - val_mae: 2157.8496\n",
      "Epoch 320/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8372806.5000 - mae: 1876.2695 - val_loss: 8909146.0000 - val_mae: 2234.1704\n",
      "Epoch 321/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7789909.5000 - mae: 1875.6022 - val_loss: 8787148.0000 - val_mae: 2230.3604\n",
      "Epoch 322/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8388687.0000 - mae: 1834.8417 - val_loss: 8795430.0000 - val_mae: 2239.3196\n",
      "Epoch 323/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8245289.5000 - mae: 1826.3317 - val_loss: 8779779.0000 - val_mae: 2233.3733\n",
      "Epoch 324/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7819044.5000 - mae: 1732.2528 - val_loss: 9053113.0000 - val_mae: 2213.4214\n",
      "Epoch 325/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8204444.0000 - mae: 1840.3589 - val_loss: 9170735.0000 - val_mae: 2225.0718\n",
      "Epoch 326/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7845734.5000 - mae: 1821.5417 - val_loss: 9499174.0000 - val_mae: 2352.9480\n",
      "Epoch 327/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7926620.0000 - mae: 1780.6165 - val_loss: 9746080.0000 - val_mae: 2370.2302\n",
      "Epoch 328/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8537273.0000 - mae: 1817.3558 - val_loss: 8390811.0000 - val_mae: 2159.4810\n",
      "Epoch 329/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7914092.0000 - mae: 1881.6511 - val_loss: 9712992.0000 - val_mae: 2372.3613\n",
      "Epoch 330/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8290562.0000 - mae: 1807.5303 - val_loss: 8429037.0000 - val_mae: 2178.5310\n",
      "Epoch 331/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7895857.0000 - mae: 1844.2323 - val_loss: 9137371.0000 - val_mae: 2250.3364\n",
      "Epoch 332/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8060581.5000 - mae: 1735.9330 - val_loss: 9334456.0000 - val_mae: 2246.9900\n",
      "Epoch 333/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8023410.0000 - mae: 1830.0978 - val_loss: 8681371.0000 - val_mae: 2200.3027\n",
      "Epoch 334/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7928604.0000 - mae: 1840.2511 - val_loss: 8700559.0000 - val_mae: 2202.7102\n",
      "Epoch 335/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7868332.0000 - mae: 1829.4259 - val_loss: 8348958.0000 - val_mae: 2162.6248\n",
      "Epoch 336/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 8165798.5000 - mae: 1816.8661 - val_loss: 9026364.0000 - val_mae: 2239.5371\n",
      "Epoch 337/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7272213.5000 - mae: 1822.3958 - val_loss: 8546859.0000 - val_mae: 2185.8411\n",
      "Epoch 338/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 8033894.5000 - mae: 1796.6642 - val_loss: 8208975.0000 - val_mae: 2139.5664\n",
      "Epoch 339/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7753251.0000 - mae: 1756.7721 - val_loss: 9102213.0000 - val_mae: 2280.5786\n",
      "Epoch 340/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7646202.0000 - mae: 1790.8054 - val_loss: 8691951.0000 - val_mae: 2206.5269\n",
      "Epoch 341/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7161488.0000 - mae: 1774.0082 - val_loss: 8681270.0000 - val_mae: 2201.7402\n",
      "Epoch 342/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7457596.0000 - mae: 1783.7665 - val_loss: 8704885.0000 - val_mae: 2213.0791\n",
      "Epoch 343/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7803754.5000 - mae: 1844.2533 - val_loss: 8849778.0000 - val_mae: 2194.7749\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 7435910.0000 - mae: 1839.5492 - val_loss: 9372160.0000 - val_mae: 2318.7854\n",
      "Epoch 345/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7863975.0000 - mae: 1777.0245 - val_loss: 8481464.0000 - val_mae: 2182.2671\n",
      "Epoch 346/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7698354.0000 - mae: 1834.7723 - val_loss: 8382691.0000 - val_mae: 2159.4246\n",
      "Epoch 347/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7580299.5000 - mae: 1770.0349 - val_loss: 8747224.0000 - val_mae: 2206.3840\n",
      "Epoch 348/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7927669.5000 - mae: 1720.2546 - val_loss: 8595148.0000 - val_mae: 2188.2922\n",
      "Epoch 349/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7474889.0000 - mae: 1798.1273 - val_loss: 8829446.0000 - val_mae: 2221.0918\n",
      "Epoch 350/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7644056.0000 - mae: 1887.2383 - val_loss: 8866795.0000 - val_mae: 2201.8848\n",
      "Epoch 351/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7893476.0000 - mae: 1783.5282 - val_loss: 8904345.0000 - val_mae: 2228.3079\n",
      "Epoch 352/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7253649.0000 - mae: 1755.7258 - val_loss: 8669703.0000 - val_mae: 2184.9031\n",
      "Epoch 353/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7635399.5000 - mae: 1860.5078 - val_loss: 9250688.0000 - val_mae: 2239.3354\n",
      "Epoch 354/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7043244.5000 - mae: 1804.4034 - val_loss: 8725491.0000 - val_mae: 2200.3813\n",
      "Epoch 355/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7245085.5000 - mae: 1762.0142 - val_loss: 9153391.0000 - val_mae: 2199.9109\n",
      "Epoch 356/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7683128.5000 - mae: 1770.0825 - val_loss: 9612167.0000 - val_mae: 2276.9883\n",
      "Epoch 357/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7428344.0000 - mae: 1855.4740 - val_loss: 8351006.0000 - val_mae: 2157.9036\n",
      "Epoch 358/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7637177.0000 - mae: 1784.5385 - val_loss: 8461338.0000 - val_mae: 2170.1213\n",
      "Epoch 359/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7357984.0000 - mae: 1745.3047 - val_loss: 8834247.0000 - val_mae: 2238.6880\n",
      "Epoch 360/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7192326.0000 - mae: 1718.0081 - val_loss: 9343820.0000 - val_mae: 2233.1638\n",
      "Epoch 361/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7634281.0000 - mae: 1738.2396 - val_loss: 9102661.0000 - val_mae: 2257.8149\n",
      "Epoch 362/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7393699.5000 - mae: 1764.3895 - val_loss: 8797993.0000 - val_mae: 2231.6387\n",
      "Epoch 363/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7294628.5000 - mae: 1685.6357 - val_loss: 9354866.0000 - val_mae: 2353.5967\n",
      "Epoch 364/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7786236.0000 - mae: 1751.1913 - val_loss: 8552368.0000 - val_mae: 2137.3452\n",
      "Epoch 365/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7502297.5000 - mae: 1773.8981 - val_loss: 9180663.0000 - val_mae: 2203.8567\n",
      "Epoch 366/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7271909.5000 - mae: 1755.5873 - val_loss: 8851990.0000 - val_mae: 2176.2891\n",
      "Epoch 367/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7156484.0000 - mae: 1802.3226 - val_loss: 9220746.0000 - val_mae: 2317.7314\n",
      "Epoch 368/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7304417.0000 - mae: 1817.8805 - val_loss: 8482978.0000 - val_mae: 2177.8345\n",
      "Epoch 369/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6935015.0000 - mae: 1660.9410 - val_loss: 8477314.0000 - val_mae: 2164.4189\n",
      "Epoch 370/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7414874.0000 - mae: 1885.2756 - val_loss: 8574461.0000 - val_mae: 2192.4426\n",
      "Epoch 371/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7069268.5000 - mae: 1772.2727 - val_loss: 8855551.0000 - val_mae: 2182.4578\n",
      "Epoch 372/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7252007.5000 - mae: 1753.2311 - val_loss: 8781206.0000 - val_mae: 2206.3794\n",
      "Epoch 373/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7699107.5000 - mae: 1753.3716 - val_loss: 8504261.0000 - val_mae: 2187.5225\n",
      "Epoch 374/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7202503.5000 - mae: 1770.4573 - val_loss: 8419164.0000 - val_mae: 2182.4043\n",
      "Epoch 375/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6895134.0000 - mae: 1768.4591 - val_loss: 9762578.0000 - val_mae: 2291.0457\n",
      "Epoch 376/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6607840.0000 - mae: 1798.7458 - val_loss: 9095901.0000 - val_mae: 2288.6365\n",
      "Epoch 377/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7463167.0000 - mae: 1743.1451 - val_loss: 8327420.0000 - val_mae: 2126.5508\n",
      "Epoch 378/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6800664.0000 - mae: 1695.1804 - val_loss: 8333178.5000 - val_mae: 2156.1099\n",
      "Epoch 379/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7712088.5000 - mae: 1689.2095 - val_loss: 8188454.5000 - val_mae: 2136.0540\n",
      "Epoch 380/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7079896.5000 - mae: 1744.7068 - val_loss: 8222908.0000 - val_mae: 2128.4570\n",
      "Epoch 381/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6266989.5000 - mae: 1667.9961 - val_loss: 8652453.0000 - val_mae: 2209.7117\n",
      "Epoch 382/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7275929.0000 - mae: 1770.6975 - val_loss: 8179818.5000 - val_mae: 2106.6340\n",
      "Epoch 383/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7426483.0000 - mae: 1750.4556 - val_loss: 8442157.0000 - val_mae: 2156.8923\n",
      "Epoch 384/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7527958.0000 - mae: 1676.2638 - val_loss: 9132529.0000 - val_mae: 2223.8904\n",
      "Epoch 385/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6569848.0000 - mae: 1766.7891 - val_loss: 9170704.0000 - val_mae: 2201.3123\n",
      "Epoch 386/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7094763.5000 - mae: 1791.4089 - val_loss: 8350912.0000 - val_mae: 2142.3479\n",
      "Epoch 387/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7105905.5000 - mae: 1804.4962 - val_loss: 8193688.5000 - val_mae: 2120.6699\n",
      "Epoch 388/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6957641.0000 - mae: 1815.6367 - val_loss: 8358384.0000 - val_mae: 2128.7922\n",
      "Epoch 389/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7147053.5000 - mae: 1682.5935 - val_loss: 8737377.0000 - val_mae: 2169.9858\n",
      "Epoch 390/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6595425.0000 - mae: 1736.8429 - val_loss: 8659185.0000 - val_mae: 2139.4006\n",
      "Epoch 391/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6787788.0000 - mae: 1769.7472 - val_loss: 8419432.0000 - val_mae: 2168.3250\n",
      "Epoch 392/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6514651.0000 - mae: 1637.1555 - val_loss: 8247450.5000 - val_mae: 2118.1475\n",
      "Epoch 393/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6710188.5000 - mae: 1786.1531 - val_loss: 8058385.0000 - val_mae: 2107.7090\n",
      "Epoch 394/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6625258.0000 - mae: 1648.9958 - val_loss: 8818885.0000 - val_mae: 2233.1370\n",
      "Epoch 395/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6793094.0000 - mae: 1727.9904 - val_loss: 8157947.5000 - val_mae: 2107.1497\n",
      "Epoch 396/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6339923.5000 - mae: 1602.3613 - val_loss: 9714839.0000 - val_mae: 2244.9785\n",
      "Epoch 397/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 7159657.0000 - mae: 1767.7654 - val_loss: 8664052.0000 - val_mae: 2141.4204\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 7117346.5000 - mae: 1692.3556 - val_loss: 8162796.0000 - val_mae: 2098.4216\n",
      "Epoch 399/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6646935.5000 - mae: 1662.7430 - val_loss: 8992078.0000 - val_mae: 2173.3438\n",
      "Epoch 400/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6319603.5000 - mae: 1713.0321 - val_loss: 9055852.0000 - val_mae: 2275.2898\n",
      "Epoch 401/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6843289.0000 - mae: 1781.8799 - val_loss: 8942067.0000 - val_mae: 2244.8960\n",
      "Epoch 402/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6421137.0000 - mae: 1699.2345 - val_loss: 8018536.5000 - val_mae: 2097.0674\n",
      "Epoch 403/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6280548.0000 - mae: 1697.0479 - val_loss: 8531607.0000 - val_mae: 2165.8005\n",
      "Epoch 404/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6463597.0000 - mae: 1698.8812 - val_loss: 8222567.5000 - val_mae: 2088.7800\n",
      "Epoch 405/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6778953.5000 - mae: 1731.1469 - val_loss: 8253533.0000 - val_mae: 2076.4331\n",
      "Epoch 406/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6650932.0000 - mae: 1586.5913 - val_loss: 9394987.0000 - val_mae: 2308.3530\n",
      "Epoch 407/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6679392.0000 - mae: 1706.0442 - val_loss: 8047876.0000 - val_mae: 2077.3669\n",
      "Epoch 408/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6261306.5000 - mae: 1725.1123 - val_loss: 8940314.0000 - val_mae: 2277.5322\n",
      "Epoch 409/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6646572.0000 - mae: 1763.3199 - val_loss: 8252217.5000 - val_mae: 2100.2854\n",
      "Epoch 410/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6400359.0000 - mae: 1756.5933 - val_loss: 8261650.0000 - val_mae: 2076.4131\n",
      "Epoch 411/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6829374.0000 - mae: 1728.6411 - val_loss: 8685593.0000 - val_mae: 2152.6936\n",
      "Epoch 412/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6536108.0000 - mae: 1666.3185 - val_loss: 8463485.0000 - val_mae: 2114.0317\n",
      "Epoch 413/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6271818.5000 - mae: 1617.5493 - val_loss: 8396522.0000 - val_mae: 2098.1536\n",
      "Epoch 414/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6504919.0000 - mae: 1711.7039 - val_loss: 7926140.0000 - val_mae: 2082.7446\n",
      "Epoch 415/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6868900.0000 - mae: 1649.8812 - val_loss: 8141991.5000 - val_mae: 2119.3843\n",
      "Epoch 416/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6346979.0000 - mae: 1717.2617 - val_loss: 8384922.5000 - val_mae: 2134.2637\n",
      "Epoch 417/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6128480.5000 - mae: 1651.4524 - val_loss: 8499866.0000 - val_mae: 2095.0354\n",
      "Epoch 418/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6315400.5000 - mae: 1726.8528 - val_loss: 8464232.0000 - val_mae: 2165.6086\n",
      "Epoch 419/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6361357.0000 - mae: 1711.8159 - val_loss: 8700816.0000 - val_mae: 2106.0500\n",
      "Epoch 420/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6137244.5000 - mae: 1602.0988 - val_loss: 7858052.0000 - val_mae: 2046.7881\n",
      "Epoch 421/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6634428.5000 - mae: 1687.5393 - val_loss: 8196751.0000 - val_mae: 2112.3899\n",
      "Epoch 422/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6518076.0000 - mae: 1701.6602 - val_loss: 8688443.0000 - val_mae: 2086.7852\n",
      "Epoch 423/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6132922.5000 - mae: 1611.1785 - val_loss: 8701013.0000 - val_mae: 2180.6272\n",
      "Epoch 424/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6148282.0000 - mae: 1734.5142 - val_loss: 8489134.0000 - val_mae: 2152.8149\n",
      "Epoch 425/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6461740.0000 - mae: 1675.4774 - val_loss: 8856990.0000 - val_mae: 2118.8220\n",
      "Epoch 426/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 5893844.0000 - mae: 1615.2939 - val_loss: 8960971.0000 - val_mae: 2133.2043\n",
      "Epoch 427/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6612081.5000 - mae: 1682.0859 - val_loss: 8342283.5000 - val_mae: 2116.2637\n",
      "Epoch 428/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5621613.0000 - mae: 1584.0420 - val_loss: 7711796.0000 - val_mae: 1977.7844\n",
      "Epoch 429/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6450452.0000 - mae: 1638.4852 - val_loss: 7808677.5000 - val_mae: 2001.5654\n",
      "Epoch 430/500\n",
      "68/68 [==============================] - 0s 983us/step - loss: 6676505.5000 - mae: 1644.9468 - val_loss: 7887656.5000 - val_mae: 2004.5049\n",
      "Epoch 431/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6618437.0000 - mae: 1656.1868 - val_loss: 8790824.0000 - val_mae: 2147.7019\n",
      "Epoch 432/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6619817.0000 - mae: 1653.4451 - val_loss: 8621014.0000 - val_mae: 2109.1111\n",
      "Epoch 433/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6048126.0000 - mae: 1646.6011 - val_loss: 7675179.5000 - val_mae: 2006.4805\n",
      "Epoch 434/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6158947.0000 - mae: 1607.4364 - val_loss: 9105880.0000 - val_mae: 2155.2732\n",
      "Epoch 435/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6169566.0000 - mae: 1776.5414 - val_loss: 8472530.0000 - val_mae: 2127.9072\n",
      "Epoch 436/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6240828.0000 - mae: 1674.3955 - val_loss: 9621815.0000 - val_mae: 2192.9341\n",
      "Epoch 437/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 5802951.0000 - mae: 1563.9167 - val_loss: 8186095.0000 - val_mae: 2052.1287\n",
      "Epoch 438/500\n",
      "68/68 [==============================] - 0s 997us/step - loss: 6194782.5000 - mae: 1636.1587 - val_loss: 7941022.0000 - val_mae: 2047.8718\n",
      "Epoch 439/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6365191.5000 - mae: 1676.9515 - val_loss: 8393204.0000 - val_mae: 2075.5999\n",
      "Epoch 440/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6491155.0000 - mae: 1677.4786 - val_loss: 8352525.0000 - val_mae: 2107.2656\n",
      "Epoch 441/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6307159.0000 - mae: 1607.1735 - val_loss: 8659373.0000 - val_mae: 2082.5579\n",
      "Epoch 442/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6248323.0000 - mae: 1686.4336 - val_loss: 8407689.0000 - val_mae: 2070.9744\n",
      "Epoch 443/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6143941.5000 - mae: 1708.3472 - val_loss: 8312356.5000 - val_mae: 2130.3369\n",
      "Epoch 444/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6164505.5000 - mae: 1704.3992 - val_loss: 7953996.0000 - val_mae: 2009.2576\n",
      "Epoch 445/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6646345.5000 - mae: 1619.8160 - val_loss: 7994780.0000 - val_mae: 2034.3414\n",
      "Epoch 446/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6319474.5000 - mae: 1633.7737 - val_loss: 8742569.0000 - val_mae: 2143.5342\n",
      "Epoch 447/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5644989.0000 - mae: 1594.6226 - val_loss: 7813164.5000 - val_mae: 2043.4414\n",
      "Epoch 448/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5757436.0000 - mae: 1625.0696 - val_loss: 8644113.0000 - val_mae: 2070.2583\n",
      "Epoch 449/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6200911.0000 - mae: 1632.2153 - val_loss: 8228855.5000 - val_mae: 2068.3535\n",
      "Epoch 450/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6156861.5000 - mae: 1614.4553 - val_loss: 8210819.0000 - val_mae: 2037.0214\n",
      "Epoch 451/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6128592.0000 - mae: 1676.3328 - val_loss: 8357052.0000 - val_mae: 2089.6792\n",
      "Epoch 452/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 5985959.5000 - mae: 1653.4556 - val_loss: 8356354.0000 - val_mae: 2053.3586\n",
      "Epoch 453/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6006136.0000 - mae: 1604.8485 - val_loss: 8271857.0000 - val_mae: 2072.1602\n",
      "Epoch 454/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6332536.5000 - mae: 1619.3733 - val_loss: 8415689.0000 - val_mae: 2121.7380\n",
      "Epoch 455/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5620540.5000 - mae: 1691.5704 - val_loss: 7687975.5000 - val_mae: 2011.7448\n",
      "Epoch 456/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6167299.5000 - mae: 1651.2554 - val_loss: 8107208.5000 - val_mae: 2049.4033\n",
      "Epoch 457/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6062153.0000 - mae: 1608.1890 - val_loss: 8178686.0000 - val_mae: 2098.3982\n",
      "Epoch 458/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5905437.5000 - mae: 1681.6111 - val_loss: 9407269.0000 - val_mae: 2229.6846\n",
      "Epoch 459/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5759608.5000 - mae: 1676.7100 - val_loss: 8127391.0000 - val_mae: 2077.3550\n",
      "Epoch 460/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5883877.5000 - mae: 1632.3896 - val_loss: 8105136.0000 - val_mae: 2064.1362\n",
      "Epoch 461/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5877738.0000 - mae: 1704.4775 - val_loss: 8291203.0000 - val_mae: 2054.7146\n",
      "Epoch 462/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6081661.5000 - mae: 1662.8422 - val_loss: 8403103.0000 - val_mae: 2085.3184\n",
      "Epoch 463/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 5932360.0000 - mae: 1647.8409 - val_loss: 8626619.0000 - val_mae: 2195.5750\n",
      "Epoch 464/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 5611546.0000 - mae: 1538.9110 - val_loss: 7741230.0000 - val_mae: 1986.2911\n",
      "Epoch 465/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6115934.0000 - mae: 1630.1328 - val_loss: 7939252.0000 - val_mae: 2059.8074\n",
      "Epoch 466/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5706388.0000 - mae: 1670.5508 - val_loss: 7732306.5000 - val_mae: 1993.2307\n",
      "Epoch 467/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5781663.0000 - mae: 1613.5653 - val_loss: 8912682.0000 - val_mae: 2109.0566\n",
      "Epoch 468/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5401131.5000 - mae: 1594.4056 - val_loss: 8533315.0000 - val_mae: 2199.0203\n",
      "Epoch 469/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6015458.0000 - mae: 1550.7865 - val_loss: 7966357.5000 - val_mae: 1996.9052\n",
      "Epoch 470/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5886126.5000 - mae: 1722.3907 - val_loss: 7672599.5000 - val_mae: 1988.3690\n",
      "Epoch 471/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5850311.5000 - mae: 1654.1866 - val_loss: 8438872.0000 - val_mae: 2109.0901\n",
      "Epoch 472/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6010297.0000 - mae: 1605.4977 - val_loss: 8284304.0000 - val_mae: 2122.8564\n",
      "Epoch 473/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5737528.5000 - mae: 1597.6328 - val_loss: 8408824.0000 - val_mae: 2062.3296\n",
      "Epoch 474/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5931284.0000 - mae: 1631.1000 - val_loss: 8315858.0000 - val_mae: 2071.6780\n",
      "Epoch 475/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5921208.0000 - mae: 1619.0066 - val_loss: 8119009.0000 - val_mae: 2078.5999\n",
      "Epoch 476/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5890994.5000 - mae: 1548.3518 - val_loss: 7512770.0000 - val_mae: 1956.6891\n",
      "Epoch 477/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5804279.0000 - mae: 1524.9429 - val_loss: 7803609.5000 - val_mae: 2045.9391\n",
      "Epoch 478/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5422886.0000 - mae: 1586.7810 - val_loss: 7420648.0000 - val_mae: 1946.4354\n",
      "Epoch 479/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 6459832.0000 - mae: 1626.7847 - val_loss: 7229090.0000 - val_mae: 1914.4446\n",
      "Epoch 480/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5834246.5000 - mae: 1568.4204 - val_loss: 8117940.5000 - val_mae: 2102.1660\n",
      "Epoch 481/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5870345.5000 - mae: 1589.4337 - val_loss: 7336577.0000 - val_mae: 1926.4470\n",
      "Epoch 482/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5557062.0000 - mae: 1515.6450 - val_loss: 7118187.5000 - val_mae: 1895.8568\n",
      "Epoch 483/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5951175.5000 - mae: 1567.3364 - val_loss: 7836533.0000 - val_mae: 2031.7201\n",
      "Epoch 484/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5377071.5000 - mae: 1565.1167 - val_loss: 8325100.0000 - val_mae: 2110.0359\n",
      "Epoch 485/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5408912.5000 - mae: 1611.4189 - val_loss: 9560269.0000 - val_mae: 2185.5227\n",
      "Epoch 486/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5715254.5000 - mae: 1644.9664 - val_loss: 7458410.0000 - val_mae: 1911.8103\n",
      "Epoch 487/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5673204.0000 - mae: 1648.6228 - val_loss: 8534803.0000 - val_mae: 2021.7346\n",
      "Epoch 488/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5178053.5000 - mae: 1517.9462 - val_loss: 7599061.5000 - val_mae: 1963.8484\n",
      "Epoch 489/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5779688.5000 - mae: 1548.5381 - val_loss: 7704679.0000 - val_mae: 1958.0627\n",
      "Epoch 490/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5743754.5000 - mae: 1634.8656 - val_loss: 7925404.0000 - val_mae: 1953.8605\n",
      "Epoch 491/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5540677.0000 - mae: 1606.9385 - val_loss: 7292031.0000 - val_mae: 1892.3088\n",
      "Epoch 492/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5673380.5000 - mae: 1551.7909 - val_loss: 8208554.5000 - val_mae: 2083.3809\n",
      "Epoch 493/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5758914.5000 - mae: 1556.0310 - val_loss: 7331500.5000 - val_mae: 1911.3705\n",
      "Epoch 494/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5174217.5000 - mae: 1562.6362 - val_loss: 9058235.0000 - val_mae: 2236.0232\n",
      "Epoch 495/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5424488.5000 - mae: 1515.8082 - val_loss: 7802882.0000 - val_mae: 2010.0455\n",
      "Epoch 496/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5623299.5000 - mae: 1606.2158 - val_loss: 7569195.5000 - val_mae: 1971.7706\n",
      "Epoch 497/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5444103.5000 - mae: 1615.8693 - val_loss: 7852930.5000 - val_mae: 2013.1143\n",
      "Epoch 498/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5543172.0000 - mae: 1595.5686 - val_loss: 7876020.5000 - val_mae: 1946.5664\n",
      "Epoch 499/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5213207.5000 - mae: 1533.1742 - val_loss: 7189865.5000 - val_mae: 1885.5940\n",
      "Epoch 500/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 5483109.5000 - mae: 1603.8674 - val_loss: 8875019.0000 - val_mae: 2103.1804\n"
     ]
    }
   ],
   "source": [
    "x = df_shuff[103:,:25].astype('float32')\n",
    "y = df_shuff[103:,25].astype('float32')\n",
    "k = 3\n",
    "num_val_samples = len(x) // k\n",
    "num_epochs = 500\n",
    "all_scores = []\n",
    "\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate([x[:i * num_val_samples],x[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([y[:i * num_val_samples],y[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1,validation_data=(val_data, val_targets))\n",
    "    #all_scores.append(np.mean(history.history['val_mae']))\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    all_scores.append(np.mean(mae_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2295.858367919922, 3132.474460449219, 2358.4678112792967], 2595.600213216146)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores , np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "smooth_mae_history = smooth_curve(average_mae_history[50:])\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No. of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower capacity\n",
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation='relu',input_shape=(train_data.shape[1],)))\n",
    "    #model.add(layers.Dense(6, activation='relu')) #6491\n",
    "    #model.add(layers.Dense(6, activation='relu')) #7963.930517578125\n",
    "   # model.add(layers.Dense(8, activation='relu'))#7635\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C0B02719D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C0B0854A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002C0B25CE168> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "x = df_shuff[103:,:25].astype('float32')\n",
    "y = df_shuff[103:,25].astype('float32')\n",
    "k = 3\n",
    "num_val_samples = len(x) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    #print('processing fold #', i)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate([x[:i * num_val_samples],x[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([y[:i * num_val_samples],y[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 10-8 -----3300.224853515625 \n",
    "     ,for 10-6 ----------- 3115.2639973958335\n",
    "     , for 25-10------------------3906.263671875\n",
    "              \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3880.220703125, 4441.96923828125, 3396.60107421875]\n",
      "3906.263671875\n"
     ]
    }
   ],
   "source": [
    "print(all_scores)\n",
    "print(np.mean(all_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Droping Layer with 8 neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation='tanh',input_shape=(train_data.shape[1],)))\n",
    "    #model.add(layers.Dense(10, activation='tanh'))\n",
    "    #model.add(layers.Dense(8, activation='tanh'))\n",
    "    model.add(layers.Dense(6, activation='tanh'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_shuff[103:,:25].astype('float32')\n",
    "y = df_shuff[103:,25].astype('float32')\n",
    "k = 3\n",
    "num_val_samples = len(x) // k\n",
    "num_epochs = 100\n",
    "all_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/100\n",
      "53/68 [======================>.......] - ETA: 0s - loss: 248534080.0000 - mae: 13582.6943WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 225758784.0000 - mae: 13007.2266 - val_loss: 176251264.0000 - val_mae: 11840.1592\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225732560.0000 - mae: 13006.1816 - val_loss: 176229936.0000 - val_mae: 11839.2266\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225712416.0000 - mae: 13005.3711 - val_loss: 176213824.0000 - val_mae: 11838.5215\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225696528.0000 - mae: 13004.7383 - val_loss: 176200848.0000 - val_mae: 11837.9492\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225683584.0000 - mae: 13004.2227 - val_loss: 176189712.0000 - val_mae: 11837.4639\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225671824.0000 - mae: 13003.7695 - val_loss: 176179184.0000 - val_mae: 11837.0166\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225660416.0000 - mae: 13003.3369 - val_loss: 176169248.0000 - val_mae: 11836.5957\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225649712.0000 - mae: 13002.9238 - val_loss: 176159536.0000 - val_mae: 11836.1836\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225639056.0000 - mae: 13002.5039 - val_loss: 176149840.0000 - val_mae: 11835.7754\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225629008.0000 - mae: 13002.0986 - val_loss: 176140288.0000 - val_mae: 11835.3740\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225617696.0000 - mae: 13001.6797 - val_loss: 176130496.0000 - val_mae: 11834.9609\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225607200.0000 - mae: 13001.2725 - val_loss: 176120816.0000 - val_mae: 11834.5420\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225596144.0000 - mae: 13000.8594 - val_loss: 176110928.0000 - val_mae: 11834.1279\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225585536.0000 - mae: 13000.4453 - val_loss: 176101104.0000 - val_mae: 11833.7178\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225574608.0000 - mae: 13000.0342 - val_loss: 176091296.0000 - val_mae: 11833.3047\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225564416.0000 - mae: 12999.6260 - val_loss: 176081856.0000 - val_mae: 11832.9033\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225553968.0000 - mae: 12999.2188 - val_loss: 176072272.0000 - val_mae: 11832.4990\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225543024.0000 - mae: 12998.8047 - val_loss: 176062128.0000 - val_mae: 11832.0654\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225532064.0000 - mae: 12998.3887 - val_loss: 176052352.0000 - val_mae: 11831.6553\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225521456.0000 - mae: 12997.9766 - val_loss: 176042944.0000 - val_mae: 11831.2549\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225511232.0000 - mae: 12997.5723 - val_loss: 176033152.0000 - val_mae: 11830.8447\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225499904.0000 - mae: 12997.1553 - val_loss: 176023424.0000 - val_mae: 11830.4346\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225489312.0000 - mae: 12996.7471 - val_loss: 176013664.0000 - val_mae: 11830.0234\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225478864.0000 - mae: 12996.3369 - val_loss: 176004000.0000 - val_mae: 11829.6045\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225467776.0000 - mae: 12995.9248 - val_loss: 175994016.0000 - val_mae: 11829.1885\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225457488.0000 - mae: 12995.5137 - val_loss: 175984400.0000 - val_mae: 11828.7832\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225446560.0000 - mae: 12995.1045 - val_loss: 175974640.0000 - val_mae: 11828.3740\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225435728.0000 - mae: 12994.6943 - val_loss: 175965024.0000 - val_mae: 11827.9678\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225424896.0000 - mae: 12994.2812 - val_loss: 175954896.0000 - val_mae: 11827.5332\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225414544.0000 - mae: 12993.8691 - val_loss: 175945648.0000 - val_mae: 11827.1484\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225404384.0000 - mae: 12993.4678 - val_loss: 175936160.0000 - val_mae: 11826.7471\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225393216.0000 - mae: 12993.0547 - val_loss: 175925968.0000 - val_mae: 11826.3135\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225382752.0000 - mae: 12992.6367 - val_loss: 175916608.0000 - val_mae: 11825.9141\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225371664.0000 - mae: 12992.2256 - val_loss: 175906672.0000 - val_mae: 11825.4990\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225361456.0000 - mae: 12991.8145 - val_loss: 175896944.0000 - val_mae: 11825.0879\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225350464.0000 - mae: 12991.3994 - val_loss: 175887136.0000 - val_mae: 11824.6650\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225339792.0000 - mae: 12990.9922 - val_loss: 175877248.0000 - val_mae: 11824.2529\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225329072.0000 - mae: 12990.5820 - val_loss: 175867840.0000 - val_mae: 11823.8516\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225318704.0000 - mae: 12990.1777 - val_loss: 175858288.0000 - val_mae: 11823.4453\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225308208.0000 - mae: 12989.7715 - val_loss: 175848704.0000 - val_mae: 11823.0410\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225297536.0000 - mae: 12989.3623 - val_loss: 175839104.0000 - val_mae: 11822.6338\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225286432.0000 - mae: 12988.9463 - val_loss: 175828976.0000 - val_mae: 11822.2129\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225276176.0000 - mae: 12988.5391 - val_loss: 175819664.0000 - val_mae: 11821.8154\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225265472.0000 - mae: 12988.1289 - val_loss: 175809680.0000 - val_mae: 11821.3984\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225255008.0000 - mae: 12987.7188 - val_loss: 175800112.0000 - val_mae: 11820.9932\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225244144.0000 - mae: 12987.3066 - val_loss: 175790464.0000 - val_mae: 11820.5859\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225233488.0000 - mae: 12986.8984 - val_loss: 175780768.0000 - val_mae: 11820.1670\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225222800.0000 - mae: 12986.4941 - val_loss: 175770864.0000 - val_mae: 11819.7520\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225212464.0000 - mae: 12986.0840 - val_loss: 175761440.0000 - val_mae: 11819.3486\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225201696.0000 - mae: 12985.6709 - val_loss: 175751632.0000 - val_mae: 11818.9385\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225191120.0000 - mae: 12985.2598 - val_loss: 175742048.0000 - val_mae: 11818.5332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225180016.0000 - mae: 12984.8516 - val_loss: 175732096.0000 - val_mae: 11818.1045\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225169984.0000 - mae: 12984.4434 - val_loss: 175722656.0000 - val_mae: 11817.7178\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225158784.0000 - mae: 12984.0244 - val_loss: 175712928.0000 - val_mae: 11817.3057\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225148768.0000 - mae: 12983.6182 - val_loss: 175703424.0000 - val_mae: 11816.9023\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225137408.0000 - mae: 12983.1982 - val_loss: 175693280.0000 - val_mae: 11816.4707\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225126768.0000 - mae: 12982.7891 - val_loss: 175683456.0000 - val_mae: 11816.0566\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225116000.0000 - mae: 12982.3789 - val_loss: 175673856.0000 - val_mae: 11815.6504\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225105696.0000 - mae: 12981.9736 - val_loss: 175664432.0000 - val_mae: 11815.2510\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225095040.0000 - mae: 12981.5615 - val_loss: 175654704.0000 - val_mae: 11814.8428\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225084384.0000 - mae: 12981.1621 - val_loss: 175645248.0000 - val_mae: 11814.4385\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225073808.0000 - mae: 12980.7500 - val_loss: 175635136.0000 - val_mae: 11814.0068\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225062720.0000 - mae: 12980.3330 - val_loss: 175625264.0000 - val_mae: 11813.5928\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225052240.0000 - mae: 12979.9287 - val_loss: 175615888.0000 - val_mae: 11813.1924\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225041600.0000 - mae: 12979.5098 - val_loss: 175606144.0000 - val_mae: 11812.7832\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225031392.0000 - mae: 12979.1074 - val_loss: 175596576.0000 - val_mae: 11812.3770\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225020800.0000 - mae: 12978.6934 - val_loss: 175586960.0000 - val_mae: 11811.9707\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 225010080.0000 - mae: 12978.2852 - val_loss: 175577104.0000 - val_mae: 11811.5576\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224999168.0000 - mae: 12977.8760 - val_loss: 175567424.0000 - val_mae: 11811.1484\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224988432.0000 - mae: 12977.4658 - val_loss: 175557536.0000 - val_mae: 11810.7217\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224978144.0000 - mae: 12977.0566 - val_loss: 175548288.0000 - val_mae: 11810.3369\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224967536.0000 - mae: 12976.6475 - val_loss: 175538496.0000 - val_mae: 11809.9160\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224956368.0000 - mae: 12976.2393 - val_loss: 175528640.0000 - val_mae: 11809.5010\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224945952.0000 - mae: 12975.8252 - val_loss: 175519072.0000 - val_mae: 11809.0957\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224935728.0000 - mae: 12975.4141 - val_loss: 175509376.0000 - val_mae: 11808.6865\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224924928.0000 - mae: 12975.0078 - val_loss: 175499920.0000 - val_mae: 11808.2842\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224914032.0000 - mae: 12974.6006 - val_loss: 175489920.0000 - val_mae: 11807.8545\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224903648.0000 - mae: 12974.1914 - val_loss: 175480304.0000 - val_mae: 11807.4492\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224892992.0000 - mae: 12973.7744 - val_loss: 175470928.0000 - val_mae: 11807.0615\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224882784.0000 - mae: 12973.3721 - val_loss: 175461296.0000 - val_mae: 11806.6514\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224871216.0000 - mae: 12972.9541 - val_loss: 175450976.0000 - val_mae: 11806.2178\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224861040.0000 - mae: 12972.5420 - val_loss: 175441680.0000 - val_mae: 11805.8174\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224850608.0000 - mae: 12972.1377 - val_loss: 175432032.0000 - val_mae: 11805.4082\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224839488.0000 - mae: 12971.7305 - val_loss: 175422064.0000 - val_mae: 11804.9922\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224828800.0000 - mae: 12971.3076 - val_loss: 175412544.0000 - val_mae: 11804.5879\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224818544.0000 - mae: 12970.8984 - val_loss: 175402800.0000 - val_mae: 11804.1670\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224807696.0000 - mae: 12970.4883 - val_loss: 175393360.0000 - val_mae: 11803.7744\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224796800.0000 - mae: 12970.0820 - val_loss: 175383168.0000 - val_mae: 11803.3428\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224786576.0000 - mae: 12969.6670 - val_loss: 175373952.0000 - val_mae: 11802.9463\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224776096.0000 - mae: 12969.2627 - val_loss: 175364256.0000 - val_mae: 11802.5361\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224765040.0000 - mae: 12968.8574 - val_loss: 175354400.0000 - val_mae: 11802.1240\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224754688.0000 - mae: 12968.4443 - val_loss: 175344992.0000 - val_mae: 11801.7217\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224743504.0000 - mae: 12968.0312 - val_loss: 175334832.0000 - val_mae: 11801.2900\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224733056.0000 - mae: 12967.6240 - val_loss: 175325264.0000 - val_mae: 11800.8838\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224722720.0000 - mae: 12967.2139 - val_loss: 175315712.0000 - val_mae: 11800.4785\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224712512.0000 - mae: 12966.8096 - val_loss: 175306240.0000 - val_mae: 11800.0859\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224701136.0000 - mae: 12966.3926 - val_loss: 175296272.0000 - val_mae: 11799.6592\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224690880.0000 - mae: 12965.9883 - val_loss: 175286624.0000 - val_mae: 11799.2510\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224679776.0000 - mae: 12965.5752 - val_loss: 175276992.0000 - val_mae: 11798.8447\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 224669408.0000 - mae: 12965.1670 - val_loss: 175267312.0000 - val_mae: 11798.4365\n",
      "processing fold # 1\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 186359920.0000 - mae: 12150.7041 - val_loss: 255083968.0000 - val_mae: 13554.5391\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186338640.0000 - mae: 12149.7910 - val_loss: 255062016.0000 - val_mae: 13553.6973\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186319824.0000 - mae: 12148.9990 - val_loss: 255043552.0000 - val_mae: 13552.9951\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 2ms/step - loss: 186305120.0000 - mae: 12148.3760 - val_loss: 255028768.0000 - val_mae: 13552.4326\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 104899464.0000 - mae: 10242.043 - 0s 997us/step - loss: 186292544.0000 - mae: 12147.8486 - val_loss: 255015728.0000 - val_mae: 13551.9512\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186281120.0000 - mae: 12147.3789 - val_loss: 255003280.0000 - val_mae: 13551.4980\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186270240.0000 - mae: 12146.9395 - val_loss: 254991568.0000 - val_mae: 13551.0674\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186259824.0000 - mae: 12146.5029 - val_loss: 254979888.0000 - val_mae: 13550.6328\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186249360.0000 - mae: 12146.0762 - val_loss: 254968560.0000 - val_mae: 13550.2188\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186239568.0000 - mae: 12145.6631 - val_loss: 254957024.0000 - val_mae: 13549.7891\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186229056.0000 - mae: 12145.2314 - val_loss: 254945552.0000 - val_mae: 13549.3672\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 983us/step - loss: 186218608.0000 - mae: 12144.8066 - val_loss: 254933680.0000 - val_mae: 13548.9238\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 50730652.0000 - mae: 7122.545 - 0s 1ms/step - loss: 186208144.0000 - mae: 12144.3828 - val_loss: 254922608.0000 - val_mae: 13548.5156\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186197888.0000 - mae: 12143.9600 - val_loss: 254911104.0000 - val_mae: 13548.0986\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186187744.0000 - mae: 12143.5391 - val_loss: 254899408.0000 - val_mae: 13547.6631\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186177792.0000 - mae: 12143.1172 - val_loss: 254888208.0000 - val_mae: 13547.2549\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186167360.0000 - mae: 12142.6914 - val_loss: 254876816.0000 - val_mae: 13546.8271\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186157040.0000 - mae: 12142.2686 - val_loss: 254865408.0000 - val_mae: 13546.4121\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186146704.0000 - mae: 12141.8516 - val_loss: 254853776.0000 - val_mae: 13545.9766\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186136560.0000 - mae: 12141.4277 - val_loss: 254842432.0000 - val_mae: 13545.5625\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186126192.0000 - mae: 12141.0059 - val_loss: 254831008.0000 - val_mae: 13545.1348\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186116016.0000 - mae: 12140.5840 - val_loss: 254819568.0000 - val_mae: 13544.7188\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186106064.0000 - mae: 12140.1670 - val_loss: 254808160.0000 - val_mae: 13544.2910\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186095472.0000 - mae: 12139.7354 - val_loss: 254796656.0000 - val_mae: 13543.8740\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186085104.0000 - mae: 12139.3145 - val_loss: 254784896.0000 - val_mae: 13543.4395\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186074688.0000 - mae: 12138.8867 - val_loss: 254773696.0000 - val_mae: 13543.0166\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186064544.0000 - mae: 12138.4688 - val_loss: 254762352.0000 - val_mae: 13542.6016\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186054528.0000 - mae: 12138.0459 - val_loss: 254751088.0000 - val_mae: 13542.1924\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186043904.0000 - mae: 12137.6250 - val_loss: 254739360.0000 - val_mae: 13541.7568\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186034000.0000 - mae: 12137.2061 - val_loss: 254728224.0000 - val_mae: 13541.3486\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186024208.0000 - mae: 12136.7881 - val_loss: 254716784.0000 - val_mae: 13540.9189\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186013792.0000 - mae: 12136.3662 - val_loss: 254705216.0000 - val_mae: 13540.4980\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 186003328.0000 - mae: 12135.9336 - val_loss: 254693856.0000 - val_mae: 13540.0703\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185993008.0000 - mae: 12135.5166 - val_loss: 254682048.0000 - val_mae: 13539.6348\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185982368.0000 - mae: 12135.0889 - val_loss: 254670640.0000 - val_mae: 13539.2207\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185972560.0000 - mae: 12134.6670 - val_loss: 254659552.0000 - val_mae: 13538.8115\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185962224.0000 - mae: 12134.2451 - val_loss: 254648176.0000 - val_mae: 13538.3838\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185952304.0000 - mae: 12133.8291 - val_loss: 254636688.0000 - val_mae: 13537.9678\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185941376.0000 - mae: 12133.3965 - val_loss: 254624912.0000 - val_mae: 13537.5312\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185931392.0000 - mae: 12132.9775 - val_loss: 254613648.0000 - val_mae: 13537.1094\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185921120.0000 - mae: 12132.5557 - val_loss: 254602032.0000 - val_mae: 13536.6875\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185910784.0000 - mae: 12132.1279 - val_loss: 254590640.0000 - val_mae: 13536.2588\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185900704.0000 - mae: 12131.7041 - val_loss: 254579536.0000 - val_mae: 13535.8516\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185890704.0000 - mae: 12131.2891 - val_loss: 254567792.0000 - val_mae: 13535.4160\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185879568.0000 - mae: 12130.8525 - val_loss: 254555712.0000 - val_mae: 13534.9756\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185869696.0000 - mae: 12130.4297 - val_loss: 254544832.0000 - val_mae: 13534.5703\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185859568.0000 - mae: 12130.0107 - val_loss: 254533392.0000 - val_mae: 13534.1416\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185848960.0000 - mae: 12129.5879 - val_loss: 254521856.0000 - val_mae: 13533.7256\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185838976.0000 - mae: 12129.1660 - val_loss: 254510448.0000 - val_mae: 13533.2969\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185828480.0000 - mae: 12128.7441 - val_loss: 254498848.0000 - val_mae: 13532.8750\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185818336.0000 - mae: 12128.3203 - val_loss: 254487616.0000 - val_mae: 13532.4531\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185808368.0000 - mae: 12127.9033 - val_loss: 254476256.0000 - val_mae: 13532.0381\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185797760.0000 - mae: 12127.4766 - val_loss: 254464384.0000 - val_mae: 13531.6006\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185787488.0000 - mae: 12127.0508 - val_loss: 254453104.0000 - val_mae: 13531.1865\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185777328.0000 - mae: 12126.6328 - val_loss: 254441472.0000 - val_mae: 13530.7549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185766768.0000 - mae: 12126.2002 - val_loss: 254430208.0000 - val_mae: 13530.3291\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185756800.0000 - mae: 12125.7832 - val_loss: 254418768.0000 - val_mae: 13529.9131\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185746736.0000 - mae: 12125.3594 - val_loss: 254407376.0000 - val_mae: 13529.4980\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185736496.0000 - mae: 12124.9365 - val_loss: 254395872.0000 - val_mae: 13529.0693\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185726176.0000 - mae: 12124.5127 - val_loss: 254384400.0000 - val_mae: 13528.6396\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185715952.0000 - mae: 12124.0918 - val_loss: 254373008.0000 - val_mae: 13528.2256\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185705632.0000 - mae: 12123.6738 - val_loss: 254361744.0000 - val_mae: 13527.8105\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185695408.0000 - mae: 12123.2461 - val_loss: 254350336.0000 - val_mae: 13527.3828\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185685184.0000 - mae: 12122.8301 - val_loss: 254338832.0000 - val_mae: 13526.9541\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185675312.0000 - mae: 12122.4092 - val_loss: 254327600.0000 - val_mae: 13526.5391\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185664320.0000 - mae: 12121.9814 - val_loss: 254315824.0000 - val_mae: 13526.1035\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185653968.0000 - mae: 12121.5537 - val_loss: 254304256.0000 - val_mae: 13525.6855\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185644112.0000 - mae: 12121.1328 - val_loss: 254293136.0000 - val_mae: 13525.2656\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185634064.0000 - mae: 12120.7109 - val_loss: 254281936.0000 - val_mae: 13524.8516\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185623744.0000 - mae: 12120.2910 - val_loss: 254270192.0000 - val_mae: 13524.4189\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185613648.0000 - mae: 12119.8662 - val_loss: 254258832.0000 - val_mae: 13524.0049\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185603408.0000 - mae: 12119.4492 - val_loss: 254247520.0000 - val_mae: 13523.5791\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 254919616.0000 - mae: 15966.202 - 0s 1ms/step - loss: 185593296.0000 - mae: 12119.0293 - val_loss: 254236064.0000 - val_mae: 13523.1631\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185582816.0000 - mae: 12118.6094 - val_loss: 254224688.0000 - val_mae: 13522.7344\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185572480.0000 - mae: 12118.1777 - val_loss: 254213328.0000 - val_mae: 13522.3203\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185562528.0000 - mae: 12117.7598 - val_loss: 254201856.0000 - val_mae: 13521.8906\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185552528.0000 - mae: 12117.3418 - val_loss: 254190688.0000 - val_mae: 13521.4775\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185541760.0000 - mae: 12116.9141 - val_loss: 254179024.0000 - val_mae: 13521.0459\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185531568.0000 - mae: 12116.4912 - val_loss: 254167280.0000 - val_mae: 13520.6104\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185520784.0000 - mae: 12116.0605 - val_loss: 254155680.0000 - val_mae: 13520.1895\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185510528.0000 - mae: 12115.6357 - val_loss: 254143904.0000 - val_mae: 13519.7559\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185500688.0000 - mae: 12115.2129 - val_loss: 254133040.0000 - val_mae: 13519.3506\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185490304.0000 - mae: 12114.7881 - val_loss: 254121168.0000 - val_mae: 13518.9131\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185480096.0000 - mae: 12114.3623 - val_loss: 254110112.0000 - val_mae: 13518.5059\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185469872.0000 - mae: 12113.9453 - val_loss: 254098736.0000 - val_mae: 13518.0771\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185459488.0000 - mae: 12113.5186 - val_loss: 254087024.0000 - val_mae: 13517.6523\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185449264.0000 - mae: 12113.1016 - val_loss: 254075664.0000 - val_mae: 13517.2266\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185439456.0000 - mae: 12112.6787 - val_loss: 254064496.0000 - val_mae: 13516.8184\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185429344.0000 - mae: 12112.2627 - val_loss: 254053008.0000 - val_mae: 13516.3848\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185418624.0000 - mae: 12111.8389 - val_loss: 254041536.0000 - val_mae: 13515.9678\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185408272.0000 - mae: 12111.4111 - val_loss: 254030032.0000 - val_mae: 13515.5391\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185398320.0000 - mae: 12110.9834 - val_loss: 254018928.0000 - val_mae: 13515.1318\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185388144.0000 - mae: 12110.5654 - val_loss: 254007504.0000 - val_mae: 13514.7021\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185377728.0000 - mae: 12110.1455 - val_loss: 253995824.0000 - val_mae: 13514.2666\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185367584.0000 - mae: 12109.7266 - val_loss: 253984528.0000 - val_mae: 13513.8525\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185357040.0000 - mae: 12109.2979 - val_loss: 253972784.0000 - val_mae: 13513.4160\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185347344.0000 - mae: 12108.8779 - val_loss: 253961792.0000 - val_mae: 13513.0127\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185337216.0000 - mae: 12108.4609 - val_loss: 253950368.0000 - val_mae: 13512.5938\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185326608.0000 - mae: 12108.0322 - val_loss: 253938816.0000 - val_mae: 13512.1631\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 185316496.0000 - mae: 12107.6064 - val_loss: 253927456.0000 - val_mae: 13511.7480\n",
      "processing fold # 2\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 215623792.0000 - mae: 12695.5479 - val_loss: 196365872.0000 - val_mae: 12457.0195\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215593856.0000 - mae: 12694.3936 - val_loss: 196344624.0000 - val_mae: 12456.1660\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215576496.0000 - mae: 12693.6895 - val_loss: 196329888.0000 - val_mae: 12455.5742\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215563280.0000 - mae: 12693.1670 - val_loss: 196318272.0000 - val_mae: 12455.1055\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215551344.0000 - mae: 12692.7090 - val_loss: 196307088.0000 - val_mae: 12454.6641\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215541008.0000 - mae: 12692.2900 - val_loss: 196296864.0000 - val_mae: 12454.2568\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215530320.0000 - mae: 12691.8750 - val_loss: 196286304.0000 - val_mae: 12453.8242\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 215519584.0000 - mae: 12691.4521 - val_loss: 196276384.0000 - val_mae: 12453.4268\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215508944.0000 - mae: 12691.0459 - val_loss: 196265616.0000 - val_mae: 12452.9990\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215498832.0000 - mae: 12690.6328 - val_loss: 196255952.0000 - val_mae: 12452.6055\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215488432.0000 - mae: 12690.2285 - val_loss: 196245072.0000 - val_mae: 12452.1680\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215477760.0000 - mae: 12689.8008 - val_loss: 196235408.0000 - val_mae: 12451.7881\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215467920.0000 - mae: 12689.4072 - val_loss: 196225280.0000 - val_mae: 12451.3818\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215457728.0000 - mae: 12688.9941 - val_loss: 196215312.0000 - val_mae: 12450.9766\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215446224.0000 - mae: 12688.5771 - val_loss: 196204400.0000 - val_mae: 12450.5391\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215435680.0000 - mae: 12688.1572 - val_loss: 196193984.0000 - val_mae: 12450.1240\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215425680.0000 - mae: 12687.7510 - val_loss: 196184112.0000 - val_mae: 12449.7266\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215415680.0000 - mae: 12687.3447 - val_loss: 196174048.0000 - val_mae: 12449.3203\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215404560.0000 - mae: 12686.9307 - val_loss: 196163360.0000 - val_mae: 12448.8867\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215394528.0000 - mae: 12686.5244 - val_loss: 196153536.0000 - val_mae: 12448.4990\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215384528.0000 - mae: 12686.1191 - val_loss: 196143424.0000 - val_mae: 12448.0928\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215373968.0000 - mae: 12685.7090 - val_loss: 196133056.0000 - val_mae: 12447.6699\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215363616.0000 - mae: 12685.2939 - val_loss: 196123008.0000 - val_mae: 12447.2676\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215352992.0000 - mae: 12684.8818 - val_loss: 196112624.0000 - val_mae: 12446.8535\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215342336.0000 - mae: 12684.4707 - val_loss: 196102128.0000 - val_mae: 12446.4258\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215332208.0000 - mae: 12684.0566 - val_loss: 196092240.0000 - val_mae: 12446.0381\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215321984.0000 - mae: 12683.6572 - val_loss: 196082160.0000 - val_mae: 12445.6318\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215311440.0000 - mae: 12683.2432 - val_loss: 196071936.0000 - val_mae: 12445.2207\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215300560.0000 - mae: 12682.8262 - val_loss: 196061328.0000 - val_mae: 12444.7910\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215290416.0000 - mae: 12682.4199 - val_loss: 196051152.0000 - val_mae: 12444.3828\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215279920.0000 - mae: 12682.0049 - val_loss: 196041040.0000 - val_mae: 12443.9766\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215270000.0000 - mae: 12681.5977 - val_loss: 196031280.0000 - val_mae: 12443.5820\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215259040.0000 - mae: 12681.1855 - val_loss: 196020448.0000 - val_mae: 12443.1543\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 997us/step - loss: 215248912.0000 - mae: 12680.7734 - val_loss: 196010448.0000 - val_mae: 12442.7490\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215238272.0000 - mae: 12680.3564 - val_loss: 195999712.0000 - val_mae: 12442.3193\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215228256.0000 - mae: 12679.9463 - val_loss: 195990064.0000 - val_mae: 12441.9258\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215217664.0000 - mae: 12679.5391 - val_loss: 195979744.0000 - val_mae: 12441.5117\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215206720.0000 - mae: 12679.1250 - val_loss: 195969184.0000 - val_mae: 12441.0928\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215196208.0000 - mae: 12678.7168 - val_loss: 195959168.0000 - val_mae: 12440.6885\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215186432.0000 - mae: 12678.3057 - val_loss: 195949152.0000 - val_mae: 12440.2881\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215175472.0000 - mae: 12677.8896 - val_loss: 195938576.0000 - val_mae: 12439.8555\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215165424.0000 - mae: 12677.4873 - val_loss: 195928480.0000 - val_mae: 12439.4492\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215154720.0000 - mae: 12677.0713 - val_loss: 195918176.0000 - val_mae: 12439.0400\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215144592.0000 - mae: 12676.6631 - val_loss: 195908176.0000 - val_mae: 12438.6348\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215134320.0000 - mae: 12676.2627 - val_loss: 195898064.0000 - val_mae: 12438.2285\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215123664.0000 - mae: 12675.8457 - val_loss: 195887856.0000 - val_mae: 12437.8203\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215113280.0000 - mae: 12675.4326 - val_loss: 195877664.0000 - val_mae: 12437.4131\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215102704.0000 - mae: 12675.0234 - val_loss: 195867200.0000 - val_mae: 12436.9883\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215092464.0000 - mae: 12674.6123 - val_loss: 195857200.0000 - val_mae: 12436.5908\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215082352.0000 - mae: 12674.2061 - val_loss: 195846752.0000 - val_mae: 12436.1660\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215071536.0000 - mae: 12673.7959 - val_loss: 195836640.0000 - val_mae: 12435.7598\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215061072.0000 - mae: 12673.3809 - val_loss: 195826496.0000 - val_mae: 12435.3525\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215051200.0000 - mae: 12672.9766 - val_loss: 195816352.0000 - val_mae: 12434.9453\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215040816.0000 - mae: 12672.5645 - val_loss: 195806384.0000 - val_mae: 12434.5430\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215030592.0000 - mae: 12672.1641 - val_loss: 195796032.0000 - val_mae: 12434.1318\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215020096.0000 - mae: 12671.7500 - val_loss: 195785968.0000 - val_mae: 12433.7256\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 215009504.0000 - mae: 12671.3359 - val_loss: 195775696.0000 - val_mae: 12433.3135\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214998864.0000 - mae: 12670.9238 - val_loss: 195764928.0000 - val_mae: 12432.8818\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214988160.0000 - mae: 12670.5107 - val_loss: 195754848.0000 - val_mae: 12432.4756\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 997us/step - loss: 214977872.0000 - mae: 12670.1016 - val_loss: 195744752.0000 - val_mae: 12432.0693\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214967936.0000 - mae: 12669.6953 - val_loss: 195734720.0000 - val_mae: 12431.6641\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214957616.0000 - mae: 12669.2861 - val_loss: 195724720.0000 - val_mae: 12431.2598\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214947296.0000 - mae: 12668.8809 - val_loss: 195714432.0000 - val_mae: 12430.8506\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214936896.0000 - mae: 12668.4668 - val_loss: 195704224.0000 - val_mae: 12430.4385\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214926208.0000 - mae: 12668.0527 - val_loss: 195693648.0000 - val_mae: 12430.0098\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214915600.0000 - mae: 12667.6426 - val_loss: 195683616.0000 - val_mae: 12429.6035\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214905488.0000 - mae: 12667.2363 - val_loss: 195673728.0000 - val_mae: 12429.2051\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214894784.0000 - mae: 12666.8281 - val_loss: 195663072.0000 - val_mae: 12428.7822\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214884944.0000 - mae: 12666.4141 - val_loss: 195653264.0000 - val_mae: 12428.3848\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214874240.0000 - mae: 12666.0039 - val_loss: 195642976.0000 - val_mae: 12427.9756\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214864000.0000 - mae: 12665.5967 - val_loss: 195632976.0000 - val_mae: 12427.5703\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214853504.0000 - mae: 12665.1826 - val_loss: 195622224.0000 - val_mae: 12427.1348\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 997us/step - loss: 214843104.0000 - mae: 12664.7725 - val_loss: 195612384.0000 - val_mae: 12426.7383\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214833264.0000 - mae: 12664.3691 - val_loss: 195602480.0000 - val_mae: 12426.3447\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214822672.0000 - mae: 12663.9541 - val_loss: 195592288.0000 - val_mae: 12425.9365\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 245089328.0000 - mae: 15655.329 - 0s 1ms/step - loss: 214812112.0000 - mae: 12663.5420 - val_loss: 195582000.0000 - val_mae: 12425.5166\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214801472.0000 - mae: 12663.1309 - val_loss: 195571424.0000 - val_mae: 12425.0947\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214790832.0000 - mae: 12662.7197 - val_loss: 195561136.0000 - val_mae: 12424.6768\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214780864.0000 - mae: 12662.3086 - val_loss: 195551152.0000 - val_mae: 12424.2803\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214770400.0000 - mae: 12661.9033 - val_loss: 195541024.0000 - val_mae: 12423.8701\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214760112.0000 - mae: 12661.4902 - val_loss: 195530928.0000 - val_mae: 12423.4678\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214749552.0000 - mae: 12661.0801 - val_loss: 195520704.0000 - val_mae: 12423.0488\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214738880.0000 - mae: 12660.6689 - val_loss: 195509888.0000 - val_mae: 12422.6133\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214728688.0000 - mae: 12660.2549 - val_loss: 195500144.0000 - val_mae: 12422.2266\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214718288.0000 - mae: 12659.8525 - val_loss: 195490144.0000 - val_mae: 12421.8213\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214708112.0000 - mae: 12659.4404 - val_loss: 195480048.0000 - val_mae: 12421.4150\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214697424.0000 - mae: 12659.0254 - val_loss: 195469376.0000 - val_mae: 12420.9805\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214687424.0000 - mae: 12658.6123 - val_loss: 195459632.0000 - val_mae: 12420.5957\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214677152.0000 - mae: 12658.2100 - val_loss: 195449472.0000 - val_mae: 12420.1865\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214666480.0000 - mae: 12657.8037 - val_loss: 195439216.0000 - val_mae: 12419.7695\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214656016.0000 - mae: 12657.3965 - val_loss: 195428832.0000 - val_mae: 12419.3525\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214645760.0000 - mae: 12656.9824 - val_loss: 195418816.0000 - val_mae: 12418.9473\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214635488.0000 - mae: 12656.5781 - val_loss: 195408640.0000 - val_mae: 12418.5410\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214625120.0000 - mae: 12656.1602 - val_loss: 195398544.0000 - val_mae: 12418.1338\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214615104.0000 - mae: 12655.7627 - val_loss: 195388400.0000 - val_mae: 12417.7266\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214604416.0000 - mae: 12655.3506 - val_loss: 195378256.0000 - val_mae: 12417.3203\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214593872.0000 - mae: 12654.9375 - val_loss: 195368048.0000 - val_mae: 12416.9082\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214583936.0000 - mae: 12654.5293 - val_loss: 195358128.0000 - val_mae: 12416.5078\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214573328.0000 - mae: 12654.1162 - val_loss: 195347696.0000 - val_mae: 12416.0918\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 214563136.0000 - mae: 12653.7080 - val_loss: 195337696.0000 - val_mae: 12415.6865\n"
     ]
    }
   ],
   "source": [
    "# for relu\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate([x[:i * num_val_samples],x[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([y[:i * num_val_samples],y[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1,validation_data=(val_data, val_targets))\n",
    "    #all_scores.append(np.mean(history.history['val_mae']))\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    all_scores.append(np.mean(mae_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12595.810735677083"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no need to change activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    from keras import regularizers\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, kernel_regularizer=regularizers.l2(0.02), activation='relu',input_shape=(train_data.shape[1],)))\n",
    "    #model.add(layers.Dense(10, kernel_regularizer=regularizers.l2(0.001), activation='relu')) #6491\n",
    "    #model.add(layers.Dense(8, kernel_regularizer=regularizers.l2(0.001), activation='relu')) #7963.930517578125\n",
    "    model.add(layers.Dense(6 ,kernel_regularizer=regularizers.l2(0.02), activation='relu'))#7635\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 234444144.0000 - mae: 13374.1221 - val_loss: 175722640.0000 - val_mae: 11850.4951\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 213743152.0000 - mae: 12589.3936 - val_loss: 154136736.0000 - val_mae: 10940.5244\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 188757552.0000 - mae: 11589.1309 - val_loss: 132244616.0000 - val_mae: 9918.9492\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 161668912.0000 - mae: 10402.2354 - val_loss: 106612392.0000 - val_mae: 8556.2744\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 127840000.0000 - mae: 8780.5537 - val_loss: 76769456.0000 - val_mae: 6649.4692\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 97670544.0000 - mae: 6872.0918 - val_loss: 51630080.0000 - val_mae: 4844.8438\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 71889384.0000 - mae: 5378.7285 - val_loss: 35955324.0000 - val_mae: 4049.9380\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 55269248.0000 - mae: 4897.4629 - val_loss: 29951866.0000 - val_mae: 3837.4751\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 49707428.0000 - mae: 4755.8652 - val_loss: 28795392.0000 - val_mae: 3883.5208\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 48091132.0000 - mae: 4912.6318 - val_loss: 28748288.0000 - val_mae: 3965.3171\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 47326272.0000 - mae: 4952.7070 - val_loss: 28760634.0000 - val_mae: 4008.5464\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 46767656.0000 - mae: 5003.0679 - val_loss: 28540264.0000 - val_mae: 3999.7817\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45969572.0000 - mae: 4971.5181 - val_loss: 27986398.0000 - val_mae: 3892.9453\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 46296800.0000 - mae: 4919.0439 - val_loss: 28023848.0000 - val_mae: 3954.7532\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45781456.0000 - mae: 4955.9634 - val_loss: 27839228.0000 - val_mae: 3956.1348\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45429864.0000 - mae: 4919.3257 - val_loss: 27504546.0000 - val_mae: 3914.0647\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45162488.0000 - mae: 4889.9971 - val_loss: 27065648.0000 - val_mae: 3840.0366\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44968616.0000 - mae: 4829.3076 - val_loss: 27082524.0000 - val_mae: 3900.2671\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44277244.0000 - mae: 4854.5879 - val_loss: 26567306.0000 - val_mae: 3795.1785\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44888440.0000 - mae: 4733.1450 - val_loss: 26334156.0000 - val_mae: 3773.3252\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44003644.0000 - mae: 4778.8281 - val_loss: 26200746.0000 - val_mae: 3806.3066\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43582472.0000 - mae: 4756.3169 - val_loss: 26021634.0000 - val_mae: 3817.1445\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43027264.0000 - mae: 4788.2959 - val_loss: 25788658.0000 - val_mae: 3812.5203\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42505932.0000 - mae: 4775.5361 - val_loss: 25400056.0000 - val_mae: 3768.7866\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42523672.0000 - mae: 4638.0547 - val_loss: 25204644.0000 - val_mae: 3778.6155\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 41470636.0000 - mae: 4763.2427 - val_loss: 24730370.0000 - val_mae: 3702.3335\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 41629968.0000 - mae: 4636.0352 - val_loss: 24561590.0000 - val_mae: 3721.4148\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40852004.0000 - mae: 4649.0991 - val_loss: 24174320.0000 - val_mae: 3678.6165\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40390372.0000 - mae: 4661.6157 - val_loss: 23765274.0000 - val_mae: 3637.3674\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40385924.0000 - mae: 4456.8633 - val_loss: 23613762.0000 - val_mae: 3668.4343\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39696828.0000 - mae: 4502.3706 - val_loss: 23313630.0000 - val_mae: 3655.2068\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39103352.0000 - mae: 4493.2861 - val_loss: 22788972.0000 - val_mae: 3588.2454\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39441404.0000 - mae: 4365.6602 - val_loss: 22253122.0000 - val_mae: 3499.7053\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 38100900.0000 - mae: 4388.4697 - val_loss: 22323914.0000 - val_mae: 3597.7058\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 37028960.0000 - mae: 4447.2314 - val_loss: 21655526.0000 - val_mae: 3514.0256\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 36596356.0000 - mae: 4383.4136 - val_loss: 21167680.0000 - val_mae: 3467.7329\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 36193724.0000 - mae: 4339.7554 - val_loss: 20692824.0000 - val_mae: 3423.1931\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 35469592.0000 - mae: 4288.5796 - val_loss: 20115252.0000 - val_mae: 3341.5247\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 34944888.0000 - mae: 4222.9209 - val_loss: 19626908.0000 - val_mae: 3289.6826\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 34177384.0000 - mae: 4186.9766 - val_loss: 19123542.0000 - val_mae: 3228.9316\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 33397738.0000 - mae: 4063.6963 - val_loss: 19370680.0000 - val_mae: 3396.2263\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 33012528.0000 - mae: 4081.3694 - val_loss: 18700352.0000 - val_mae: 3320.3633\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32059998.0000 - mae: 4036.6641 - val_loss: 18686904.0000 - val_mae: 3379.9775\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 31313456.0000 - mae: 4046.5911 - val_loss: 18014702.0000 - val_mae: 3306.1621\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 30997612.0000 - mae: 3903.9941 - val_loss: 17286948.0000 - val_mae: 3214.3462\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29636190.0000 - mae: 3898.5911 - val_loss: 16162697.0000 - val_mae: 2976.1943\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29636744.0000 - mae: 3661.2598 - val_loss: 16750889.0000 - val_mae: 3248.9929\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28472496.0000 - mae: 3712.0295 - val_loss: 16354671.0000 - val_mae: 3240.8013\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27058292.0000 - mae: 3700.1084 - val_loss: 15632294.0000 - val_mae: 3155.2444\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 26973064.0000 - mae: 3648.9434 - val_loss: 14674819.0000 - val_mae: 2995.6675\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 26217032.0000 - mae: 3527.1370 - val_loss: 14188845.0000 - val_mae: 2961.0667\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 25493152.0000 - mae: 3463.0161 - val_loss: 13743836.0000 - val_mae: 2934.4326\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 24795372.0000 - mae: 3320.6350 - val_loss: 14895032.0000 - val_mae: 3243.6108\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 23984694.0000 - mae: 3528.3103 - val_loss: 12803853.0000 - val_mae: 2835.9983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 22974890.0000 - mae: 3361.2983 - val_loss: 11744493.0000 - val_mae: 2402.9307\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 23518926.0000 - mae: 3102.5859 - val_loss: 12119047.0000 - val_mae: 2789.1802\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 22075306.0000 - mae: 3143.6067 - val_loss: 12734497.0000 - val_mae: 2993.4365\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 21365270.0000 - mae: 3252.7043 - val_loss: 11434854.0000 - val_mae: 2745.0811\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20860498.0000 - mae: 3154.5156 - val_loss: 10921104.0000 - val_mae: 2666.7520\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20055380.0000 - mae: 3130.0947 - val_loss: 10156816.0000 - val_mae: 2479.5645\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 19587318.0000 - mae: 3056.3870 - val_loss: 9716997.0000 - val_mae: 2395.6982\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18818620.0000 - mae: 2914.1592 - val_loss: 11084283.0000 - val_mae: 2813.0996\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18546260.0000 - mae: 2983.2544 - val_loss: 10369329.0000 - val_mae: 2687.5232\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 17859072.0000 - mae: 2840.3691 - val_loss: 11851477.0000 - val_mae: 2988.9355\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 17533200.0000 - mae: 2987.2034 - val_loss: 9372705.0000 - val_mae: 2499.2275\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16860100.0000 - mae: 2808.2969 - val_loss: 8358647.5000 - val_mae: 2219.9817\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16673376.0000 - mae: 2747.9116 - val_loss: 9647336.0000 - val_mae: 2592.8403\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16235384.0000 - mae: 2831.5903 - val_loss: 8376419.0000 - val_mae: 2289.7280\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16073728.0000 - mae: 2675.2041 - val_loss: 10039659.0000 - val_mae: 2669.0667\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15452280.0000 - mae: 2798.1111 - val_loss: 7873640.5000 - val_mae: 2160.3362\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15149944.0000 - mae: 2600.8169 - val_loss: 9392434.0000 - val_mae: 2554.8569\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14508632.0000 - mae: 2640.3447 - val_loss: 7451767.0000 - val_mae: 2042.1013\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14950468.0000 - mae: 2602.9868 - val_loss: 7334408.0000 - val_mae: 2010.6625\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14800056.0000 - mae: 2575.8994 - val_loss: 7373495.0000 - val_mae: 2043.3936\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14572383.0000 - mae: 2542.4082 - val_loss: 7946408.5000 - val_mae: 2232.8252\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13841553.0000 - mae: 2547.5410 - val_loss: 7154660.0000 - val_mae: 1977.9437\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14224592.0000 - mae: 2559.1792 - val_loss: 7789487.0000 - val_mae: 2194.9070\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13636715.0000 - mae: 2506.4695 - val_loss: 9213953.0000 - val_mae: 2483.3821\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13989551.0000 - mae: 2541.3506 - val_loss: 8504176.0000 - val_mae: 2345.6040\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13943167.0000 - mae: 2481.4712 - val_loss: 8060919.5000 - val_mae: 2256.4819\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13674473.0000 - mae: 2518.7207 - val_loss: 8504116.0000 - val_mae: 2341.4241\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13354675.0000 - mae: 2547.9155 - val_loss: 7850306.5000 - val_mae: 2204.1167\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13283423.0000 - mae: 2457.1250 - val_loss: 10300909.0000 - val_mae: 2602.0383\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13349246.0000 - mae: 2517.7395 - val_loss: 7969688.5000 - val_mae: 2219.0977\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13070459.0000 - mae: 2478.8850 - val_loss: 6964013.5000 - val_mae: 1974.3578\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13203096.0000 - mae: 2340.9685 - val_loss: 9650440.0000 - val_mae: 2489.4719\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13043272.0000 - mae: 2515.7107 - val_loss: 7772297.0000 - val_mae: 2158.0059\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12499192.0000 - mae: 2385.6624 - val_loss: 8462652.0000 - val_mae: 2292.3098\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13069925.0000 - mae: 2457.4519 - val_loss: 9090638.0000 - val_mae: 2390.4614\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13117994.0000 - mae: 2394.5173 - val_loss: 8432688.0000 - val_mae: 2292.6343\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12874112.0000 - mae: 2391.9246 - val_loss: 8359391.0000 - val_mae: 2282.3118\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12927604.0000 - mae: 2411.7546 - val_loss: 8454173.0000 - val_mae: 2288.4148\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12441147.0000 - mae: 2369.0747 - val_loss: 10992948.0000 - val_mae: 2662.9004\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11959149.0000 - mae: 2412.4336 - val_loss: 7586920.5000 - val_mae: 2094.1904\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13195029.0000 - mae: 2403.9333 - val_loss: 7386678.5000 - val_mae: 2059.7195\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12752868.0000 - mae: 2400.8403 - val_loss: 7818726.5000 - val_mae: 2139.1318\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12409334.0000 - mae: 2417.3926 - val_loss: 8665440.0000 - val_mae: 2290.4006\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12366987.0000 - mae: 2414.5200 - val_loss: 9572911.0000 - val_mae: 2426.8477\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12505269.0000 - mae: 2428.2969 - val_loss: 8054763.5000 - val_mae: 2165.0166\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12680758.0000 - mae: 2352.9814 - val_loss: 9589091.0000 - val_mae: 2421.1733\n",
      "processing fold # 1\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 194499968.0000 - mae: 12502.5264 - val_loss: 252617488.0000 - val_mae: 13488.6426\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 176208560.0000 - mae: 11735.0654 - val_loss: 231769616.0000 - val_mae: 12731.1143\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 153838112.0000 - mae: 10803.4609 - val_loss: 202082880.0000 - val_mae: 11594.5312\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 125382568.0000 - mae: 9343.8721 - val_loss: 156300256.0000 - val_mae: 9581.4688\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 84954152.0000 - mae: 7027.7065 - val_loss: 110818968.0000 - val_mae: 7133.1099\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 54164492.0000 - mae: 4858.2114 - val_loss: 79159536.0000 - val_mae: 5666.5776\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 37685200.0000 - mae: 3927.1411 - val_loss: 64960052.0000 - val_mae: 5145.7910\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32316642.0000 - mae: 3808.4785 - val_loss: 59496352.0000 - val_mae: 5070.4917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 30518578.0000 - mae: 3867.6870 - val_loss: 57791328.0000 - val_mae: 5079.1167\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29738930.0000 - mae: 3913.1880 - val_loss: 57359948.0000 - val_mae: 5073.3359\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29790080.0000 - mae: 3833.7100 - val_loss: 56692100.0000 - val_mae: 5056.7422\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29501402.0000 - mae: 3841.2717 - val_loss: 56046944.0000 - val_mae: 5054.8042\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29028152.0000 - mae: 3873.9021 - val_loss: 55087756.0000 - val_mae: 5068.0742\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28862542.0000 - mae: 3815.0645 - val_loss: 55411316.0000 - val_mae: 5029.8789\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28820618.0000 - mae: 3785.6167 - val_loss: 54482784.0000 - val_mae: 5042.8472\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28612864.0000 - mae: 3750.8857 - val_loss: 54426380.0000 - val_mae: 5022.3198\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28416124.0000 - mae: 3779.1072 - val_loss: 54314928.0000 - val_mae: 4998.9502\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28105074.0000 - mae: 3771.4321 - val_loss: 52820808.0000 - val_mae: 5032.9336\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27712560.0000 - mae: 3720.2703 - val_loss: 51917476.0000 - val_mae: 5046.1108\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 27610388.0000 - mae: 3748.1833 - val_loss: 51388768.0000 - val_mae: 5036.7529\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27263714.0000 - mae: 3777.6755 - val_loss: 52129300.0000 - val_mae: 4970.3843\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27135994.0000 - mae: 3716.1245 - val_loss: 52787688.0000 - val_mae: 4913.2686\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27029454.0000 - mae: 3691.7742 - val_loss: 51769104.0000 - val_mae: 4923.7095\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 26949178.0000 - mae: 3623.3003 - val_loss: 51546016.0000 - val_mae: 4903.8525\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 26157752.0000 - mae: 3681.6699 - val_loss: 52179192.0000 - val_mae: 4848.4736\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 26508294.0000 - mae: 3610.4292 - val_loss: 50744376.0000 - val_mae: 4868.4780\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 25988144.0000 - mae: 3647.7209 - val_loss: 50781908.0000 - val_mae: 4834.4258\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 25809422.0000 - mae: 3531.3132 - val_loss: 48677344.0000 - val_mae: 4892.1289\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 25367250.0000 - mae: 3642.1973 - val_loss: 48997880.0000 - val_mae: 4826.8384\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 24985008.0000 - mae: 3585.9829 - val_loss: 49328684.0000 - val_mae: 4765.0195\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 25286050.0000 - mae: 3427.4094 - val_loss: 47895804.0000 - val_mae: 4790.9551\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 24505974.0000 - mae: 3521.0039 - val_loss: 47313968.0000 - val_mae: 4774.1572\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 24023358.0000 - mae: 3471.4473 - val_loss: 48578584.0000 - val_mae: 4670.1406\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 23957546.0000 - mae: 3432.0474 - val_loss: 46996880.0000 - val_mae: 4687.9126\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 24387602.0000 - mae: 3308.6108 - val_loss: 46928368.0000 - val_mae: 4645.9688\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 23196714.0000 - mae: 3351.8965 - val_loss: 47551024.0000 - val_mae: 4578.0776\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 22001406.0000 - mae: 3338.2710 - val_loss: 50896352.0000 - val_mae: 4505.4287\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 22591986.0000 - mae: 3269.6162 - val_loss: 43961840.0000 - val_mae: 4613.5884\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 22234544.0000 - mae: 3349.8892 - val_loss: 43600832.0000 - val_mae: 4577.3218\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 21241510.0000 - mae: 3239.5935 - val_loss: 46616816.0000 - val_mae: 4398.0000\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 21592908.0000 - mae: 3185.4780 - val_loss: 42708792.0000 - val_mae: 4481.3975\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20734828.0000 - mae: 3294.7144 - val_loss: 43444824.0000 - val_mae: 4383.3716\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20808026.0000 - mae: 3173.0242 - val_loss: 42910856.0000 - val_mae: 4341.4619\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20198648.0000 - mae: 3146.1653 - val_loss: 41943160.0000 - val_mae: 4302.4238\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 19983036.0000 - mae: 3064.3892 - val_loss: 40159112.0000 - val_mae: 4314.3906\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 19598532.0000 - mae: 3021.3408 - val_loss: 40189008.0000 - val_mae: 4239.2539\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 19117368.0000 - mae: 2976.4661 - val_loss: 38571040.0000 - val_mae: 4229.6641\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18636332.0000 - mae: 2948.3848 - val_loss: 38459284.0000 - val_mae: 4148.9746\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18123526.0000 - mae: 2959.0815 - val_loss: 38307360.0000 - val_mae: 4078.8657\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 17697800.0000 - mae: 2865.0596 - val_loss: 36461808.0000 - val_mae: 4082.3271\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 17441760.0000 - mae: 2767.8857 - val_loss: 36447716.0000 - val_mae: 4002.5208\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16595704.0000 - mae: 2788.2986 - val_loss: 36816740.0000 - val_mae: 3883.0510\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16443727.0000 - mae: 2659.0413 - val_loss: 33583076.0000 - val_mae: 3982.0840\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15743224.0000 - mae: 2757.5613 - val_loss: 35103992.0000 - val_mae: 3784.1621\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15632275.0000 - mae: 2633.0811 - val_loss: 32453880.0000 - val_mae: 3859.8010\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15443704.0000 - mae: 2640.5847 - val_loss: 32717304.0000 - val_mae: 3743.8257\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14550516.0000 - mae: 2577.5642 - val_loss: 31184804.0000 - val_mae: 3757.0308\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14257160.0000 - mae: 2565.3223 - val_loss: 33656460.0000 - val_mae: 3546.9763\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13916082.0000 - mae: 2561.6719 - val_loss: 31098142.0000 - val_mae: 3545.1348\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13746628.0000 - mae: 2474.7947 - val_loss: 30120252.0000 - val_mae: 3521.1187\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12971270.0000 - mae: 2488.4971 - val_loss: 31668202.0000 - val_mae: 3390.0237\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13349567.0000 - mae: 2434.2498 - val_loss: 28068474.0000 - val_mae: 3517.1387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12764196.0000 - mae: 2416.6165 - val_loss: 27398272.0000 - val_mae: 3514.6589\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12449685.0000 - mae: 2386.8721 - val_loss: 27860282.0000 - val_mae: 3350.3855\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12166216.0000 - mae: 2390.9346 - val_loss: 30980250.0000 - val_mae: 3239.2117\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12361429.0000 - mae: 2270.9326 - val_loss: 25854496.0000 - val_mae: 3433.3162\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 11905068.0000 - mae: 2446.7947 - val_loss: 28718430.0000 - val_mae: 3171.5393\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 11925138.0000 - mae: 2259.7927 - val_loss: 25510248.0000 - val_mae: 3289.1475\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11561976.0000 - mae: 2268.9844 - val_loss: 24651216.0000 - val_mae: 3349.6892\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11155798.0000 - mae: 2421.7051 - val_loss: 26363758.0000 - val_mae: 3121.0105\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11111259.0000 - mae: 2356.2356 - val_loss: 24888406.0000 - val_mae: 3145.2261\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11286793.0000 - mae: 2282.2285 - val_loss: 25334196.0000 - val_mae: 3081.9534\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11237757.0000 - mae: 2281.8806 - val_loss: 24480124.0000 - val_mae: 3084.8396\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10793963.0000 - mae: 2194.3345 - val_loss: 24375536.0000 - val_mae: 3066.2593\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10018842.0000 - mae: 2235.9995 - val_loss: 29279260.0000 - val_mae: 3149.3164\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11103264.0000 - mae: 2191.8870 - val_loss: 23099410.0000 - val_mae: 3074.1536\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10575257.0000 - mae: 2209.9062 - val_loss: 22362556.0000 - val_mae: 3130.6733\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10645779.0000 - mae: 2273.4956 - val_loss: 23066396.0000 - val_mae: 3009.5176\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10415051.0000 - mae: 2234.6326 - val_loss: 23088476.0000 - val_mae: 2978.3379\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10454155.0000 - mae: 2251.3406 - val_loss: 24827800.0000 - val_mae: 2921.6357\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10509796.0000 - mae: 2175.7520 - val_loss: 23011690.0000 - val_mae: 2937.2786\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10070741.0000 - mae: 2255.5972 - val_loss: 22299136.0000 - val_mae: 2933.4836\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10226592.0000 - mae: 2218.9109 - val_loss: 22927170.0000 - val_mae: 2906.5835\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9940097.0000 - mae: 2109.4644 - val_loss: 27817842.0000 - val_mae: 3101.7266\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10001145.0000 - mae: 2120.8770 - val_loss: 25193670.0000 - val_mae: 2903.6162\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10128629.0000 - mae: 2193.8191 - val_loss: 23670664.0000 - val_mae: 2869.7756\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10133718.0000 - mae: 2242.1279 - val_loss: 21647734.0000 - val_mae: 2880.5630\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9840421.0000 - mae: 2155.7583 - val_loss: 22987050.0000 - val_mae: 2849.1287\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9935035.0000 - mae: 2223.8452 - val_loss: 21351040.0000 - val_mae: 2861.6392\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9884586.0000 - mae: 2152.8259 - val_loss: 23050440.0000 - val_mae: 2835.2217\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10034313.0000 - mae: 2131.2373 - val_loss: 20564472.0000 - val_mae: 2877.2178\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9779544.0000 - mae: 2130.3059 - val_loss: 20065790.0000 - val_mae: 2887.0610\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9887484.0000 - mae: 2189.8320 - val_loss: 20214710.0000 - val_mae: 2836.3196\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9706360.0000 - mae: 2179.6553 - val_loss: 20671392.0000 - val_mae: 2802.9248\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9563521.0000 - mae: 2223.7356 - val_loss: 21652540.0000 - val_mae: 2783.2539\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9682732.0000 - mae: 2196.2910 - val_loss: 20109778.0000 - val_mae: 2776.5161\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9379696.0000 - mae: 2218.0439 - val_loss: 21478034.0000 - val_mae: 2766.5479\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9126408.0000 - mae: 2173.4084 - val_loss: 18886726.0000 - val_mae: 2850.8088\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9184434.0000 - mae: 2171.6489 - val_loss: 19039284.0000 - val_mae: 2800.1042\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9423502.0000 - mae: 2174.3171 - val_loss: 19737240.0000 - val_mae: 2738.1809\n",
      "processing fold # 2\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 219875952.0000 - mae: 12884.7959 - val_loss: 197648384.0000 - val_mae: 12517.8877\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 213978448.0000 - mae: 12635.4717 - val_loss: 187167904.0000 - val_mae: 12093.4541\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 195805440.0000 - mae: 11908.4756 - val_loss: 167136544.0000 - val_mae: 11224.7441\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 175741344.0000 - mae: 11014.8760 - val_loss: 146462448.0000 - val_mae: 10266.8760\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 152490880.0000 - mae: 9964.6670 - val_loss: 123163496.0000 - val_mae: 9065.0049\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 126628744.0000 - mae: 8597.7227 - val_loss: 98238816.0000 - val_mae: 7573.0552\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 100474304.0000 - mae: 7027.5830 - val_loss: 74427312.0000 - val_mae: 5872.9785\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 79410904.0000 - mae: 5817.3779 - val_loss: 56906904.0000 - val_mae: 4669.7441\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 60788268.0000 - mae: 5131.3052 - val_loss: 44978716.0000 - val_mae: 4368.3584\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 52529544.0000 - mae: 4748.8550 - val_loss: 40666444.0000 - val_mae: 4421.5747\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 49770396.0000 - mae: 4699.1128 - val_loss: 39194216.0000 - val_mae: 4507.3828\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 48146060.0000 - mae: 4764.9038 - val_loss: 38527880.0000 - val_mae: 4599.7632\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 47426040.0000 - mae: 4774.4062 - val_loss: 38195244.0000 - val_mae: 4620.5005\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 47166328.0000 - mae: 4788.8062 - val_loss: 37970772.0000 - val_mae: 4585.4219\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 46629732.0000 - mae: 4817.1704 - val_loss: 37720944.0000 - val_mae: 4582.9883\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 46312544.0000 - mae: 4762.8984 - val_loss: 37534240.0000 - val_mae: 4619.2432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 46324076.0000 - mae: 4790.1694 - val_loss: 37322452.0000 - val_mae: 4587.2959\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45833092.0000 - mae: 4821.6392 - val_loss: 37123740.0000 - val_mae: 4535.5991\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45818376.0000 - mae: 4789.4731 - val_loss: 36946044.0000 - val_mae: 4513.1875\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45478988.0000 - mae: 4766.2363 - val_loss: 36742120.0000 - val_mae: 4482.0161\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45487372.0000 - mae: 4731.6250 - val_loss: 36511832.0000 - val_mae: 4498.1030\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45094504.0000 - mae: 4732.6094 - val_loss: 36290036.0000 - val_mae: 4494.6436\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44909812.0000 - mae: 4708.0742 - val_loss: 36067232.0000 - val_mae: 4476.7075\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44370800.0000 - mae: 4750.9199 - val_loss: 35885776.0000 - val_mae: 4413.6284\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44624736.0000 - mae: 4649.3145 - val_loss: 35662900.0000 - val_mae: 4408.5952\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44138024.0000 - mae: 4707.0718 - val_loss: 35498836.0000 - val_mae: 4360.3813\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44143296.0000 - mae: 4603.3926 - val_loss: 35200240.0000 - val_mae: 4406.2783\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43312700.0000 - mae: 4702.3091 - val_loss: 35128556.0000 - val_mae: 4301.9731\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43671544.0000 - mae: 4615.9268 - val_loss: 34770760.0000 - val_mae: 4351.5752\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43289024.0000 - mae: 4622.7695 - val_loss: 34502072.0000 - val_mae: 4375.1963\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42386128.0000 - mae: 4570.9312 - val_loss: 34426808.0000 - val_mae: 4494.8906\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43034500.0000 - mae: 4598.8979 - val_loss: 34029984.0000 - val_mae: 4356.9219\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42343912.0000 - mae: 4609.9097 - val_loss: 33851436.0000 - val_mae: 4264.8472\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42685136.0000 - mae: 4504.5811 - val_loss: 33556452.0000 - val_mae: 4276.6211\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42123492.0000 - mae: 4500.8467 - val_loss: 33249408.0000 - val_mae: 4336.6655\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 41267772.0000 - mae: 4627.3135 - val_loss: 32922944.0000 - val_mae: 4308.9648\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40458720.0000 - mae: 4593.8804 - val_loss: 32853372.0000 - val_mae: 4098.6206\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 41339732.0000 - mae: 4454.6562 - val_loss: 32266966.0000 - val_mae: 4164.3442\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40749196.0000 - mae: 4440.4360 - val_loss: 31948400.0000 - val_mae: 4216.7886\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40092944.0000 - mae: 4503.5078 - val_loss: 31657770.0000 - val_mae: 4089.0762\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39606836.0000 - mae: 4481.2720 - val_loss: 31514420.0000 - val_mae: 3991.3345\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39727324.0000 - mae: 4332.0571 - val_loss: 30826762.0000 - val_mae: 4151.8530\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 38780000.0000 - mae: 4430.6470 - val_loss: 30428570.0000 - val_mae: 4043.8364\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39363020.0000 - mae: 4284.7158 - val_loss: 30078444.0000 - val_mae: 4071.8271\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 38071348.0000 - mae: 4404.7075 - val_loss: 29670038.0000 - val_mae: 4000.4871\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 37348120.0000 - mae: 4339.0156 - val_loss: 29423140.0000 - val_mae: 3863.2166\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 37537944.0000 - mae: 4197.9194 - val_loss: 28935168.0000 - val_mae: 4050.4084\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 37110324.0000 - mae: 4277.6558 - val_loss: 28387176.0000 - val_mae: 3922.0823\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 35940932.0000 - mae: 4266.0156 - val_loss: 28207912.0000 - val_mae: 3730.3308\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 36160280.0000 - mae: 4163.0308 - val_loss: 27396820.0000 - val_mae: 3796.8123\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 35131376.0000 - mae: 4194.2461 - val_loss: 26895976.0000 - val_mae: 3720.1509\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 34703528.0000 - mae: 4148.6294 - val_loss: 26375636.0000 - val_mae: 3651.6711\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 33926708.0000 - mae: 4116.5430 - val_loss: 25865040.0000 - val_mae: 3580.1960\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 33409616.0000 - mae: 4071.0381 - val_loss: 25129292.0000 - val_mae: 3548.1089\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32792260.0000 - mae: 3940.8521 - val_loss: 24480880.0000 - val_mae: 3514.0840\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32144742.0000 - mae: 3918.4131 - val_loss: 23958916.0000 - val_mae: 3444.8928\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 31361960.0000 - mae: 3758.8413 - val_loss: 23896952.0000 - val_mae: 3294.1216\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 30687306.0000 - mae: 3863.8640 - val_loss: 23225322.0000 - val_mae: 3245.0488\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29939774.0000 - mae: 3798.6606 - val_loss: 21982186.0000 - val_mae: 3303.7988\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29188812.0000 - mae: 3744.2651 - val_loss: 21420798.0000 - val_mae: 3211.5491\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28295856.0000 - mae: 3650.2686 - val_loss: 21297416.0000 - val_mae: 3076.6333\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27786892.0000 - mae: 3566.5010 - val_loss: 20023422.0000 - val_mae: 3146.1030\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 26589280.0000 - mae: 3686.3218 - val_loss: 19609952.0000 - val_mae: 2990.2124\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 26113350.0000 - mae: 3526.4624 - val_loss: 18711376.0000 - val_mae: 3001.5525\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 25401386.0000 - mae: 3473.9485 - val_loss: 18335444.0000 - val_mae: 2855.5471\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 24071244.0000 - mae: 3256.9233 - val_loss: 17637706.0000 - val_mae: 3055.8657\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 23829764.0000 - mae: 3387.2717 - val_loss: 16763313.0000 - val_mae: 2810.7830\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 22783594.0000 - mae: 3224.9944 - val_loss: 16329976.0000 - val_mae: 2711.5767\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 21992272.0000 - mae: 3198.2090 - val_loss: 16097165.0000 - val_mae: 2620.4551\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 21699056.0000 - mae: 3183.0884 - val_loss: 15181801.0000 - val_mae: 2633.9395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 21061402.0000 - mae: 3000.5771 - val_loss: 14616909.0000 - val_mae: 2722.6882\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 19977566.0000 - mae: 3027.8240 - val_loss: 14077518.0000 - val_mae: 2667.7725\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20076904.0000 - mae: 2963.4104 - val_loss: 14251156.0000 - val_mae: 2437.5264\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 19373900.0000 - mae: 2881.2532 - val_loss: 13511814.0000 - val_mae: 2448.6797\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18408226.0000 - mae: 2829.8132 - val_loss: 13058138.0000 - val_mae: 2443.8879\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 17877800.0000 - mae: 2885.6311 - val_loss: 12515280.0000 - val_mae: 2438.3188\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 17472192.0000 - mae: 2746.7522 - val_loss: 12102262.0000 - val_mae: 2472.4526\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16694155.0000 - mae: 2847.2153 - val_loss: 11995030.0000 - val_mae: 2336.4556\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16498056.0000 - mae: 2698.1216 - val_loss: 11969882.0000 - val_mae: 2286.5310\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15949845.0000 - mae: 2586.1404 - val_loss: 11253893.0000 - val_mae: 2354.6968\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15349639.0000 - mae: 2624.0723 - val_loss: 12370643.0000 - val_mae: 2291.8704\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15538218.0000 - mae: 2477.0149 - val_loss: 10942388.0000 - val_mae: 2472.0344\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15432577.0000 - mae: 2573.3801 - val_loss: 10664449.0000 - val_mae: 2297.0837\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14544577.0000 - mae: 2559.8403 - val_loss: 11159864.0000 - val_mae: 2267.6152\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14418768.0000 - mae: 2503.1335 - val_loss: 10444831.0000 - val_mae: 2398.3025\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14277991.0000 - mae: 2530.6675 - val_loss: 10255061.0000 - val_mae: 2312.4941\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13745510.0000 - mae: 2491.5974 - val_loss: 10340126.0000 - val_mae: 2247.4053\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13833783.0000 - mae: 2468.5161 - val_loss: 10204658.0000 - val_mae: 2252.2568\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13597140.0000 - mae: 2406.5830 - val_loss: 10067654.0000 - val_mae: 2341.7729\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13113788.0000 - mae: 2515.2246 - val_loss: 11527284.0000 - val_mae: 2432.5510\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13421744.0000 - mae: 2429.1616 - val_loss: 10005947.0000 - val_mae: 2357.6270\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12797088.0000 - mae: 2452.7898 - val_loss: 10068412.0000 - val_mae: 2287.8906\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12762578.0000 - mae: 2435.8379 - val_loss: 10990249.0000 - val_mae: 2420.2241\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13502809.0000 - mae: 2322.2087 - val_loss: 10451963.0000 - val_mae: 2337.4702\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 13301904.0000 - mae: 2397.6321 - val_loss: 11120428.0000 - val_mae: 2442.7058\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12988015.0000 - mae: 2306.8450 - val_loss: 9881295.0000 - val_mae: 2349.1428\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 12263922.0000 - mae: 2445.9441 - val_loss: 10005639.0000 - val_mae: 2311.3782\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12446917.0000 - mae: 2408.3381 - val_loss: 9760261.0000 - val_mae: 2310.2485\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12542114.0000 - mae: 2392.7815 - val_loss: 9708534.0000 - val_mae: 2313.2183\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12120055.0000 - mae: 2296.2119 - val_loss: 10045166.0000 - val_mae: 2339.0005\n"
     ]
    }
   ],
   "source": [
    "x = df_shuff[103:,:25].astype('float32')\n",
    "y = df_shuff[103:,25].astype('float32')\n",
    "k = 3\n",
    "num_val_samples = len(x) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate([x[:i * num_val_samples],x[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([y[:i * num_val_samples],y[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1,validation_data=(val_data, val_targets))\n",
    "    #all_scores.append(np.mean(history.history['val_mae']))\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    all_scores.append(np.mean(mae_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3830.950694580078"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no need to use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# droupout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation='relu',input_shape=(train_data.shape[1],)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # lower capacity\n",
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation='relu',input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(6, activation='relu')) #6491\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    #model.add(layers.Dense(6, activation='relu')) #7963.930517578125\n",
    "   # model.add(layers.Dense(8, activation='relu'))#7635\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/100\n",
      "40/68 [================>.............] - ETA: 0s - loss: 230667984.0000 - mae: 13365.7832WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 250506464.0000 - mae: 13862.1641 - val_loss: 188039200.0000 - val_mae: 12312.6729\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 239812048.0000 - mae: 13511.0332 - val_loss: 184491584.0000 - val_mae: 12171.2881\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 236063552.0000 - mae: 13412.8496 - val_loss: 181628832.0000 - val_mae: 12055.9141\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 234473520.0000 - mae: 13333.0459 - val_loss: 178961296.0000 - val_mae: 11946.4805\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 228593312.0000 - mae: 13100.9961 - val_loss: 177389232.0000 - val_mae: 11882.1074\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 226813680.0000 - mae: 13049.3145 - val_loss: 176292896.0000 - val_mae: 11841.3359\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 225682768.0000 - mae: 13003.9531 - val_loss: 176274768.0000 - val_mae: 11841.0420\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 226008608.0000 - mae: 13011.5742 - val_loss: 176273344.0000 - val_mae: 11840.9932\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 223898272.0000 - mae: 12934.1006 - val_loss: 176271968.0000 - val_mae: 11840.9365\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 221770544.0000 - mae: 12842.0957 - val_loss: 175948992.0000 - val_mae: 11827.8525\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 222289072.0000 - mae: 12875.8086 - val_loss: 172257792.0000 - val_mae: 11674.7314\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 217188608.0000 - mae: 12650.8564 - val_loss: 168993664.0000 - val_mae: 11537.8398\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 213467936.0000 - mae: 12558.1182 - val_loss: 165848624.0000 - val_mae: 11405.1611\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 216237200.0000 - mae: 12568.9951 - val_loss: 163213552.0000 - val_mae: 11291.5908\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 203745120.0000 - mae: 12312.1758 - val_loss: 160374160.0000 - val_mae: 11167.9990\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 212698176.0000 - mae: 12386.9766 - val_loss: 158139808.0000 - val_mae: 11069.6699\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 203990480.0000 - mae: 11856.1299 - val_loss: 153790048.0000 - val_mae: 10876.0088\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 196037072.0000 - mae: 11538.9766 - val_loss: 149526192.0000 - val_mae: 10682.8662\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 204005968.0000 - mae: 11522.2168 - val_loss: 145180608.0000 - val_mae: 10482.3047\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 179891824.0000 - mae: 11011.4746 - val_loss: 140156672.0000 - val_mae: 10245.9102\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 190120128.0000 - mae: 11071.2324 - val_loss: 136586368.0000 - val_mae: 10074.5566\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 182238592.0000 - mae: 10506.5518 - val_loss: 133062592.0000 - val_mae: 9902.7266\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 192424032.0000 - mae: 11132.4414 - val_loss: 130701088.0000 - val_mae: 9786.0771\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 167181968.0000 - mae: 10436.2471 - val_loss: 127673584.0000 - val_mae: 9634.5859\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 179456368.0000 - mae: 10644.7090 - val_loss: 125392376.0000 - val_mae: 9518.8174\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 192200272.0000 - mae: 11424.6768 - val_loss: 125554408.0000 - val_mae: 9527.2764\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 181806368.0000 - mae: 10413.1904 - val_loss: 123552864.0000 - val_mae: 9424.9697\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 183042560.0000 - mae: 10654.1953 - val_loss: 124431088.0000 - val_mae: 9470.4268\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 169205760.0000 - mae: 10925.5117 - val_loss: 122045008.0000 - val_mae: 9347.3047\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 163568016.0000 - mae: 10281.7393 - val_loss: 117236720.0000 - val_mae: 9094.2461\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 166231168.0000 - mae: 10370.4072 - val_loss: 115305504.0000 - val_mae: 8990.6865\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 163401296.0000 - mae: 10452.1123 - val_loss: 116629568.0000 - val_mae: 9062.3760\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 158232912.0000 - mae: 9502.3086 - val_loss: 116976344.0000 - val_mae: 9077.2734\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 180412224.0000 - mae: 11010.1084 - val_loss: 114866504.0000 - val_mae: 8958.4355\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 158710096.0000 - mae: 9883.2578 - val_loss: 113733312.0000 - val_mae: 8897.1807\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 189274960.0000 - mae: 10777.8750 - val_loss: 111950624.0000 - val_mae: 8798.8594\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 139272368.0000 - mae: 9746.3340 - val_loss: 108142032.0000 - val_mae: 8585.8633\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 177073264.0000 - mae: 10448.2910 - val_loss: 108809288.0000 - val_mae: 8623.5938\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 171742352.0000 - mae: 10384.5840 - val_loss: 105335720.0000 - val_mae: 8425.9629\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 168823120.0000 - mae: 10041.7441 - val_loss: 103247520.0000 - val_mae: 8305.2080\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 158437408.0000 - mae: 9565.5254 - val_loss: 101295016.0000 - val_mae: 8192.0771\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 166222512.0000 - mae: 10098.7334 - val_loss: 99321384.0000 - val_mae: 8077.3511\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 136857600.0000 - mae: 8850.6465 - val_loss: 95104032.0000 - val_mae: 7828.7842\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 152739872.0000 - mae: 9645.6914 - val_loss: 94759472.0000 - val_mae: 7804.2905\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 162724624.0000 - mae: 10323.5732 - val_loss: 94926104.0000 - val_mae: 7810.6377\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 146596288.0000 - mae: 9543.2939 - val_loss: 93024936.0000 - val_mae: 7697.2334\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 162030416.0000 - mae: 9350.7666 - val_loss: 94326624.0000 - val_mae: 7782.9331\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 154189280.0000 - mae: 9945.6895 - val_loss: 95932816.0000 - val_mae: 7889.7939\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 174746112.0000 - mae: 9756.6904 - val_loss: 96310752.0000 - val_mae: 7926.2207\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 149850384.0000 - mae: 9290.5820 - val_loss: 93582224.0000 - val_mae: 7754.6377\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 158864768.0000 - mae: 9703.7734 - val_loss: 91580640.0000 - val_mae: 7627.2231\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 2ms/step - loss: 142381664.0000 - mae: 8921.7021 - val_loss: 93093640.0000 - val_mae: 7731.0117\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 139203296.0000 - mae: 9427.0088 - val_loss: 90779944.0000 - val_mae: 7585.4800\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 149456000.0000 - mae: 9130.5762 - val_loss: 91887976.0000 - val_mae: 7657.1367\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 153287008.0000 - mae: 9056.1709 - val_loss: 89381648.0000 - val_mae: 7501.8569\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 169746336.0000 - mae: 10508.7461 - val_loss: 89401632.0000 - val_mae: 7504.5635\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 134794784.0000 - mae: 9020.7061 - val_loss: 86952752.0000 - val_mae: 7342.3647\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 139207216.0000 - mae: 9338.1367 - val_loss: 87582920.0000 - val_mae: 7392.6729\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 155558720.0000 - mae: 9855.6494 - val_loss: 91482176.0000 - val_mae: 7659.3965\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 168678432.0000 - mae: 10266.5801 - val_loss: 92786112.0000 - val_mae: 7740.7114\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 155430736.0000 - mae: 9513.4971 - val_loss: 92607264.0000 - val_mae: 7729.1250\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 172891328.0000 - mae: 10233.7070 - val_loss: 94742896.0000 - val_mae: 7861.9927\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 166719040.0000 - mae: 9832.4873 - val_loss: 95565224.0000 - val_mae: 7910.5938\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 114693208.0000 - mae: 8567.1133 - val_loss: 93127720.0000 - val_mae: 7764.3721\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 172407584.0000 - mae: 10381.1455 - val_loss: 92875712.0000 - val_mae: 7744.5488\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 146352512.0000 - mae: 9896.9482 - val_loss: 91247096.0000 - val_mae: 7645.9438\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 139488288.0000 - mae: 9241.3145 - val_loss: 91310560.0000 - val_mae: 7653.3701\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 159364784.0000 - mae: 10193.3506 - val_loss: 91251000.0000 - val_mae: 7654.3296\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 167568528.0000 - mae: 9837.6523 - val_loss: 93716112.0000 - val_mae: 7813.4136\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 147663360.0000 - mae: 9528.7354 - val_loss: 94092752.0000 - val_mae: 7842.3604\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 112685488.0000 - mae: 8854.1875 - val_loss: 90266168.0000 - val_mae: 7606.0317\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 153848080.0000 - mae: 9810.2324 - val_loss: 94346544.0000 - val_mae: 7871.3418\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 162327264.0000 - mae: 10117.6816 - val_loss: 92722000.0000 - val_mae: 7768.1211\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 112830176.0000 - mae: 8394.1650 - val_loss: 92235272.0000 - val_mae: 7737.3564\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 152791760.0000 - mae: 9278.0791 - val_loss: 93113872.0000 - val_mae: 7796.5938\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 156642768.0000 - mae: 9341.1582 - val_loss: 96787136.0000 - val_mae: 8026.9209\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 155775872.0000 - mae: 9088.7910 - val_loss: 98960400.0000 - val_mae: 8159.9727\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 141999280.0000 - mae: 9481.1943 - val_loss: 96411472.0000 - val_mae: 8002.4043\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 156003072.0000 - mae: 9708.6914 - val_loss: 96491688.0000 - val_mae: 8011.5981\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 136871136.0000 - mae: 9487.3457 - val_loss: 91819040.0000 - val_mae: 7709.4092\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 143193008.0000 - mae: 8909.7959 - val_loss: 92668784.0000 - val_mae: 7771.8154\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 143663072.0000 - mae: 9483.1982 - val_loss: 95339248.0000 - val_mae: 7937.7729\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 141514096.0000 - mae: 8892.3672 - val_loss: 94312168.0000 - val_mae: 7871.1772\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 125729488.0000 - mae: 8818.7383 - val_loss: 93671136.0000 - val_mae: 7828.9502\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 153943680.0000 - mae: 9426.4697 - val_loss: 95169896.0000 - val_mae: 7925.0195\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 161919264.0000 - mae: 9643.8262 - val_loss: 96530584.0000 - val_mae: 8017.1177\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 128809712.0000 - mae: 8873.9766 - val_loss: 94748544.0000 - val_mae: 7902.0396\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 148438352.0000 - mae: 8572.7207 - val_loss: 97515192.0000 - val_mae: 8076.5742\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 148075280.0000 - mae: 9309.7197 - val_loss: 97278224.0000 - val_mae: 8058.4844\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 161637024.0000 - mae: 10010.6719 - val_loss: 97976480.0000 - val_mae: 8111.3696\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 152313728.0000 - mae: 9573.5371 - val_loss: 97296000.0000 - val_mae: 8069.6646\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 156690032.0000 - mae: 9441.9316 - val_loss: 94664984.0000 - val_mae: 7903.7856\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 155823296.0000 - mae: 9215.7920 - val_loss: 95729968.0000 - val_mae: 7972.6113\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 118928232.0000 - mae: 8282.0635 - val_loss: 93462616.0000 - val_mae: 7824.0928\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 154647712.0000 - mae: 10067.8330 - val_loss: 91526264.0000 - val_mae: 7694.5649\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 162864768.0000 - mae: 9447.6885 - val_loss: 91599528.0000 - val_mae: 7702.7378\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 169040320.0000 - mae: 10314.2549 - val_loss: 93368808.0000 - val_mae: 7815.2769\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 166189856.0000 - mae: 10381.8477 - val_loss: 94588208.0000 - val_mae: 7901.4043\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 163667552.0000 - mae: 9451.8203 - val_loss: 96365184.0000 - val_mae: 8011.0176\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 154821200.0000 - mae: 9785.7324 - val_loss: 97414880.0000 - val_mae: 8086.0112\n",
      "processing fold # 1\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 163825808.0000 - mae: 11126.1445 - val_loss: 231166432.0000 - val_mae: 12684.0469\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 155951152.0000 - mae: 10658.3867 - val_loss: 213310416.0000 - val_mae: 12017.2715\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 133943280.0000 - mae: 9867.0088 - val_loss: 189755056.0000 - val_mae: 11070.0059\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 131890160.0000 - mae: 9259.9795 - val_loss: 167785088.0000 - val_mae: 10097.1211\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 2ms/step - loss: 126707520.0000 - mae: 9113.1689 - val_loss: 146002064.0000 - val_mae: 9037.0078\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 101830144.0000 - mae: 7373.4829 - val_loss: 129730680.0000 - val_mae: 8160.9727\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 98241928.0000 - mae: 7415.7866 - val_loss: 116008872.0000 - val_mae: 7385.7349\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 99138408.0000 - mae: 7561.5356 - val_loss: 110502152.0000 - val_mae: 7111.3882\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 94854720.0000 - mae: 7614.9062 - val_loss: 104834768.0000 - val_mae: 6829.4727\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 92541352.0000 - mae: 7420.3252 - val_loss: 100795456.0000 - val_mae: 6629.2217\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 98607312.0000 - mae: 7291.6743 - val_loss: 103048800.0000 - val_mae: 6740.4194\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 79467928.0000 - mae: 6865.1436 - val_loss: 102875848.0000 - val_mae: 6732.3623\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 86460064.0000 - mae: 6949.3003 - val_loss: 98666320.0000 - val_mae: 6523.5957\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 105878408.0000 - mae: 7846.7510 - val_loss: 102097864.0000 - val_mae: 6694.1260\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 72670016.0000 - mae: 6479.2671 - val_loss: 93973872.0000 - val_mae: 6310.6001\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 100569072.0000 - mae: 7377.4932 - val_loss: 96108800.0000 - val_mae: 6404.6421\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 107656728.0000 - mae: 8020.2856 - val_loss: 97491160.0000 - val_mae: 6465.2148\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 76164280.0000 - mae: 6934.2798 - val_loss: 98358488.0000 - val_mae: 6509.4697\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 76286184.0000 - mae: 6490.9756 - val_loss: 95291872.0000 - val_mae: 6369.0039\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 75311048.0000 - mae: 7096.2129 - val_loss: 98059688.0000 - val_mae: 6495.7642\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 85394408.0000 - mae: 6957.9912 - val_loss: 100521576.0000 - val_mae: 6618.8252\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 87865056.0000 - mae: 7297.0186 - val_loss: 99837608.0000 - val_mae: 6585.5703\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 70767216.0000 - mae: 6398.9961 - val_loss: 97112360.0000 - val_mae: 6449.0732\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 72524840.0000 - mae: 6602.1245 - val_loss: 92689032.0000 - val_mae: 6252.8604\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 91612072.0000 - mae: 7265.5420 - val_loss: 92660160.0000 - val_mae: 6251.7256\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 66016076.0000 - mae: 6177.4092 - val_loss: 88802360.0000 - val_mae: 6074.6055\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 84455480.0000 - mae: 7010.9727 - val_loss: 91634928.0000 - val_mae: 6210.9429\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 67284160.0000 - mae: 6467.7373 - val_loss: 91255744.0000 - val_mae: 6185.5566\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 84309800.0000 - mae: 6854.1982 - val_loss: 88971960.0000 - val_mae: 6077.8271\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 63099436.0000 - mae: 6171.8701 - val_loss: 88979056.0000 - val_mae: 6086.2197\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 58151260.0000 - mae: 6035.2275 - val_loss: 88297024.0000 - val_mae: 6042.8242\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 59061932.0000 - mae: 5771.0479 - val_loss: 89822168.0000 - val_mae: 6115.2119\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 74205608.0000 - mae: 6427.0024 - val_loss: 91626176.0000 - val_mae: 6199.6240\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 89284856.0000 - mae: 6993.4937 - val_loss: 92361744.0000 - val_mae: 6231.6001\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 76905536.0000 - mae: 6812.5796 - val_loss: 91514256.0000 - val_mae: 6193.6406\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 70262680.0000 - mae: 6257.6826 - val_loss: 92305168.0000 - val_mae: 6229.3164\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 91195336.0000 - mae: 7502.6152 - val_loss: 100345136.0000 - val_mae: 6623.6582\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 63057976.0000 - mae: 6061.4292 - val_loss: 97787152.0000 - val_mae: 6495.0537\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 75462816.0000 - mae: 6894.6836 - val_loss: 94014832.0000 - val_mae: 6306.7144\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 64918776.0000 - mae: 6074.3711 - val_loss: 94189096.0000 - val_mae: 6315.3853\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 61533748.0000 - mae: 5620.1401 - val_loss: 91859392.0000 - val_mae: 6210.3140\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 64987980.0000 - mae: 6196.3740 - val_loss: 97070160.0000 - val_mae: 6461.9727\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 89950536.0000 - mae: 7061.8540 - val_loss: 93321600.0000 - val_mae: 6275.5640\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 70388688.0000 - mae: 6145.7285 - val_loss: 97247464.0000 - val_mae: 6472.4854\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 82460736.0000 - mae: 6373.8760 - val_loss: 94371392.0000 - val_mae: 6325.9331\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 93179488.0000 - mae: 6985.7881 - val_loss: 92256864.0000 - val_mae: 6227.0054\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 71852328.0000 - mae: 6527.1509 - val_loss: 89588184.0000 - val_mae: 6104.7012\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 88572264.0000 - mae: 6410.0303 - val_loss: 88007896.0000 - val_mae: 6031.1084\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 58560372.0000 - mae: 5819.9829 - val_loss: 86062928.0000 - val_mae: 5937.9722\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 76841168.0000 - mae: 6418.6963 - val_loss: 79711184.0000 - val_mae: 5655.4487\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 77858192.0000 - mae: 6541.4404 - val_loss: 84871752.0000 - val_mae: 5880.8105\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 94737728.0000 - mae: 7694.2046 - val_loss: 89741176.0000 - val_mae: 6114.5181\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 81622464.0000 - mae: 6784.7607 - val_loss: 97368616.0000 - val_mae: 6484.0625\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 82636816.0000 - mae: 6941.9619 - val_loss: 95651600.0000 - val_mae: 6397.8931\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 70153488.0000 - mae: 6249.0894 - val_loss: 83067568.0000 - val_mae: 5791.3145\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 62443692.0000 - mae: 6073.4106 - val_loss: 79655768.0000 - val_mae: 5650.9961\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 79768096.0000 - mae: 6877.0596 - val_loss: 83593048.0000 - val_mae: 5818.9141\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 86085768.0000 - mae: 6866.2402 - val_loss: 90365680.0000 - val_mae: 6144.4497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 90213256.0000 - mae: 7435.9912 - val_loss: 97146792.0000 - val_mae: 6475.7739\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 66547576.0000 - mae: 6324.3955 - val_loss: 90773568.0000 - val_mae: 6163.5625\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 83777704.0000 - mae: 6657.6479 - val_loss: 89443744.0000 - val_mae: 6102.0239\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 83348136.0000 - mae: 6730.7070 - val_loss: 90348104.0000 - val_mae: 6144.4712\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 84453000.0000 - mae: 6488.1758 - val_loss: 90107600.0000 - val_mae: 6133.1543\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 83154760.0000 - mae: 6734.9170 - val_loss: 90693520.0000 - val_mae: 6159.2949\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 73803960.0000 - mae: 6600.4233 - val_loss: 90124592.0000 - val_mae: 6133.4258\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 84179192.0000 - mae: 6281.7319 - val_loss: 90227480.0000 - val_mae: 6137.5957\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 74247560.0000 - mae: 6172.0220 - val_loss: 92726352.0000 - val_mae: 6257.1685\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 106566064.0000 - mae: 7716.3760 - val_loss: 96634296.0000 - val_mae: 6457.7290\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 66669876.0000 - mae: 6236.7598 - val_loss: 87441904.0000 - val_mae: 6009.1045\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 71305592.0000 - mae: 6421.5762 - val_loss: 88239240.0000 - val_mae: 6046.6133\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 71247840.0000 - mae: 6080.6963 - val_loss: 84798400.0000 - val_mae: 5882.6250\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 66416300.0000 - mae: 6245.9258 - val_loss: 83729424.0000 - val_mae: 5829.6479\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 82016080.0000 - mae: 5909.6836 - val_loss: 86294552.0000 - val_mae: 5955.8076\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 49063672.0000 - mae: 5248.5020 - val_loss: 77310456.0000 - val_mae: 5546.8057\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 81372128.0000 - mae: 6719.3677 - val_loss: 80168392.0000 - val_mae: 5658.2529\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 61621620.0000 - mae: 6634.5273 - val_loss: 88819656.0000 - val_mae: 6074.7954\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 56756692.0000 - mae: 5585.3896 - val_loss: 88357952.0000 - val_mae: 6054.1450\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 65761288.0000 - mae: 6078.2734 - val_loss: 86405336.0000 - val_mae: 5962.3628\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 57895656.0000 - mae: 5758.1479 - val_loss: 88258016.0000 - val_mae: 6050.1636\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 59371584.0000 - mae: 5682.9326 - val_loss: 81660368.0000 - val_mae: 5729.7231\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 86606856.0000 - mae: 6554.3877 - val_loss: 89450192.0000 - val_mae: 6105.1523\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 76664112.0000 - mae: 6612.7822 - val_loss: 91589048.0000 - val_mae: 6209.7173\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 79494008.0000 - mae: 6420.6006 - val_loss: 88982976.0000 - val_mae: 6082.2378\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 61410928.0000 - mae: 5885.5161 - val_loss: 83383456.0000 - val_mae: 5816.4810\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 91231232.0000 - mae: 6842.0586 - val_loss: 89883720.0000 - val_mae: 6128.7617\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 64364972.0000 - mae: 6213.1680 - val_loss: 85348160.0000 - val_mae: 5911.5698\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 60254896.0000 - mae: 5884.8296 - val_loss: 86360768.0000 - val_mae: 5963.6260\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 75999880.0000 - mae: 6273.7222 - val_loss: 81630504.0000 - val_mae: 5728.1650\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 63437780.0000 - mae: 5965.1655 - val_loss: 84470592.0000 - val_mae: 5870.2124\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 80920808.0000 - mae: 6546.5801 - val_loss: 90214832.0000 - val_mae: 6145.9131\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 66800332.0000 - mae: 6689.9785 - val_loss: 86387672.0000 - val_mae: 5962.6665\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 84734968.0000 - mae: 6746.7520 - val_loss: 93091728.0000 - val_mae: 6296.2402\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 88668608.0000 - mae: 7372.7700 - val_loss: 93308184.0000 - val_mae: 6307.0044\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 63304224.0000 - mae: 6117.9775 - val_loss: 86735672.0000 - val_mae: 5979.4697\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 65437404.0000 - mae: 5602.0039 - val_loss: 84124920.0000 - val_mae: 5853.8286\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 70451584.0000 - mae: 6119.5225 - val_loss: 83680208.0000 - val_mae: 5833.0854\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 81102976.0000 - mae: 6565.0615 - val_loss: 83445648.0000 - val_mae: 5822.0581\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 75673512.0000 - mae: 6729.4336 - val_loss: 86186688.0000 - val_mae: 5953.7954\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 72338352.0000 - mae: 6472.7588 - val_loss: 88767192.0000 - val_mae: 6077.2773\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 65789672.0000 - mae: 6233.3262 - val_loss: 87007864.0000 - val_mae: 5989.8032\n",
      "processing fold # 2\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 195966080.0000 - mae: 11692.0000 - val_loss: 177351888.0000 - val_mae: 11653.2070\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 186128816.0000 - mae: 11311.5410 - val_loss: 161637328.0000 - val_mae: 10955.3184\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 178394720.0000 - mae: 11021.9316 - val_loss: 146435472.0000 - val_mae: 10238.3369\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 155304368.0000 - mae: 10301.0205 - val_loss: 131950664.0000 - val_mae: 9507.9482\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 164953984.0000 - mae: 9905.4033 - val_loss: 120208384.0000 - val_mae: 8870.6738\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 147614048.0000 - mae: 9321.7744 - val_loss: 108399552.0000 - val_mae: 8181.9448\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 134737440.0000 - mae: 8798.8076 - val_loss: 97205184.0000 - val_mae: 7473.6016\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 117878256.0000 - mae: 8195.2832 - val_loss: 90791608.0000 - val_mae: 7034.5166\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 135554080.0000 - mae: 9280.8330 - val_loss: 88255480.0000 - val_mae: 6859.8955\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 155736880.0000 - mae: 10083.8838 - val_loss: 87064880.0000 - val_mae: 6781.2095\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 147927872.0000 - mae: 9466.1797 - val_loss: 88913208.0000 - val_mae: 6917.9180\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 2ms/step - loss: 116768776.0000 - mae: 8748.3555 - val_loss: 80455048.0000 - val_mae: 6313.6143\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 126643864.0000 - mae: 8766.5195 - val_loss: 77275336.0000 - val_mae: 6118.0269\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 119838624.0000 - mae: 8186.8530 - val_loss: 76049336.0000 - val_mae: 6053.7148\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 132753064.0000 - mae: 8685.0273 - val_loss: 77682480.0000 - val_mae: 6190.6543\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 142133536.0000 - mae: 9391.9258 - val_loss: 72590904.0000 - val_mae: 5840.0664\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 138861008.0000 - mae: 8829.9736 - val_loss: 73768064.0000 - val_mae: 5927.0942\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 143862048.0000 - mae: 8814.8887 - val_loss: 70873568.0000 - val_mae: 5739.2852\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 120170440.0000 - mae: 8231.0986 - val_loss: 69863704.0000 - val_mae: 5677.2095\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 111418840.0000 - mae: 8057.5259 - val_loss: 70493312.0000 - val_mae: 5730.2832\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 107468128.0000 - mae: 7918.0396 - val_loss: 68027944.0000 - val_mae: 5555.6133\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 109758936.0000 - mae: 8195.5234 - val_loss: 63727652.0000 - val_mae: 5254.5610\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 122789256.0000 - mae: 8334.8193 - val_loss: 65817504.0000 - val_mae: 5407.5708\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 101306664.0000 - mae: 8092.6875 - val_loss: 61174676.0000 - val_mae: 5087.7549\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 110083112.0000 - mae: 7772.8770 - val_loss: 57220584.0000 - val_mae: 4809.0845\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 99952792.0000 - mae: 7276.5122 - val_loss: 56086164.0000 - val_mae: 4728.7822\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 126468456.0000 - mae: 8418.7285 - val_loss: 56984712.0000 - val_mae: 4800.6099\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 102297784.0000 - mae: 7829.8574 - val_loss: 55241584.0000 - val_mae: 4674.3384\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 89671936.0000 - mae: 7522.5571 - val_loss: 55919936.0000 - val_mae: 4726.1733\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 106382704.0000 - mae: 7947.6094 - val_loss: 54358676.0000 - val_mae: 4617.8047\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 115805632.0000 - mae: 8070.2261 - val_loss: 53204436.0000 - val_mae: 4537.8267\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 109694176.0000 - mae: 7965.8374 - val_loss: 56456448.0000 - val_mae: 4783.1162\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 106355656.0000 - mae: 7634.4268 - val_loss: 58121780.0000 - val_mae: 4909.7168\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 90738376.0000 - mae: 7805.8613 - val_loss: 56267336.0000 - val_mae: 4782.9023\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 109106160.0000 - mae: 7762.3936 - val_loss: 53384908.0000 - val_mae: 4569.2656\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 90688536.0000 - mae: 7212.5239 - val_loss: 50228988.0000 - val_mae: 4333.5317\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 94900536.0000 - mae: 7092.9009 - val_loss: 53552780.0000 - val_mae: 4591.9893\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 116524368.0000 - mae: 8311.0195 - val_loss: 54720288.0000 - val_mae: 4686.4316\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 92893880.0000 - mae: 7976.8706 - val_loss: 51955920.0000 - val_mae: 4478.7300\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 103341928.0000 - mae: 7777.4365 - val_loss: 51448508.0000 - val_mae: 4442.2617\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 106400872.0000 - mae: 8105.7949 - val_loss: 51950468.0000 - val_mae: 4483.6436\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 103883552.0000 - mae: 7421.3755 - val_loss: 50685068.0000 - val_mae: 4389.2173\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 118179016.0000 - mae: 8320.5166 - val_loss: 53617568.0000 - val_mae: 4618.9492\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 98940688.0000 - mae: 7634.7036 - val_loss: 53416440.0000 - val_mae: 4608.9248\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 91526368.0000 - mae: 6971.0898 - val_loss: 53131172.0000 - val_mae: 4592.9189\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 98449152.0000 - mae: 7467.8105 - val_loss: 48221348.0000 - val_mae: 4216.8540\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 113531488.0000 - mae: 8372.5781 - val_loss: 52690780.0000 - val_mae: 4566.1675\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 111210040.0000 - mae: 7618.6743 - val_loss: 53907588.0000 - val_mae: 4663.0903\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 83969304.0000 - mae: 6903.2148 - val_loss: 51374156.0000 - val_mae: 4469.8613\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 97022240.0000 - mae: 7522.0898 - val_loss: 49099584.0000 - val_mae: 4294.0210\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 98636224.0000 - mae: 7236.7178 - val_loss: 52825508.0000 - val_mae: 4590.3013\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 76202944.0000 - mae: 6377.1748 - val_loss: 47095640.0000 - val_mae: 4149.3101\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 83235760.0000 - mae: 6779.9658 - val_loss: 44632540.0000 - val_mae: 4004.6724\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 71610336.0000 - mae: 6741.2935 - val_loss: 41461348.0000 - val_mae: 3904.1719\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 106582104.0000 - mae: 7786.7070 - val_loss: 42431704.0000 - val_mae: 3924.3340\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 97086592.0000 - mae: 7028.3696 - val_loss: 45907492.0000 - val_mae: 4074.5464\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 100348480.0000 - mae: 7476.7705 - val_loss: 47635424.0000 - val_mae: 4197.9175\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 115153648.0000 - mae: 8109.6958 - val_loss: 47541084.0000 - val_mae: 4192.5479\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 100159712.0000 - mae: 7648.2524 - val_loss: 46515496.0000 - val_mae: 4118.5493\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 89512352.0000 - mae: 6817.7339 - val_loss: 44927068.0000 - val_mae: 4018.6582\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 101433896.0000 - mae: 7570.2139 - val_loss: 45227860.0000 - val_mae: 4035.9734\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 108903352.0000 - mae: 8001.9248 - val_loss: 48003176.0000 - val_mae: 4231.8682\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 85183288.0000 - mae: 6810.1152 - val_loss: 49431704.0000 - val_mae: 4348.1499\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 78457344.0000 - mae: 6220.3911 - val_loss: 50860648.0000 - val_mae: 4463.1758\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 111605696.0000 - mae: 7636.9487 - val_loss: 48793648.0000 - val_mae: 4297.5645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 87028264.0000 - mae: 6597.9624 - val_loss: 50097956.0000 - val_mae: 4405.7866\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 98076248.0000 - mae: 6713.7754 - val_loss: 49026776.0000 - val_mae: 4320.6211\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 103277824.0000 - mae: 7583.9985 - val_loss: 50305740.0000 - val_mae: 4427.3550\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 105435616.0000 - mae: 7578.2065 - val_loss: 49859960.0000 - val_mae: 4393.2632\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 107587704.0000 - mae: 7784.2446 - val_loss: 49557440.0000 - val_mae: 4374.5195\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 72842200.0000 - mae: 6116.8560 - val_loss: 45279888.0000 - val_mae: 4045.5952\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 93697224.0000 - mae: 7620.9780 - val_loss: 44973056.0000 - val_mae: 4025.2288\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 65339360.0000 - mae: 6467.3540 - val_loss: 46090592.0000 - val_mae: 4107.7495\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 82404192.0000 - mae: 6631.0112 - val_loss: 47242312.0000 - val_mae: 4196.3013\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 67790344.0000 - mae: 6441.6450 - val_loss: 45714912.0000 - val_mae: 4086.3262\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 100949704.0000 - mae: 7582.8535 - val_loss: 44770888.0000 - val_mae: 4017.6855\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 106441280.0000 - mae: 7150.8047 - val_loss: 49720608.0000 - val_mae: 4405.9307\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 94877400.0000 - mae: 7460.3320 - val_loss: 46137824.0000 - val_mae: 4121.7881\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 58701552.0000 - mae: 6093.6006 - val_loss: 43994592.0000 - val_mae: 3966.9595\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 81544704.0000 - mae: 6665.3237 - val_loss: 43679632.0000 - val_mae: 3947.1318\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 93569664.0000 - mae: 6938.9155 - val_loss: 45255992.0000 - val_mae: 4062.5881\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 95182024.0000 - mae: 6991.9341 - val_loss: 46405188.0000 - val_mae: 4148.6338\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 81861960.0000 - mae: 6455.9507 - val_loss: 43964564.0000 - val_mae: 3968.0469\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 98668056.0000 - mae: 7727.4814 - val_loss: 47948512.0000 - val_mae: 4277.0200\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 97144704.0000 - mae: 7334.1289 - val_loss: 46215268.0000 - val_mae: 4137.9316\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 95134288.0000 - mae: 6764.8208 - val_loss: 43649900.0000 - val_mae: 3947.8223\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 93169456.0000 - mae: 7378.5918 - val_loss: 45542032.0000 - val_mae: 4090.7021\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 71198688.0000 - mae: 6561.5430 - val_loss: 46701692.0000 - val_mae: 4182.1123\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 75642944.0000 - mae: 6774.6108 - val_loss: 40513120.0000 - val_mae: 3802.2449\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 83367192.0000 - mae: 6545.9102 - val_loss: 44314564.0000 - val_mae: 4004.1089\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 78375496.0000 - mae: 6777.1914 - val_loss: 45561400.0000 - val_mae: 4100.7788\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 126003784.0000 - mae: 8136.3384 - val_loss: 47025392.0000 - val_mae: 4219.3555\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 87984448.0000 - mae: 7116.6436 - val_loss: 42003292.0000 - val_mae: 3858.9287\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 86891120.0000 - mae: 6940.0894 - val_loss: 45248620.0000 - val_mae: 4079.9673\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 88488560.0000 - mae: 6704.8833 - val_loss: 48040224.0000 - val_mae: 4306.6167\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 94101384.0000 - mae: 6919.6611 - val_loss: 47967104.0000 - val_mae: 4302.8789\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 100601808.0000 - mae: 7430.6372 - val_loss: 44787808.0000 - val_mae: 4049.9348\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 99892288.0000 - mae: 7012.3091 - val_loss: 49063904.0000 - val_mae: 4392.5439\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 78440104.0000 - mae: 6565.8677 - val_loss: 42701184.0000 - val_mae: 3892.6787\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 103691272.0000 - mae: 7720.0283 - val_loss: 45928132.0000 - val_mae: 4140.2979\n"
     ]
    }
   ],
   "source": [
    "x = df_shuff[103:,:25].astype('float32')\n",
    "y = df_shuff[103:,25].astype('float32')\n",
    "k = 3\n",
    "num_val_samples = len(x) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate([x[:i * num_val_samples],x[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([y[:i * num_val_samples],y[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1,validation_data=(val_data, val_targets))\n",
    "    #all_scores.append(np.mean(history.history['val_mae']))\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    all_scores.append(np.mean(mae_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6745.682183430989"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation='relu',input_shape=(train_data.shape[1],)))\n",
    "    #model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(8, activation='relu'))\n",
    "    #model.add(layers.Dense(6, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 176455136.0000 - mae: 10960.8418 - val_loss: 103366520.0000 - val_mae: 8306.2197\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 114787808.0000 - mae: 7933.8394 - val_loss: 60585540.0000 - val_mae: 5384.9038\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 78000432.0000 - mae: 5886.9805 - val_loss: 39726144.0000 - val_mae: 4242.9424\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 60487920.0000 - mae: 4977.6445 - val_loss: 32764202.0000 - val_mae: 3968.1177\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 53084760.0000 - mae: 4865.5571 - val_loss: 30418950.0000 - val_mae: 3920.7712\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 50446288.0000 - mae: 5014.2695 - val_loss: 30019530.0000 - val_mae: 3937.3088\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 49871320.0000 - mae: 4995.7051 - val_loss: 29674626.0000 - val_mae: 3927.0510\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 49163988.0000 - mae: 5038.4385 - val_loss: 29417158.0000 - val_mae: 3958.6663\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 48527808.0000 - mae: 4925.0269 - val_loss: 29478944.0000 - val_mae: 4035.5137\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 47749856.0000 - mae: 5040.7588 - val_loss: 29258694.0000 - val_mae: 4036.0249\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 46982216.0000 - mae: 5053.7134 - val_loss: 28503396.0000 - val_mae: 3918.5771\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 46988848.0000 - mae: 4925.4878 - val_loss: 28489980.0000 - val_mae: 3970.9043\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 46343656.0000 - mae: 4955.3120 - val_loss: 28233844.0000 - val_mae: 3970.1470\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45852224.0000 - mae: 4950.2627 - val_loss: 27842958.0000 - val_mae: 3937.5332\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45451296.0000 - mae: 4842.1001 - val_loss: 27721216.0000 - val_mae: 3965.5261\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44852640.0000 - mae: 4867.6099 - val_loss: 27305712.0000 - val_mae: 3932.7109\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44047428.0000 - mae: 4827.3818 - val_loss: 26441720.0000 - val_mae: 3759.2739\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43694176.0000 - mae: 4823.2319 - val_loss: 26002156.0000 - val_mae: 3687.6157\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43700024.0000 - mae: 4679.6206 - val_loss: 26189992.0000 - val_mae: 3844.9248\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42332880.0000 - mae: 4780.8579 - val_loss: 25346882.0000 - val_mae: 3650.9688\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42658340.0000 - mae: 4668.1509 - val_loss: 25121990.0000 - val_mae: 3696.1880\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 41643344.0000 - mae: 4744.6772 - val_loss: 24653082.0000 - val_mae: 3600.3860\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42179568.0000 - mae: 4547.2109 - val_loss: 24508722.0000 - val_mae: 3674.6514\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40654596.0000 - mae: 4487.6685 - val_loss: 24974888.0000 - val_mae: 3822.4785\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40014208.0000 - mae: 4628.7148 - val_loss: 23700476.0000 - val_mae: 3600.1616\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40014368.0000 - mae: 4541.1050 - val_loss: 23235974.0000 - val_mae: 3543.9858\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39558028.0000 - mae: 4456.4395 - val_loss: 23269100.0000 - val_mae: 3645.8083\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39011192.0000 - mae: 4433.1128 - val_loss: 22753860.0000 - val_mae: 3585.9373\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 38289028.0000 - mae: 4436.2876 - val_loss: 22213456.0000 - val_mae: 3512.5317\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 37699844.0000 - mae: 4376.9990 - val_loss: 22203838.0000 - val_mae: 3584.0286\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 36655444.0000 - mae: 4432.0688 - val_loss: 21347410.0000 - val_mae: 3434.7913\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 36664240.0000 - mae: 4251.4614 - val_loss: 21204478.0000 - val_mae: 3479.7151\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 35425140.0000 - mae: 4333.7471 - val_loss: 20410166.0000 - val_mae: 3317.8438\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 35911640.0000 - mae: 4139.4263 - val_loss: 20630840.0000 - val_mae: 3460.2534\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 34688800.0000 - mae: 4258.5820 - val_loss: 19979282.0000 - val_mae: 3373.1140\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 34085064.0000 - mae: 4116.3940 - val_loss: 19850130.0000 - val_mae: 3405.6982\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 33848176.0000 - mae: 4069.1223 - val_loss: 19320298.0000 - val_mae: 3335.7925\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32950946.0000 - mae: 3991.3809 - val_loss: 19192432.0000 - val_mae: 3369.7439\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32430490.0000 - mae: 4052.8140 - val_loss: 18813200.0000 - val_mae: 3345.0579\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 31473124.0000 - mae: 4014.6052 - val_loss: 17832170.0000 - val_mae: 3161.7927\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 31183638.0000 - mae: 3931.4614 - val_loss: 17418670.0000 - val_mae: 3134.7600\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 30438330.0000 - mae: 3865.7390 - val_loss: 16743765.0000 - val_mae: 2968.4631\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 30175072.0000 - mae: 3879.4744 - val_loss: 16402605.0000 - val_mae: 2965.3689\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29179782.0000 - mae: 3614.1113 - val_loss: 17210038.0000 - val_mae: 3288.4126\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28512188.0000 - mae: 3797.9199 - val_loss: 16575057.0000 - val_mae: 3202.4441\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28026686.0000 - mae: 3760.2378 - val_loss: 15450472.0000 - val_mae: 2969.6152\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27543270.0000 - mae: 3635.4797 - val_loss: 15038323.0000 - val_mae: 2917.3503\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27350128.0000 - mae: 3627.5088 - val_loss: 14992146.0000 - val_mae: 2991.1406\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 26459500.0000 - mae: 3576.0034 - val_loss: 14352628.0000 - val_mae: 2878.1033\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 26076022.0000 - mae: 3437.3931 - val_loss: 14775026.0000 - val_mae: 3079.7744\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 25015460.0000 - mae: 3490.5176 - val_loss: 15302108.0000 - val_mae: 3252.5723\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 24300046.0000 - mae: 3555.7559 - val_loss: 13025922.0000 - val_mae: 2651.2993\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 24613400.0000 - mae: 3216.8542 - val_loss: 14149155.0000 - val_mae: 3092.5359\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 23837270.0000 - mae: 3363.5693 - val_loss: 13319960.0000 - val_mae: 2944.5059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 23235386.0000 - mae: 3408.5317 - val_loss: 12633031.0000 - val_mae: 2809.4597\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 22620880.0000 - mae: 3342.9561 - val_loss: 12303398.0000 - val_mae: 2777.8657\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 22152976.0000 - mae: 3241.7029 - val_loss: 11742486.0000 - val_mae: 2662.9033\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20961618.0000 - mae: 3363.3408 - val_loss: 10986289.0000 - val_mae: 2343.8379\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 21273456.0000 - mae: 3172.3201 - val_loss: 11725720.0000 - val_mae: 2788.1050\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20361186.0000 - mae: 3113.6301 - val_loss: 10502051.0000 - val_mae: 2377.9050\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20652176.0000 - mae: 3025.1396 - val_loss: 10800668.0000 - val_mae: 2607.6980\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 19944518.0000 - mae: 2986.9856 - val_loss: 11637509.0000 - val_mae: 2853.4053\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 19263024.0000 - mae: 3144.1533 - val_loss: 10492716.0000 - val_mae: 2601.9749\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18865936.0000 - mae: 2900.9426 - val_loss: 11902660.0000 - val_mae: 2939.7808\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18379030.0000 - mae: 2924.4287 - val_loss: 9896728.0000 - val_mae: 2479.3037\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18346630.0000 - mae: 2865.4458 - val_loss: 11128526.0000 - val_mae: 2807.9966\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16338340.0000 - mae: 2955.1821 - val_loss: 9350530.0000 - val_mae: 1835.2277\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18057630.0000 - mae: 2856.5410 - val_loss: 10275784.0000 - val_mae: 2638.6123\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 17404714.0000 - mae: 2912.0420 - val_loss: 9290550.0000 - val_mae: 2391.1631\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 17046268.0000 - mae: 2864.9414 - val_loss: 9745658.0000 - val_mae: 2533.6765\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 17286074.0000 - mae: 2827.5776 - val_loss: 9070160.0000 - val_mae: 2365.3342\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16669239.0000 - mae: 2888.2654 - val_loss: 8701936.0000 - val_mae: 2264.1914\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16671290.0000 - mae: 2778.2393 - val_loss: 9503876.0000 - val_mae: 2506.4197\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16309282.0000 - mae: 2806.2368 - val_loss: 8830147.0000 - val_mae: 2335.3438\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16208632.0000 - mae: 2712.3503 - val_loss: 9836297.0000 - val_mae: 2588.8530\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15777816.0000 - mae: 2793.9016 - val_loss: 8679731.0000 - val_mae: 2314.4124\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15565868.0000 - mae: 2718.1375 - val_loss: 9104642.0000 - val_mae: 2433.4849\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15350481.0000 - mae: 2736.0295 - val_loss: 7861620.0000 - val_mae: 2042.7355\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14596376.0000 - mae: 2563.4121 - val_loss: 12271569.0000 - val_mae: 2987.7737\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14234855.0000 - mae: 2764.5059 - val_loss: 7867597.5000 - val_mae: 2067.1418\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15070541.0000 - mae: 2653.6184 - val_loss: 8997592.0000 - val_mae: 2408.4810\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14952124.0000 - mae: 2624.7859 - val_loss: 9068784.0000 - val_mae: 2423.4968\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14565547.0000 - mae: 2656.9951 - val_loss: 8592344.0000 - val_mae: 2306.5430\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14642677.0000 - mae: 2612.6821 - val_loss: 7660152.0000 - val_mae: 2045.5830\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13990113.0000 - mae: 2614.9548 - val_loss: 9286100.0000 - val_mae: 2456.2168\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13964961.0000 - mae: 2539.4033 - val_loss: 10583736.0000 - val_mae: 2676.4429\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13953576.0000 - mae: 2674.2097 - val_loss: 11593837.0000 - val_mae: 2811.6895\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14045133.0000 - mae: 2628.5964 - val_loss: 7524080.0000 - val_mae: 2040.5120\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14232392.0000 - mae: 2512.8159 - val_loss: 9087634.0000 - val_mae: 2391.8918\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14354096.0000 - mae: 2534.9658 - val_loss: 8850301.0000 - val_mae: 2337.5984\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13695280.0000 - mae: 2550.8062 - val_loss: 10112048.0000 - val_mae: 2573.4436\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13861938.0000 - mae: 2475.2915 - val_loss: 10704760.0000 - val_mae: 2655.2979\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13932447.0000 - mae: 2586.7273 - val_loss: 8434155.0000 - val_mae: 2244.1096\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13688723.0000 - mae: 2567.3450 - val_loss: 10199239.0000 - val_mae: 2559.8423\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13627256.0000 - mae: 2564.6072 - val_loss: 7570998.0000 - val_mae: 2081.3145\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13838659.0000 - mae: 2520.0840 - val_loss: 8267324.0000 - val_mae: 2221.1899\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12883974.0000 - mae: 2508.0803 - val_loss: 11315178.0000 - val_mae: 2715.5703\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13163241.0000 - mae: 2503.7620 - val_loss: 7294761.0000 - val_mae: 2028.4731\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13211304.0000 - mae: 2446.2361 - val_loss: 7146277.5000 - val_mae: 1996.0466\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13815505.0000 - mae: 2515.4133 - val_loss: 8539440.0000 - val_mae: 2264.2568\n",
      "processing fold # 1\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 135724960.0000 - mae: 9909.6221 - val_loss: 174187920.0000 - val_mae: 10232.3252\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 98561816.0000 - mae: 7710.7480 - val_loss: 130370456.0000 - val_mae: 7935.5981\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 64990968.0000 - mae: 5531.4312 - val_loss: 95642944.0000 - val_mae: 6398.5654\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 47588344.0000 - mae: 4479.9009 - val_loss: 77456648.0000 - val_mae: 5709.4463\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39454912.0000 - mae: 4174.3027 - val_loss: 68870200.0000 - val_mae: 5466.2559\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 36098532.0000 - mae: 4184.2939 - val_loss: 65252480.0000 - val_mae: 5399.8164\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 34945776.0000 - mae: 4218.3691 - val_loss: 63738588.0000 - val_mae: 5390.7563\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 34470940.0000 - mae: 4141.0581 - val_loss: 61999584.0000 - val_mae: 5422.4136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 33947568.0000 - mae: 4187.3877 - val_loss: 62251992.0000 - val_mae: 5368.4443\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 33704632.0000 - mae: 4150.3950 - val_loss: 61717396.0000 - val_mae: 5356.8208\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 33464696.0000 - mae: 4130.2881 - val_loss: 61963680.0000 - val_mae: 5306.7949\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 33123046.0000 - mae: 4113.7695 - val_loss: 61098336.0000 - val_mae: 5299.6172\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32532446.0000 - mae: 4141.1997 - val_loss: 61238156.0000 - val_mae: 5259.2349\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32681382.0000 - mae: 4030.9844 - val_loss: 60531320.0000 - val_mae: 5250.0952\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32341338.0000 - mae: 4031.4775 - val_loss: 59837120.0000 - val_mae: 5234.2490\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32005440.0000 - mae: 3920.1526 - val_loss: 60393000.0000 - val_mae: 5189.1079\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 31559788.0000 - mae: 3985.6416 - val_loss: 58419592.0000 - val_mae: 5221.0723\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 31065334.0000 - mae: 3966.8418 - val_loss: 57727584.0000 - val_mae: 5209.7129\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 30809510.0000 - mae: 3966.1594 - val_loss: 57310504.0000 - val_mae: 5188.0962\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 30211396.0000 - mae: 3956.9937 - val_loss: 57849804.0000 - val_mae: 5116.2671\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 30391782.0000 - mae: 3853.9084 - val_loss: 56592736.0000 - val_mae: 5125.9189\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29651730.0000 - mae: 3905.6655 - val_loss: 56435596.0000 - val_mae: 5084.3740\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29369918.0000 - mae: 3837.8044 - val_loss: 55071564.0000 - val_mae: 5095.9297\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28978704.0000 - mae: 3804.6577 - val_loss: 54368072.0000 - val_mae: 5072.8975\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28502812.0000 - mae: 3794.7722 - val_loss: 53730060.0000 - val_mae: 5054.4541\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27867200.0000 - mae: 3822.5762 - val_loss: 54462340.0000 - val_mae: 4965.9321\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28202624.0000 - mae: 3674.0264 - val_loss: 52831108.0000 - val_mae: 4989.1230\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27043106.0000 - mae: 3776.4172 - val_loss: 52894340.0000 - val_mae: 4924.9580\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27201764.0000 - mae: 3545.9004 - val_loss: 51406644.0000 - val_mae: 4939.0342\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 26555730.0000 - mae: 3673.6790 - val_loss: 51289904.0000 - val_mae: 4882.1177\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 25924862.0000 - mae: 3605.1426 - val_loss: 50444008.0000 - val_mae: 4866.6855\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 25647934.0000 - mae: 3569.7451 - val_loss: 49190556.0000 - val_mae: 4860.6855\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 25083778.0000 - mae: 3600.3386 - val_loss: 49052800.0000 - val_mae: 4795.5366\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 24457706.0000 - mae: 3551.3535 - val_loss: 49650464.0000 - val_mae: 4700.4565\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 24494174.0000 - mae: 3437.5737 - val_loss: 47736116.0000 - val_mae: 4717.2710\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 23892700.0000 - mae: 3442.1238 - val_loss: 47209368.0000 - val_mae: 4673.8398\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 23403972.0000 - mae: 3422.0020 - val_loss: 46093572.0000 - val_mae: 4655.2852\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 22895478.0000 - mae: 3368.8977 - val_loss: 45689760.0000 - val_mae: 4606.7441\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 22534356.0000 - mae: 3300.2329 - val_loss: 45579788.0000 - val_mae: 4531.1982\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 22008996.0000 - mae: 3258.5256 - val_loss: 44860576.0000 - val_mae: 4496.1211\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 21948396.0000 - mae: 3186.7322 - val_loss: 43554500.0000 - val_mae: 4490.7759\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20931728.0000 - mae: 3247.4277 - val_loss: 43848908.0000 - val_mae: 4404.4019\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20721696.0000 - mae: 3170.5117 - val_loss: 43430892.0000 - val_mae: 4352.6235\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 20169380.0000 - mae: 3054.0051 - val_loss: 41072908.0000 - val_mae: 4395.0698\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 19679574.0000 - mae: 2946.8230 - val_loss: 39531788.0000 - val_mae: 4417.3643\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 19060534.0000 - mae: 3112.3188 - val_loss: 41198912.0000 - val_mae: 4225.4702\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 19353434.0000 - mae: 2834.6016 - val_loss: 39002304.0000 - val_mae: 4273.9263\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18275544.0000 - mae: 3004.3027 - val_loss: 40402960.0000 - val_mae: 4127.4902\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18112860.0000 - mae: 2906.8716 - val_loss: 39793140.0000 - val_mae: 4088.0225\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 18110940.0000 - mae: 2865.2083 - val_loss: 38457908.0000 - val_mae: 4076.5459\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 17328222.0000 - mae: 2851.5164 - val_loss: 38579808.0000 - val_mae: 4001.3796\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 17424892.0000 - mae: 2785.5291 - val_loss: 36869864.0000 - val_mae: 4000.9573\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16698669.0000 - mae: 2776.0574 - val_loss: 35945844.0000 - val_mae: 3973.4043\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 16055644.0000 - mae: 2717.7695 - val_loss: 34369608.0000 - val_mae: 3997.4250\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15870298.0000 - mae: 2780.4910 - val_loss: 33915812.0000 - val_mae: 3932.8157\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15468358.0000 - mae: 2739.4309 - val_loss: 34243784.0000 - val_mae: 3821.0000\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 15059318.0000 - mae: 2641.1646 - val_loss: 36034216.0000 - val_mae: 3695.3059\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14995224.0000 - mae: 2513.9353 - val_loss: 31990886.0000 - val_mae: 3827.4739\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14256248.0000 - mae: 2622.6179 - val_loss: 34011540.0000 - val_mae: 3622.2224\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14458008.0000 - mae: 2472.1782 - val_loss: 31397192.0000 - val_mae: 3684.6655\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14005037.0000 - mae: 2497.0659 - val_loss: 30320820.0000 - val_mae: 3713.9858\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13065338.0000 - mae: 2473.6545 - val_loss: 34229388.0000 - val_mae: 3476.7148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13830156.0000 - mae: 2416.6289 - val_loss: 31168828.0000 - val_mae: 3482.3879\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13369734.0000 - mae: 2426.2983 - val_loss: 30295392.0000 - val_mae: 3487.9307\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 13004266.0000 - mae: 2401.4236 - val_loss: 29175006.0000 - val_mae: 3499.1621\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12763116.0000 - mae: 2427.4146 - val_loss: 28775334.0000 - val_mae: 3470.9082\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12683818.0000 - mae: 2340.1672 - val_loss: 28294448.0000 - val_mae: 3461.9690\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12434797.0000 - mae: 2398.9409 - val_loss: 27583934.0000 - val_mae: 3465.2012\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 12263161.0000 - mae: 2340.4531 - val_loss: 26938326.0000 - val_mae: 3465.2788\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 11851103.0000 - mae: 2370.3655 - val_loss: 26053798.0000 - val_mae: 3511.2021\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11541621.0000 - mae: 2330.7986 - val_loss: 27805148.0000 - val_mae: 3242.3645\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11546552.0000 - mae: 2343.4041 - val_loss: 28533008.0000 - val_mae: 3176.2246\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11849461.0000 - mae: 2241.6694 - val_loss: 26647122.0000 - val_mae: 3228.7317\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11540840.0000 - mae: 2138.6760 - val_loss: 24838210.0000 - val_mae: 3417.3201\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11202203.0000 - mae: 2327.2227 - val_loss: 24341220.0000 - val_mae: 3392.8579\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11343545.0000 - mae: 2294.7854 - val_loss: 25719106.0000 - val_mae: 3147.1580\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11071682.0000 - mae: 2284.7761 - val_loss: 24862582.0000 - val_mae: 3181.4348\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10756160.0000 - mae: 2314.2695 - val_loss: 26682032.0000 - val_mae: 3063.8066\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11017895.0000 - mae: 2230.0769 - val_loss: 25296178.0000 - val_mae: 3066.4558\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 11160552.0000 - mae: 2181.3611 - val_loss: 25348640.0000 - val_mae: 3057.0281\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10668818.0000 - mae: 2231.1409 - val_loss: 25861388.0000 - val_mae: 3025.8557\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10649512.0000 - mae: 2148.5879 - val_loss: 23459886.0000 - val_mae: 3104.0542\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10455874.0000 - mae: 2267.2646 - val_loss: 25516334.0000 - val_mae: 2992.2727\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 11018411.0000 - mae: 2219.5398 - val_loss: 24981110.0000 - val_mae: 2994.2366\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10502380.0000 - mae: 2155.2007 - val_loss: 22725318.0000 - val_mae: 3079.4668\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10424246.0000 - mae: 2211.0901 - val_loss: 24247096.0000 - val_mae: 2975.9893\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10361686.0000 - mae: 2194.7258 - val_loss: 23390034.0000 - val_mae: 2980.4255\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 10073489.0000 - mae: 2211.3083 - val_loss: 22632864.0000 - val_mae: 2976.9121\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10050108.0000 - mae: 2130.2349 - val_loss: 21636190.0000 - val_mae: 3063.3667\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9893246.0000 - mae: 2148.9744 - val_loss: 22681282.0000 - val_mae: 2948.3633\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10131792.0000 - mae: 2186.4819 - val_loss: 23186244.0000 - val_mae: 2925.6401\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9944473.0000 - mae: 2216.2007 - val_loss: 24455666.0000 - val_mae: 2894.3269\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 10097809.0000 - mae: 2155.1248 - val_loss: 22204824.0000 - val_mae: 2915.5923\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9891807.0000 - mae: 2158.8357 - val_loss: 21110628.0000 - val_mae: 2973.0767\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9884155.0000 - mae: 2197.6660 - val_loss: 21764050.0000 - val_mae: 2896.2693\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9767851.0000 - mae: 2196.2468 - val_loss: 22307802.0000 - val_mae: 2864.9287\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9494372.0000 - mae: 2220.5234 - val_loss: 24357764.0000 - val_mae: 2861.0569\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 9927950.0000 - mae: 2207.4412 - val_loss: 22004418.0000 - val_mae: 2847.1301\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9442085.0000 - mae: 2191.8074 - val_loss: 22564844.0000 - val_mae: 2826.8813\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 9683960.0000 - mae: 2219.6648 - val_loss: 21685960.0000 - val_mae: 2816.2708\n",
      "processing fold # 2\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 240496496.0000 - mae: 13623.1035 - val_loss: 203117184.0000 - val_mae: 12703.6084\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 216863104.0000 - mae: 12725.0400 - val_loss: 193220928.0000 - val_mae: 12316.7822\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 208499264.0000 - mae: 12408.6689 - val_loss: 185042960.0000 - val_mae: 11989.9170\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 198868544.0000 - mae: 12020.3291 - val_loss: 174059536.0000 - val_mae: 11526.6475\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 183875904.0000 - mae: 11421.7217 - val_loss: 157323696.0000 - val_mae: 10784.8838\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - ETA: 0s - loss: 164601872.0000 - mae: 10794.298 - 0s 2ms/step - loss: 166058288.0000 - mae: 10627.3857 - val_loss: 138682048.0000 - val_mae: 9895.2139\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 145706592.0000 - mae: 9651.9316 - val_loss: 118142688.0000 - val_mae: 8813.2158\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 122262416.0000 - mae: 8446.5166 - val_loss: 95949072.0000 - val_mae: 7472.3452\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 102078344.0000 - mae: 7120.8208 - val_loss: 77006496.0000 - val_mae: 6111.6826\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 82767400.0000 - mae: 6009.7100 - val_loss: 61508848.0000 - val_mae: 5039.6050\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 66395180.0000 - mae: 5312.6211 - val_loss: 49154676.0000 - val_mae: 4311.2817\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 57092132.0000 - mae: 4912.1943 - val_loss: 43076560.0000 - val_mae: 4299.7085\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 51894276.0000 - mae: 4742.2734 - val_loss: 40469104.0000 - val_mae: 4324.6973\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 49249432.0000 - mae: 4674.7876 - val_loss: 38660244.0000 - val_mae: 4378.5522\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 47580860.0000 - mae: 4682.7964 - val_loss: 38018912.0000 - val_mae: 4437.8638\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 2ms/step - loss: 46753032.0000 - mae: 4742.5479 - val_loss: 37712096.0000 - val_mae: 4468.6055\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 46762376.0000 - mae: 4688.7520 - val_loss: 37419376.0000 - val_mae: 4541.1704\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45971848.0000 - mae: 4776.9849 - val_loss: 37290740.0000 - val_mae: 4550.3550\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45962592.0000 - mae: 4752.7822 - val_loss: 37163388.0000 - val_mae: 4551.8071\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45726284.0000 - mae: 4781.6509 - val_loss: 37034632.0000 - val_mae: 4573.1548\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44912548.0000 - mae: 4778.9355 - val_loss: 37103040.0000 - val_mae: 4453.4966\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45792904.0000 - mae: 4700.9976 - val_loss: 36856612.0000 - val_mae: 4515.4355\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45293972.0000 - mae: 4780.0728 - val_loss: 36741212.0000 - val_mae: 4505.0425\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45336324.0000 - mae: 4730.0327 - val_loss: 36687692.0000 - val_mae: 4466.6724\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45276464.0000 - mae: 4744.9136 - val_loss: 36541596.0000 - val_mae: 4475.2661\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 45104476.0000 - mae: 4727.6343 - val_loss: 36397476.0000 - val_mae: 4492.2075\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44863700.0000 - mae: 4715.8052 - val_loss: 36260136.0000 - val_mae: 4514.5640\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44604132.0000 - mae: 4747.0605 - val_loss: 36145552.0000 - val_mae: 4510.1821\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44380764.0000 - mae: 4750.0522 - val_loss: 36024252.0000 - val_mae: 4484.0303\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44384876.0000 - mae: 4735.7627 - val_loss: 35896472.0000 - val_mae: 4470.1987\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44187064.0000 - mae: 4702.6382 - val_loss: 35811556.0000 - val_mae: 4428.6021\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44394480.0000 - mae: 4658.3027 - val_loss: 35706168.0000 - val_mae: 4423.3936\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44259440.0000 - mae: 4664.2241 - val_loss: 35580608.0000 - val_mae: 4423.1772\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44046952.0000 - mae: 4676.8345 - val_loss: 35467472.0000 - val_mae: 4408.8857\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43781872.0000 - mae: 4654.9702 - val_loss: 35413852.0000 - val_mae: 4374.4336\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 44006872.0000 - mae: 4618.1060 - val_loss: 35286440.0000 - val_mae: 4376.3530\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43522912.0000 - mae: 4679.2920 - val_loss: 35129324.0000 - val_mae: 4389.5938\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43311388.0000 - mae: 4686.4204 - val_loss: 35031328.0000 - val_mae: 4371.9722\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43394616.0000 - mae: 4626.1187 - val_loss: 34877684.0000 - val_mae: 4392.9126\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43207368.0000 - mae: 4647.1367 - val_loss: 34766500.0000 - val_mae: 4383.0776\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 43190972.0000 - mae: 4575.6924 - val_loss: 34646420.0000 - val_mae: 4417.3726\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42687712.0000 - mae: 4668.1445 - val_loss: 34526092.0000 - val_mae: 4358.9038\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42745408.0000 - mae: 4636.7817 - val_loss: 34412424.0000 - val_mae: 4339.5938\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42836724.0000 - mae: 4583.2773 - val_loss: 34278820.0000 - val_mae: 4338.8062\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42541472.0000 - mae: 4577.8730 - val_loss: 34140540.0000 - val_mae: 4343.5757\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42351864.0000 - mae: 4592.3940 - val_loss: 34005476.0000 - val_mae: 4386.9805\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 41961480.0000 - mae: 4632.9302 - val_loss: 33914460.0000 - val_mae: 4293.6777\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42098500.0000 - mae: 4578.7363 - val_loss: 33754552.0000 - val_mae: 4303.8115\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 41815024.0000 - mae: 4578.4307 - val_loss: 33618468.0000 - val_mae: 4296.0352\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 41794232.0000 - mae: 4541.3784 - val_loss: 33542328.0000 - val_mae: 4248.2573\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 42238240.0000 - mae: 4481.2666 - val_loss: 33411004.0000 - val_mae: 4240.4810\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 41500812.0000 - mae: 4469.4385 - val_loss: 33198708.0000 - val_mae: 4295.0073\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 41551264.0000 - mae: 4511.2744 - val_loss: 33080944.0000 - val_mae: 4260.9858\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 41144012.0000 - mae: 4522.8555 - val_loss: 32909944.0000 - val_mae: 4298.4980\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40921184.0000 - mae: 4521.2114 - val_loss: 32755892.0000 - val_mae: 4256.0186\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40839456.0000 - mae: 4488.2051 - val_loss: 32594398.0000 - val_mae: 4276.7720\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40618836.0000 - mae: 4512.2939 - val_loss: 32413500.0000 - val_mae: 4259.1953\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40426184.0000 - mae: 4482.0347 - val_loss: 32273476.0000 - val_mae: 4191.7603\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40433236.0000 - mae: 4457.1050 - val_loss: 32144606.0000 - val_mae: 4152.3408\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 40231432.0000 - mae: 4386.8491 - val_loss: 31940946.0000 - val_mae: 4205.5981\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39824172.0000 - mae: 4474.5508 - val_loss: 31767654.0000 - val_mae: 4175.7075\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39730244.0000 - mae: 4457.4214 - val_loss: 31629094.0000 - val_mae: 4124.0000\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39450968.0000 - mae: 4426.2480 - val_loss: 31509428.0000 - val_mae: 4077.8699\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39527296.0000 - mae: 4368.5747 - val_loss: 31224594.0000 - val_mae: 4146.3984\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 39152328.0000 - mae: 4348.5962 - val_loss: 31023898.0000 - val_mae: 4171.0566\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 38784308.0000 - mae: 4424.6299 - val_loss: 30855880.0000 - val_mae: 4096.8198\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 38641960.0000 - mae: 4404.1553 - val_loss: 30630828.0000 - val_mae: 4116.1792\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 38493048.0000 - mae: 4375.5342 - val_loss: 30444592.0000 - val_mae: 4128.7749\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 38540604.0000 - mae: 4266.7964 - val_loss: 30261668.0000 - val_mae: 4112.9248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 37845652.0000 - mae: 4402.2842 - val_loss: 30076906.0000 - val_mae: 4108.6855\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 37623040.0000 - mae: 4347.7188 - val_loss: 29875920.0000 - val_mae: 4033.5750\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 37926896.0000 - mae: 4262.8579 - val_loss: 29709744.0000 - val_mae: 3991.5964\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 37465316.0000 - mae: 4259.8359 - val_loss: 29452368.0000 - val_mae: 4036.0938\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 36942164.0000 - mae: 4318.0684 - val_loss: 29302662.0000 - val_mae: 3943.4353\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 36994108.0000 - mae: 4277.6743 - val_loss: 29038950.0000 - val_mae: 3963.7869\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 36810336.0000 - mae: 4265.2217 - val_loss: 28847418.0000 - val_mae: 3916.9397\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 36570840.0000 - mae: 4255.9775 - val_loss: 28613162.0000 - val_mae: 3903.1062\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 35844728.0000 - mae: 4252.1572 - val_loss: 28592442.0000 - val_mae: 3800.5598\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 36126916.0000 - mae: 4201.1016 - val_loss: 28198472.0000 - val_mae: 3847.2026\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 35608756.0000 - mae: 4219.6265 - val_loss: 27863912.0000 - val_mae: 3905.4990\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 35314980.0000 - mae: 4227.3125 - val_loss: 27643218.0000 - val_mae: 3861.2827\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 35047008.0000 - mae: 4129.0396 - val_loss: 27627410.0000 - val_mae: 3731.8262\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 34921076.0000 - mae: 4064.6191 - val_loss: 27187666.0000 - val_mae: 3826.3513\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 34285408.0000 - mae: 4154.5464 - val_loss: 27060470.0000 - val_mae: 3723.7151\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 34580896.0000 - mae: 4058.0051 - val_loss: 26215974.0000 - val_mae: 3648.7224\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 33214354.0000 - mae: 4013.2991 - val_loss: 26071466.0000 - val_mae: 3571.8936\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 33419754.0000 - mae: 3943.4338 - val_loss: 25501570.0000 - val_mae: 3603.4783\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32840704.0000 - mae: 3977.4365 - val_loss: 25309484.0000 - val_mae: 3547.3535\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32333334.0000 - mae: 3974.0327 - val_loss: 24809782.0000 - val_mae: 3563.5820\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 32010248.0000 - mae: 3935.4238 - val_loss: 24484280.0000 - val_mae: 3562.5667\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 31810884.0000 - mae: 3874.2095 - val_loss: 24333232.0000 - val_mae: 3473.6995\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 31128472.0000 - mae: 3901.5969 - val_loss: 23883332.0000 - val_mae: 3487.2432\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 30712986.0000 - mae: 3830.1187 - val_loss: 23515804.0000 - val_mae: 3580.2195\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 30081374.0000 - mae: 3828.0320 - val_loss: 23549350.0000 - val_mae: 3359.4651\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 30318638.0000 - mae: 3785.9216 - val_loss: 22817372.0000 - val_mae: 3428.7771\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 29805078.0000 - mae: 3750.4434 - val_loss: 22559346.0000 - val_mae: 3356.8770\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 29594676.0000 - mae: 3678.2747 - val_loss: 22181288.0000 - val_mae: 3402.4492\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28900234.0000 - mae: 3729.1052 - val_loss: 21874958.0000 - val_mae: 3357.7776\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 28384490.0000 - mae: 3733.6228 - val_loss: 21640920.0000 - val_mae: 3268.8760\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 27940356.0000 - mae: 3740.1721 - val_loss: 21462916.0000 - val_mae: 3193.0671\n"
     ]
    }
   ],
   "source": [
    "x = df_shuff[103:,:25].astype('float32')\n",
    "y = df_shuff[103:,25].astype('float32')\n",
    "k = 3\n",
    "num_val_samples = len(x) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = x[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    partial_train_data = np.concatenate([x[:i * num_val_samples],x[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([y[:i * num_val_samples],y[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets,epochs=num_epochs, batch_size=1,validation_data=(val_data, val_targets))\n",
    "    #all_scores.append(np.mean(history.history['val_mae']))\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    all_scores.append(np.mean(mae_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.772323 ],\n",
       "       [ 6.202093 ],\n",
       "       [10.003999 ],\n",
       "       [10.637757 ],\n",
       "       [ 5.2780795],\n",
       "       [ 5.2123947],\n",
       "       [ 6.606345 ],\n",
       "       [ 8.213878 ],\n",
       "       [ 9.32983  ],\n",
       "       [ 9.031932 ],\n",
       "       [ 5.396051 ],\n",
       "       [ 7.112819 ],\n",
       "       [ 7.9115424],\n",
       "       [ 6.678185 ],\n",
       "       [10.22585  ],\n",
       "       [ 5.531982 ],\n",
       "       [ 5.3526   ],\n",
       "       [ 7.1732287],\n",
       "       [ 8.867246 ],\n",
       "       [ 7.936401 ],\n",
       "       [12.869277 ],\n",
       "       [ 8.327964 ],\n",
       "       [ 5.4785295],\n",
       "       [ 8.309916 ],\n",
       "       [ 7.6665907],\n",
       "       [ 5.1308594],\n",
       "       [ 5.5846868],\n",
       "       [ 7.36691  ],\n",
       "       [ 9.007764 ],\n",
       "       [ 7.334466 ],\n",
       "       [ 9.323819 ],\n",
       "       [ 5.2342544],\n",
       "       [ 5.448571 ],\n",
       "       [ 4.8710523],\n",
       "       [ 8.7143   ],\n",
       "       [ 9.861895 ],\n",
       "       [ 5.4749207],\n",
       "       [ 5.3027425],\n",
       "       [ 5.2490067],\n",
       "       [ 8.100242 ],\n",
       "       [ 5.192646 ],\n",
       "       [ 9.399413 ],\n",
       "       [ 9.821404 ],\n",
       "       [ 6.1073556],\n",
       "       [ 7.1566105],\n",
       "       [12.406443 ],\n",
       "       [10.7579565],\n",
       "       [ 9.4598055],\n",
       "       [ 5.9888635],\n",
       "       [ 5.4617696],\n",
       "       [ 7.3175316],\n",
       "       [ 5.0088906],\n",
       "       [ 7.88146  ],\n",
       "       [ 5.391606 ],\n",
       "       [ 8.442523 ],\n",
       "       [10.4468155],\n",
       "       [ 7.9750905],\n",
       "       [ 8.131222 ],\n",
       "       [ 6.236362 ],\n",
       "       [ 6.7047534],\n",
       "       [ 5.796927 ],\n",
       "       [ 9.191456 ]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8778.,  7295., 16695., 14399.,  6938.,  6649., 10698., 13495.,\n",
       "       14489., 12629.,  7395., 10245., 11549.,  7957., 18399.,  6377.,\n",
       "        5499., 11245., 18150., 20970., 36000., 15250.,  9258., 15510.,\n",
       "       11694.,  5572.,  6575.,  8921., 18620.,  9989., 14869.,  6795.,\n",
       "        8358.,  5348., 12940., 18920.,  5572.,  5118.,  5195., 12170.,\n",
       "        5399., 19045., 15690.,  8948., 10345., 32250., 31600., 17450.,\n",
       "        7898.,  6295.,  9639.,  6488., 16925.,  7499., 11048., 23875.,\n",
       "       11850., 15645.,  7295., 13845.,  7898., 11900.], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
